{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76e39b48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "82cd8e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "477210f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "N = 100\n",
    "x = torch.randn(N)\n",
    "plt.hist(x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e663502",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = 3 * x + 5 + torch.randn(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bed7a4a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x,y,alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "eefb32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x, w, b):\n",
    "    return w * x + b\n",
    "\n",
    "def loss_fn2(y_pred, y_true):\n",
    "    return sum((y_pred-y_true)**2)/len(y_pred)\n",
    "def loss_fn(y_pred, y_true):\n",
    "    squared_diffs = (y_pred - y_true)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0d73c8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loss_fn, params, x, y_true, epochs, lr=0.01):\n",
    "    for epoch in range(epochs):\n",
    "        if params.grad is not None:\n",
    "            params.grad.zero_()\n",
    "        \n",
    "        y_pred = model(x, *params)\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        print(f\"epoch {epoch} loss is {loss}\")\n",
    "        print(f\"epoch {epoch} params.grad right before loss.backward() : {params.grad}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        print(f\"epoch {epoch} : params.grad right after loss.backward(): {params.grad}\")\n",
    "        with torch.no_grad():\n",
    "            params -= lr * params.grad\n",
    "        print(f\"epoch {epoch} after parameter update : {params}, required_grad : {params.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8e336b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss is 27.537954330444336\n",
      "epoch 0 params.grad right before loss.backward() : None\n",
      "epoch 0 : params.grad right after loss.backward(): tensor([-2.1467, -9.7693])\n",
      "epoch 0 after parameter update : tensor([1.0215, 0.0977], requires_grad=True), required_grad : True\n",
      "epoch 1 loss is 26.547100067138672\n",
      "epoch 1 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 1 : params.grad right after loss.backward(): tensor([-2.1279, -9.5764])\n",
      "epoch 1 after parameter update : tensor([1.0427, 0.1935], requires_grad=True), required_grad : True\n",
      "epoch 2 loss is 25.594009399414062\n",
      "epoch 2 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 2 : params.grad right after loss.backward(): tensor([-2.1091, -9.3873])\n",
      "epoch 2 after parameter update : tensor([1.0638, 0.2873], requires_grad=True), required_grad : True\n",
      "epoch 3 loss is 24.677217483520508\n",
      "epoch 3 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 3 : params.grad right after loss.backward(): tensor([-2.0904, -9.2019])\n",
      "epoch 3 after parameter update : tensor([1.0847, 0.3793], requires_grad=True), required_grad : True\n",
      "epoch 4 loss is 23.79532241821289\n",
      "epoch 4 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 4 : params.grad right after loss.backward(): tensor([-2.0718, -9.0203])\n",
      "epoch 4 after parameter update : tensor([1.1055, 0.4696], requires_grad=True), required_grad : True\n",
      "epoch 5 loss is 22.946977615356445\n",
      "epoch 5 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 5 : params.grad right after loss.backward(): tensor([-2.0531, -8.8422])\n",
      "epoch 5 after parameter update : tensor([1.1260, 0.5580], requires_grad=True), required_grad : True\n",
      "epoch 6 loss is 22.130884170532227\n",
      "epoch 6 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 6 : params.grad right after loss.backward(): tensor([-2.0346, -8.6677])\n",
      "epoch 6 after parameter update : tensor([1.1463, 0.6447], requires_grad=True), required_grad : True\n",
      "epoch 7 loss is 21.34579086303711\n",
      "epoch 7 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 7 : params.grad right after loss.backward(): tensor([-2.0161, -8.4967])\n",
      "epoch 7 after parameter update : tensor([1.1665, 0.7296], requires_grad=True), required_grad : True\n",
      "epoch 8 loss is 20.59052276611328\n",
      "epoch 8 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 8 : params.grad right after loss.backward(): tensor([-1.9977, -8.3290])\n",
      "epoch 8 after parameter update : tensor([1.1865, 0.8129], requires_grad=True), required_grad : True\n",
      "epoch 9 loss is 19.86391830444336\n",
      "epoch 9 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 9 : params.grad right after loss.backward(): tensor([-1.9793, -8.1647])\n",
      "epoch 9 after parameter update : tensor([1.2063, 0.8946], requires_grad=True), required_grad : True\n",
      "epoch 10 loss is 19.164867401123047\n",
      "epoch 10 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 10 : params.grad right after loss.backward(): tensor([-1.9610, -8.0037])\n",
      "epoch 10 after parameter update : tensor([1.2259, 0.9746], requires_grad=True), required_grad : True\n",
      "epoch 11 loss is 18.4923152923584\n",
      "epoch 11 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 11 : params.grad right after loss.backward(): tensor([-1.9428, -7.8458])\n",
      "epoch 11 after parameter update : tensor([1.2453, 1.0530], requires_grad=True), required_grad : True\n",
      "epoch 12 loss is 17.845245361328125\n",
      "epoch 12 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 12 : params.grad right after loss.backward(): tensor([-1.9247, -7.6911])\n",
      "epoch 12 after parameter update : tensor([1.2646, 1.1300], requires_grad=True), required_grad : True\n",
      "epoch 13 loss is 17.222673416137695\n",
      "epoch 13 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 13 : params.grad right after loss.backward(): tensor([-1.9066, -7.5395])\n",
      "epoch 13 after parameter update : tensor([1.2836, 1.2054], requires_grad=True), required_grad : True\n",
      "epoch 14 loss is 16.623659133911133\n",
      "epoch 14 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 14 : params.grad right after loss.backward(): tensor([-1.8886, -7.3909])\n",
      "epoch 14 after parameter update : tensor([1.3025, 1.2793], requires_grad=True), required_grad : True\n",
      "epoch 15 loss is 16.047292709350586\n",
      "epoch 15 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 15 : params.grad right after loss.backward(): tensor([-1.8707, -7.2452])\n",
      "epoch 15 after parameter update : tensor([1.3212, 1.3517], requires_grad=True), required_grad : True\n",
      "epoch 16 loss is 15.492706298828125\n",
      "epoch 16 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 16 : params.grad right after loss.backward(): tensor([-1.8529, -7.1024])\n",
      "epoch 16 after parameter update : tensor([1.3397, 1.4227], requires_grad=True), required_grad : True\n",
      "epoch 17 loss is 14.959067344665527\n",
      "epoch 17 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 17 : params.grad right after loss.backward(): tensor([-1.8352, -6.9625])\n",
      "epoch 17 after parameter update : tensor([1.3581, 1.4924], requires_grad=True), required_grad : True\n",
      "epoch 18 loss is 14.445556640625\n",
      "epoch 18 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 18 : params.grad right after loss.backward(): tensor([-1.8175, -6.8253])\n",
      "epoch 18 after parameter update : tensor([1.3763, 1.5606], requires_grad=True), required_grad : True\n",
      "epoch 19 loss is 13.951425552368164\n",
      "epoch 19 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 19 : params.grad right after loss.backward(): tensor([-1.8000, -6.6909])\n",
      "epoch 19 after parameter update : tensor([1.3943, 1.6275], requires_grad=True), required_grad : True\n",
      "epoch 20 loss is 13.475913047790527\n",
      "epoch 20 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 20 : params.grad right after loss.backward(): tensor([-1.7825, -6.5591])\n",
      "epoch 20 after parameter update : tensor([1.4121, 1.6931], requires_grad=True), required_grad : True\n",
      "epoch 21 loss is 13.018311500549316\n",
      "epoch 21 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 21 : params.grad right after loss.backward(): tensor([-1.7651, -6.4300])\n",
      "epoch 21 after parameter update : tensor([1.4297, 1.7574], requires_grad=True), required_grad : True\n",
      "epoch 22 loss is 12.577934265136719\n",
      "epoch 22 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 22 : params.grad right after loss.backward(): tensor([-1.7479, -6.3034])\n",
      "epoch 22 after parameter update : tensor([1.4472, 1.8205], requires_grad=True), required_grad : True\n",
      "epoch 23 loss is 12.154123306274414\n",
      "epoch 23 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 23 : params.grad right after loss.backward(): tensor([-1.7307, -6.1793])\n",
      "epoch 23 after parameter update : tensor([1.4645, 1.8822], requires_grad=True), required_grad : True\n",
      "epoch 24 loss is 11.746241569519043\n",
      "epoch 24 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 24 : params.grad right after loss.backward(): tensor([-1.7136, -6.0577])\n",
      "epoch 24 after parameter update : tensor([1.4817, 1.9428], requires_grad=True), required_grad : True\n",
      "epoch 25 loss is 11.353676795959473\n",
      "epoch 25 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 25 : params.grad right after loss.backward(): tensor([-1.6966, -5.9385])\n",
      "epoch 25 after parameter update : tensor([1.4986, 2.0022], requires_grad=True), required_grad : True\n",
      "epoch 26 loss is 10.975852012634277\n",
      "epoch 26 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 26 : params.grad right after loss.backward(): tensor([-1.6797, -5.8216])\n",
      "epoch 26 after parameter update : tensor([1.5154, 2.0604], requires_grad=True), required_grad : True\n",
      "epoch 27 loss is 10.612195014953613\n",
      "epoch 27 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 27 : params.grad right after loss.backward(): tensor([-1.6630, -5.7071])\n",
      "epoch 27 after parameter update : tensor([1.5321, 2.1175], requires_grad=True), required_grad : True\n",
      "epoch 28 loss is 10.262175559997559\n",
      "epoch 28 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 28 : params.grad right after loss.backward(): tensor([-1.6463, -5.5949])\n",
      "epoch 28 after parameter update : tensor([1.5485, 2.1734], requires_grad=True), required_grad : True\n",
      "epoch 29 loss is 9.925261497497559\n",
      "epoch 29 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 29 : params.grad right after loss.backward(): tensor([-1.6297, -5.4848])\n",
      "epoch 29 after parameter update : tensor([1.5648, 2.2283], requires_grad=True), required_grad : True\n",
      "epoch 30 loss is 9.60096263885498\n",
      "epoch 30 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 30 : params.grad right after loss.backward(): tensor([-1.6132, -5.3770])\n",
      "epoch 30 after parameter update : tensor([1.5810, 2.2821], requires_grad=True), required_grad : True\n",
      "epoch 31 loss is 9.28879165649414\n",
      "epoch 31 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 31 : params.grad right after loss.backward(): tensor([-1.5969, -5.2713])\n",
      "epoch 31 after parameter update : tensor([1.5969, 2.3348], requires_grad=True), required_grad : True\n",
      "epoch 32 loss is 8.988288879394531\n",
      "epoch 32 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 32 : params.grad right after loss.backward(): tensor([-1.5806, -5.1677])\n",
      "epoch 32 after parameter update : tensor([1.6127, 2.3864], requires_grad=True), required_grad : True\n",
      "epoch 33 loss is 8.699006080627441\n",
      "epoch 33 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 33 : params.grad right after loss.backward(): tensor([-1.5645, -5.0661])\n",
      "epoch 33 after parameter update : tensor([1.6284, 2.4371], requires_grad=True), required_grad : True\n",
      "epoch 34 loss is 8.420522689819336\n",
      "epoch 34 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 34 : params.grad right after loss.backward(): tensor([-1.5485, -4.9666])\n",
      "epoch 34 after parameter update : tensor([1.6439, 2.4868], requires_grad=True), required_grad : True\n",
      "epoch 35 loss is 8.152424812316895\n",
      "epoch 35 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 35 : params.grad right after loss.backward(): tensor([-1.5325, -4.8690])\n",
      "epoch 35 after parameter update : tensor([1.6592, 2.5355], requires_grad=True), required_grad : True\n",
      "epoch 36 loss is 7.894315242767334\n",
      "epoch 36 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 36 : params.grad right after loss.backward(): tensor([-1.5167, -4.7734])\n",
      "epoch 36 after parameter update : tensor([1.6743, 2.5832], requires_grad=True), required_grad : True\n",
      "epoch 37 loss is 7.645816802978516\n",
      "epoch 37 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 37 : params.grad right after loss.backward(): tensor([-1.5010, -4.6796])\n",
      "epoch 37 after parameter update : tensor([1.6894, 2.6300], requires_grad=True), required_grad : True\n",
      "epoch 38 loss is 7.406564712524414\n",
      "epoch 38 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 38 : params.grad right after loss.backward(): tensor([-1.4854, -4.5877])\n",
      "epoch 38 after parameter update : tensor([1.7042, 2.6759], requires_grad=True), required_grad : True\n",
      "epoch 39 loss is 7.176204681396484\n",
      "epoch 39 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 39 : params.grad right after loss.backward(): tensor([-1.4700, -4.4977])\n",
      "epoch 39 after parameter update : tensor([1.7189, 2.7208], requires_grad=True), required_grad : True\n",
      "epoch 40 loss is 6.954407215118408\n",
      "epoch 40 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 40 : params.grad right after loss.backward(): tensor([-1.4546, -4.4094])\n",
      "epoch 40 after parameter update : tensor([1.7335, 2.7649], requires_grad=True), required_grad : True\n",
      "epoch 41 loss is 6.740839004516602\n",
      "epoch 41 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 41 : params.grad right after loss.backward(): tensor([-1.4393, -4.3229])\n",
      "epoch 41 after parameter update : tensor([1.7479, 2.8082], requires_grad=True), required_grad : True\n",
      "epoch 42 loss is 6.53519344329834\n",
      "epoch 42 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 42 : params.grad right after loss.backward(): tensor([-1.4242, -4.2380])\n",
      "epoch 42 after parameter update : tensor([1.7621, 2.8506], requires_grad=True), required_grad : True\n",
      "epoch 43 loss is 6.3371686935424805\n",
      "epoch 43 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 43 : params.grad right after loss.backward(): tensor([-1.4092, -4.1549])\n",
      "epoch 43 after parameter update : tensor([1.7762, 2.8921], requires_grad=True), required_grad : True\n",
      "epoch 44 loss is 6.146478176116943\n",
      "epoch 44 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 44 : params.grad right after loss.backward(): tensor([-1.3943, -4.0734])\n",
      "epoch 44 after parameter update : tensor([1.7901, 2.9328], requires_grad=True), required_grad : True\n",
      "epoch 45 loss is 5.9628400802612305\n",
      "epoch 45 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 45 : params.grad right after loss.backward(): tensor([-1.3795, -3.9935])\n",
      "epoch 45 after parameter update : tensor([1.8039, 2.9728], requires_grad=True), required_grad : True\n",
      "epoch 46 loss is 5.7859930992126465\n",
      "epoch 46 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 46 : params.grad right after loss.backward(): tensor([-1.3648, -3.9152])\n",
      "epoch 46 after parameter update : tensor([1.8176, 3.0119], requires_grad=True), required_grad : True\n",
      "epoch 47 loss is 5.615678787231445\n",
      "epoch 47 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 47 : params.grad right after loss.backward(): tensor([-1.3503, -3.8385])\n",
      "epoch 47 after parameter update : tensor([1.8311, 3.0503], requires_grad=True), required_grad : True\n",
      "epoch 48 loss is 5.451650619506836\n",
      "epoch 48 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 48 : params.grad right after loss.backward(): tensor([-1.3358, -3.7632])\n",
      "epoch 48 after parameter update : tensor([1.8444, 3.0879], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49 loss is 5.293671131134033\n",
      "epoch 49 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 49 : params.grad right after loss.backward(): tensor([-1.3215, -3.6895])\n",
      "epoch 49 after parameter update : tensor([1.8576, 3.1248], requires_grad=True), required_grad : True\n",
      "epoch 50 loss is 5.141511917114258\n",
      "epoch 50 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 50 : params.grad right after loss.backward(): tensor([-1.3073, -3.6172])\n",
      "epoch 50 after parameter update : tensor([1.8707, 3.1610], requires_grad=True), required_grad : True\n",
      "epoch 51 loss is 4.994957447052002\n",
      "epoch 51 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 51 : params.grad right after loss.backward(): tensor([-1.2932, -3.5463])\n",
      "epoch 51 after parameter update : tensor([1.8837, 3.1965], requires_grad=True), required_grad : True\n",
      "epoch 52 loss is 4.853789806365967\n",
      "epoch 52 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 52 : params.grad right after loss.backward(): tensor([-1.2792, -3.4769])\n",
      "epoch 52 after parameter update : tensor([1.8964, 3.2312], requires_grad=True), required_grad : True\n",
      "epoch 53 loss is 4.717810153961182\n",
      "epoch 53 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 53 : params.grad right after loss.backward(): tensor([-1.2653, -3.4088])\n",
      "epoch 53 after parameter update : tensor([1.9091, 3.2653], requires_grad=True), required_grad : True\n",
      "epoch 54 loss is 4.586824417114258\n",
      "epoch 54 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 54 : params.grad right after loss.backward(): tensor([-1.2516, -3.3421])\n",
      "epoch 54 after parameter update : tensor([1.9216, 3.2987], requires_grad=True), required_grad : True\n",
      "epoch 55 loss is 4.460643291473389\n",
      "epoch 55 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 55 : params.grad right after loss.backward(): tensor([-1.2379, -3.2767])\n",
      "epoch 55 after parameter update : tensor([1.9340, 3.3315], requires_grad=True), required_grad : True\n",
      "epoch 56 loss is 4.339089393615723\n",
      "epoch 56 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 56 : params.grad right after loss.backward(): tensor([-1.2244, -3.2125])\n",
      "epoch 56 after parameter update : tensor([1.9462, 3.3636], requires_grad=True), required_grad : True\n",
      "epoch 57 loss is 4.221985816955566\n",
      "epoch 57 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 57 : params.grad right after loss.backward(): tensor([-1.2110, -3.1497])\n",
      "epoch 57 after parameter update : tensor([1.9583, 3.3951], requires_grad=True), required_grad : True\n",
      "epoch 58 loss is 4.109166622161865\n",
      "epoch 58 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 58 : params.grad right after loss.backward(): tensor([-1.1977, -3.0881])\n",
      "epoch 58 after parameter update : tensor([1.9703, 3.4260], requires_grad=True), required_grad : True\n",
      "epoch 59 loss is 4.0004706382751465\n",
      "epoch 59 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 59 : params.grad right after loss.backward(): tensor([-1.1846, -3.0277])\n",
      "epoch 59 after parameter update : tensor([1.9822, 3.4563], requires_grad=True), required_grad : True\n",
      "epoch 60 loss is 3.8957467079162598\n",
      "epoch 60 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 60 : params.grad right after loss.backward(): tensor([-1.1715, -2.9684])\n",
      "epoch 60 after parameter update : tensor([1.9939, 3.4860], requires_grad=True), required_grad : True\n",
      "epoch 61 loss is 3.794842481613159\n",
      "epoch 61 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 61 : params.grad right after loss.backward(): tensor([-1.1586, -2.9104])\n",
      "epoch 61 after parameter update : tensor([2.0055, 3.5151], requires_grad=True), required_grad : True\n",
      "epoch 62 loss is 3.697617292404175\n",
      "epoch 62 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 62 : params.grad right after loss.backward(): tensor([-1.1457, -2.8535])\n",
      "epoch 62 after parameter update : tensor([2.0169, 3.5436], requires_grad=True), required_grad : True\n",
      "epoch 63 loss is 3.603933811187744\n",
      "epoch 63 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 63 : params.grad right after loss.backward(): tensor([-1.1330, -2.7978])\n",
      "epoch 63 after parameter update : tensor([2.0283, 3.5716], requires_grad=True), required_grad : True\n",
      "epoch 64 loss is 3.5136587619781494\n",
      "epoch 64 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 64 : params.grad right after loss.backward(): tensor([-1.1204, -2.7431])\n",
      "epoch 64 after parameter update : tensor([2.0395, 3.5990], requires_grad=True), required_grad : True\n",
      "epoch 65 loss is 3.4266631603240967\n",
      "epoch 65 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 65 : params.grad right after loss.backward(): tensor([-1.1079, -2.6895])\n",
      "epoch 65 after parameter update : tensor([2.0505, 3.6259], requires_grad=True), required_grad : True\n",
      "epoch 66 loss is 3.3428311347961426\n",
      "epoch 66 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 66 : params.grad right after loss.backward(): tensor([-1.0955, -2.6370])\n",
      "epoch 66 after parameter update : tensor([2.0615, 3.6523], requires_grad=True), required_grad : True\n",
      "epoch 67 loss is 3.262037992477417\n",
      "epoch 67 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 67 : params.grad right after loss.backward(): tensor([-1.0833, -2.5855])\n",
      "epoch 67 after parameter update : tensor([2.0723, 3.6781], requires_grad=True), required_grad : True\n",
      "epoch 68 loss is 3.184175491333008\n",
      "epoch 68 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 68 : params.grad right after loss.backward(): tensor([-1.0711, -2.5350])\n",
      "epoch 68 after parameter update : tensor([2.0830, 3.7035], requires_grad=True), required_grad : True\n",
      "epoch 69 loss is 3.109130859375\n",
      "epoch 69 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 69 : params.grad right after loss.backward(): tensor([-1.0591, -2.4855])\n",
      "epoch 69 after parameter update : tensor([2.0936, 3.7283], requires_grad=True), required_grad : True\n",
      "epoch 70 loss is 3.0368010997772217\n",
      "epoch 70 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 70 : params.grad right after loss.backward(): tensor([-1.0472, -2.4370])\n",
      "epoch 70 after parameter update : tensor([2.1041, 3.7527], requires_grad=True), required_grad : True\n",
      "epoch 71 loss is 2.967087745666504\n",
      "epoch 71 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 71 : params.grad right after loss.backward(): tensor([-1.0353, -2.3895])\n",
      "epoch 71 after parameter update : tensor([2.1145, 3.7766], requires_grad=True), required_grad : True\n",
      "epoch 72 loss is 2.899890184402466\n",
      "epoch 72 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 72 : params.grad right after loss.backward(): tensor([-1.0236, -2.3429])\n",
      "epoch 72 after parameter update : tensor([2.1247, 3.8000], requires_grad=True), required_grad : True\n",
      "epoch 73 loss is 2.8351168632507324\n",
      "epoch 73 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 73 : params.grad right after loss.backward(): tensor([-1.0120, -2.2972])\n",
      "epoch 73 after parameter update : tensor([2.1348, 3.8230], requires_grad=True), required_grad : True\n",
      "epoch 74 loss is 2.7726786136627197\n",
      "epoch 74 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 74 : params.grad right after loss.backward(): tensor([-1.0006, -2.2524])\n",
      "epoch 74 after parameter update : tensor([2.1448, 3.8455], requires_grad=True), required_grad : True\n",
      "epoch 75 loss is 2.71248722076416\n",
      "epoch 75 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 75 : params.grad right after loss.backward(): tensor([-0.9892, -2.2085])\n",
      "epoch 75 after parameter update : tensor([2.1547, 3.8676], requires_grad=True), required_grad : True\n",
      "epoch 76 loss is 2.6544606685638428\n",
      "epoch 76 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 76 : params.grad right after loss.backward(): tensor([-0.9779, -2.1654])\n",
      "epoch 76 after parameter update : tensor([2.1645, 3.8893], requires_grad=True), required_grad : True\n",
      "epoch 77 loss is 2.5985186100006104\n",
      "epoch 77 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 77 : params.grad right after loss.backward(): tensor([-0.9667, -2.1232])\n",
      "epoch 77 after parameter update : tensor([2.1742, 3.9105], requires_grad=True), required_grad : True\n",
      "epoch 78 loss is 2.5445854663848877\n",
      "epoch 78 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 78 : params.grad right after loss.backward(): tensor([-0.9557, -2.0819])\n",
      "epoch 78 after parameter update : tensor([2.1837, 3.9313], requires_grad=True), required_grad : True\n",
      "epoch 79 loss is 2.4925851821899414\n",
      "epoch 79 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 79 : params.grad right after loss.backward(): tensor([-0.9447, -2.0413])\n",
      "epoch 79 after parameter update : tensor([2.1932, 3.9517], requires_grad=True), required_grad : True\n",
      "epoch 80 loss is 2.4424469470977783\n",
      "epoch 80 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 80 : params.grad right after loss.backward(): tensor([-0.9339, -2.0016])\n",
      "epoch 80 after parameter update : tensor([2.2025, 3.9718], requires_grad=True), required_grad : True\n",
      "epoch 81 loss is 2.3941023349761963\n",
      "epoch 81 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 81 : params.grad right after loss.backward(): tensor([-0.9232, -1.9626])\n",
      "epoch 81 after parameter update : tensor([2.2117, 3.9914], requires_grad=True), required_grad : True\n",
      "epoch 82 loss is 2.3474864959716797\n",
      "epoch 82 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 82 : params.grad right after loss.backward(): tensor([-0.9125, -1.9244])\n",
      "epoch 82 after parameter update : tensor([2.2209, 4.0106], requires_grad=True), required_grad : True\n",
      "epoch 83 loss is 2.302535057067871\n",
      "epoch 83 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 83 : params.grad right after loss.backward(): tensor([-0.9020, -1.8869])\n",
      "epoch 83 after parameter update : tensor([2.2299, 4.0295], requires_grad=True), required_grad : True\n",
      "epoch 84 loss is 2.2591865062713623\n",
      "epoch 84 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 84 : params.grad right after loss.backward(): tensor([-0.8916, -1.8502])\n",
      "epoch 84 after parameter update : tensor([2.2388, 4.0480], requires_grad=True), required_grad : True\n",
      "epoch 85 loss is 2.2173826694488525\n",
      "epoch 85 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 85 : params.grad right after loss.backward(): tensor([-0.8813, -1.8142])\n",
      "epoch 85 after parameter update : tensor([2.2476, 4.0661], requires_grad=True), required_grad : True\n",
      "epoch 86 loss is 2.1770660877227783\n",
      "epoch 86 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 86 : params.grad right after loss.backward(): tensor([-0.8711, -1.7789])\n",
      "epoch 86 after parameter update : tensor([2.2563, 4.0839], requires_grad=True), required_grad : True\n",
      "epoch 87 loss is 2.1381843090057373\n",
      "epoch 87 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 87 : params.grad right after loss.backward(): tensor([-0.8610, -1.7444])\n",
      "epoch 87 after parameter update : tensor([2.2649, 4.1014], requires_grad=True), required_grad : True\n",
      "epoch 88 loss is 2.1006836891174316\n",
      "epoch 88 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 88 : params.grad right after loss.backward(): tensor([-0.8509, -1.7105])\n",
      "epoch 88 after parameter update : tensor([2.2734, 4.1185], requires_grad=True), required_grad : True\n",
      "epoch 89 loss is 2.064511299133301\n",
      "epoch 89 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 89 : params.grad right after loss.backward(): tensor([-0.8410, -1.6772])\n",
      "epoch 89 after parameter update : tensor([2.2818, 4.1352], requires_grad=True), required_grad : True\n",
      "epoch 90 loss is 2.0296216011047363\n",
      "epoch 90 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 90 : params.grad right after loss.backward(): tensor([-0.8312, -1.6446])\n",
      "epoch 90 after parameter update : tensor([2.2902, 4.1517], requires_grad=True), required_grad : True\n",
      "epoch 91 loss is 1.9959678649902344\n",
      "epoch 91 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 91 : params.grad right after loss.backward(): tensor([-0.8215, -1.6127])\n",
      "epoch 91 after parameter update : tensor([2.2984, 4.1678], requires_grad=True), required_grad : True\n",
      "epoch 92 loss is 1.9635043144226074\n",
      "epoch 92 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 92 : params.grad right after loss.backward(): tensor([-0.8119, -1.5814])\n",
      "epoch 92 after parameter update : tensor([2.3065, 4.1836], requires_grad=True), required_grad : True\n",
      "epoch 93 loss is 1.9321870803833008\n",
      "epoch 93 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 93 : params.grad right after loss.backward(): tensor([-0.8024, -1.5507])\n",
      "epoch 93 after parameter update : tensor([2.3145, 4.1991], requires_grad=True), required_grad : True\n",
      "epoch 94 loss is 1.9019744396209717\n",
      "epoch 94 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 94 : params.grad right after loss.backward(): tensor([-0.7930, -1.5206])\n",
      "epoch 94 after parameter update : tensor([2.3224, 4.2143], requires_grad=True), required_grad : True\n",
      "epoch 95 loss is 1.8728265762329102\n",
      "epoch 95 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 95 : params.grad right after loss.backward(): tensor([-0.7837, -1.4910])\n",
      "epoch 95 after parameter update : tensor([2.3303, 4.2293], requires_grad=True), required_grad : True\n",
      "epoch 96 loss is 1.8447052240371704\n",
      "epoch 96 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 96 : params.grad right after loss.backward(): tensor([-0.7744, -1.4621])\n",
      "epoch 96 after parameter update : tensor([2.3380, 4.2439], requires_grad=True), required_grad : True\n",
      "epoch 97 loss is 1.8175721168518066\n",
      "epoch 97 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 97 : params.grad right after loss.backward(): tensor([-0.7653, -1.4338])\n",
      "epoch 97 after parameter update : tensor([2.3457, 4.2582], requires_grad=True), required_grad : True\n",
      "epoch 98 loss is 1.7913923263549805\n",
      "epoch 98 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 98 : params.grad right after loss.backward(): tensor([-0.7563, -1.4060])\n",
      "epoch 98 after parameter update : tensor([2.3532, 4.2723], requires_grad=True), required_grad : True\n",
      "epoch 99 loss is 1.7661312818527222\n",
      "epoch 99 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 99 : params.grad right after loss.backward(): tensor([-0.7473, -1.3787])\n",
      "epoch 99 after parameter update : tensor([2.3607, 4.2861], requires_grad=True), required_grad : True\n",
      "epoch 100 loss is 1.7417558431625366\n",
      "epoch 100 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 100 : params.grad right after loss.backward(): tensor([-0.7385, -1.3520])\n",
      "epoch 100 after parameter update : tensor([2.3681, 4.2996], requires_grad=True), required_grad : True\n",
      "epoch 101 loss is 1.7182323932647705\n",
      "epoch 101 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 101 : params.grad right after loss.backward(): tensor([-0.7298, -1.3258])\n",
      "epoch 101 after parameter update : tensor([2.3754, 4.3128], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 102 loss is 1.6955331563949585\n",
      "epoch 102 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 102 : params.grad right after loss.backward(): tensor([-0.7211, -1.3001])\n",
      "epoch 102 after parameter update : tensor([2.3826, 4.3258], requires_grad=True), required_grad : True\n",
      "epoch 103 loss is 1.6736245155334473\n",
      "epoch 103 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 103 : params.grad right after loss.backward(): tensor([-0.7125, -1.2749])\n",
      "epoch 103 after parameter update : tensor([2.3897, 4.3386], requires_grad=True), required_grad : True\n",
      "epoch 104 loss is 1.6524816751480103\n",
      "epoch 104 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 104 : params.grad right after loss.backward(): tensor([-0.7041, -1.2502])\n",
      "epoch 104 after parameter update : tensor([2.3968, 4.3511], requires_grad=True), required_grad : True\n",
      "epoch 105 loss is 1.632075309753418\n",
      "epoch 105 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 105 : params.grad right after loss.backward(): tensor([-0.6957, -1.2260])\n",
      "epoch 105 after parameter update : tensor([2.4037, 4.3634], requires_grad=True), required_grad : True\n",
      "epoch 106 loss is 1.6123793125152588\n",
      "epoch 106 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 106 : params.grad right after loss.backward(): tensor([-0.6874, -1.2023])\n",
      "epoch 106 after parameter update : tensor([2.4106, 4.3754], requires_grad=True), required_grad : True\n",
      "epoch 107 loss is 1.5933674573898315\n",
      "epoch 107 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 107 : params.grad right after loss.backward(): tensor([-0.6792, -1.1790])\n",
      "epoch 107 after parameter update : tensor([2.4174, 4.3872], requires_grad=True), required_grad : True\n",
      "epoch 108 loss is 1.5750160217285156\n",
      "epoch 108 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 108 : params.grad right after loss.backward(): tensor([-0.6710, -1.1562])\n",
      "epoch 108 after parameter update : tensor([2.4241, 4.3987], requires_grad=True), required_grad : True\n",
      "epoch 109 loss is 1.5573012828826904\n",
      "epoch 109 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 109 : params.grad right after loss.backward(): tensor([-0.6630, -1.1338])\n",
      "epoch 109 after parameter update : tensor([2.4307, 4.4101], requires_grad=True), required_grad : True\n",
      "epoch 110 loss is 1.5402002334594727\n",
      "epoch 110 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 110 : params.grad right after loss.backward(): tensor([-0.6551, -1.1119])\n",
      "epoch 110 after parameter update : tensor([2.4373, 4.4212], requires_grad=True), required_grad : True\n",
      "epoch 111 loss is 1.5236902236938477\n",
      "epoch 111 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 111 : params.grad right after loss.backward(): tensor([-0.6472, -1.0904])\n",
      "epoch 111 after parameter update : tensor([2.4438, 4.4321], requires_grad=True), required_grad : True\n",
      "epoch 112 loss is 1.5077511072158813\n",
      "epoch 112 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 112 : params.grad right after loss.backward(): tensor([-0.6394, -1.0694])\n",
      "epoch 112 after parameter update : tensor([2.4502, 4.4428], requires_grad=True), required_grad : True\n",
      "epoch 113 loss is 1.4923628568649292\n",
      "epoch 113 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 113 : params.grad right after loss.backward(): tensor([-0.6317, -1.0487])\n",
      "epoch 113 after parameter update : tensor([2.4565, 4.4533], requires_grad=True), required_grad : True\n",
      "epoch 114 loss is 1.477504014968872\n",
      "epoch 114 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 114 : params.grad right after loss.backward(): tensor([-0.6241, -1.0284])\n",
      "epoch 114 after parameter update : tensor([2.4627, 4.4636], requires_grad=True), required_grad : True\n",
      "epoch 115 loss is 1.463157296180725\n",
      "epoch 115 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 115 : params.grad right after loss.backward(): tensor([-0.6166, -1.0086])\n",
      "epoch 115 after parameter update : tensor([2.4689, 4.4736], requires_grad=True), required_grad : True\n",
      "epoch 116 loss is 1.4493037462234497\n",
      "epoch 116 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 116 : params.grad right after loss.backward(): tensor([-0.6092, -0.9891])\n",
      "epoch 116 after parameter update : tensor([2.4750, 4.4835], requires_grad=True), required_grad : True\n",
      "epoch 117 loss is 1.4359265565872192\n",
      "epoch 117 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 117 : params.grad right after loss.backward(): tensor([-0.6018, -0.9700])\n",
      "epoch 117 after parameter update : tensor([2.4810, 4.4932], requires_grad=True), required_grad : True\n",
      "epoch 118 loss is 1.4230079650878906\n",
      "epoch 118 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 118 : params.grad right after loss.backward(): tensor([-0.5945, -0.9513])\n",
      "epoch 118 after parameter update : tensor([2.4869, 4.5027], requires_grad=True), required_grad : True\n",
      "epoch 119 loss is 1.410532832145691\n",
      "epoch 119 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 119 : params.grad right after loss.backward(): tensor([-0.5873, -0.9330])\n",
      "epoch 119 after parameter update : tensor([2.4928, 4.5121], requires_grad=True), required_grad : True\n",
      "epoch 120 loss is 1.3984837532043457\n",
      "epoch 120 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 120 : params.grad right after loss.backward(): tensor([-0.5802, -0.9150])\n",
      "epoch 120 after parameter update : tensor([2.4986, 4.5212], requires_grad=True), required_grad : True\n",
      "epoch 121 loss is 1.3868474960327148\n",
      "epoch 121 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 121 : params.grad right after loss.backward(): tensor([-0.5731, -0.8973])\n",
      "epoch 121 after parameter update : tensor([2.5043, 4.5302], requires_grad=True), required_grad : True\n",
      "epoch 122 loss is 1.3756076097488403\n",
      "epoch 122 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 122 : params.grad right after loss.backward(): tensor([-0.5662, -0.8800])\n",
      "epoch 122 after parameter update : tensor([2.5100, 4.5390], requires_grad=True), required_grad : True\n",
      "epoch 123 loss is 1.3647516965866089\n",
      "epoch 123 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 123 : params.grad right after loss.backward(): tensor([-0.5593, -0.8631])\n",
      "epoch 123 after parameter update : tensor([2.5156, 4.5476], requires_grad=True), required_grad : True\n",
      "epoch 124 loss is 1.3542653322219849\n",
      "epoch 124 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 124 : params.grad right after loss.backward(): tensor([-0.5525, -0.8465])\n",
      "epoch 124 after parameter update : tensor([2.5211, 4.5561], requires_grad=True), required_grad : True\n",
      "epoch 125 loss is 1.3441357612609863\n",
      "epoch 125 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 125 : params.grad right after loss.backward(): tensor([-0.5458, -0.8302])\n",
      "epoch 125 after parameter update : tensor([2.5266, 4.5644], requires_grad=True), required_grad : True\n",
      "epoch 126 loss is 1.3343502283096313\n",
      "epoch 126 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 126 : params.grad right after loss.backward(): tensor([-0.5391, -0.8142])\n",
      "epoch 126 after parameter update : tensor([2.5320, 4.5725], requires_grad=True), required_grad : True\n",
      "epoch 127 loss is 1.3248968124389648\n",
      "epoch 127 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 127 : params.grad right after loss.backward(): tensor([-0.5325, -0.7985])\n",
      "epoch 127 after parameter update : tensor([2.5373, 4.5805], requires_grad=True), required_grad : True\n",
      "epoch 128 loss is 1.3157637119293213\n",
      "epoch 128 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 128 : params.grad right after loss.backward(): tensor([-0.5260, -0.7831])\n",
      "epoch 128 after parameter update : tensor([2.5426, 4.5884], requires_grad=True), required_grad : True\n",
      "epoch 129 loss is 1.3069396018981934\n",
      "epoch 129 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 129 : params.grad right after loss.backward(): tensor([-0.5196, -0.7681])\n",
      "epoch 129 after parameter update : tensor([2.5478, 4.5960], requires_grad=True), required_grad : True\n",
      "epoch 130 loss is 1.298413872718811\n",
      "epoch 130 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 130 : params.grad right after loss.backward(): tensor([-0.5132, -0.7533])\n",
      "epoch 130 after parameter update : tensor([2.5529, 4.6036], requires_grad=True), required_grad : True\n",
      "epoch 131 loss is 1.290176272392273\n",
      "epoch 131 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 131 : params.grad right after loss.backward(): tensor([-0.5069, -0.7388])\n",
      "epoch 131 after parameter update : tensor([2.5580, 4.6110], requires_grad=True), required_grad : True\n",
      "epoch 132 loss is 1.2822163105010986\n",
      "epoch 132 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 132 : params.grad right after loss.backward(): tensor([-0.5007, -0.7246])\n",
      "epoch 132 after parameter update : tensor([2.5630, 4.6182], requires_grad=True), required_grad : True\n",
      "epoch 133 loss is 1.2745248079299927\n",
      "epoch 133 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 133 : params.grad right after loss.backward(): tensor([-0.4945, -0.7107])\n",
      "epoch 133 after parameter update : tensor([2.5679, 4.6253], requires_grad=True), required_grad : True\n",
      "epoch 134 loss is 1.2670921087265015\n",
      "epoch 134 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 134 : params.grad right after loss.backward(): tensor([-0.4885, -0.6970])\n",
      "epoch 134 after parameter update : tensor([2.5728, 4.6323], requires_grad=True), required_grad : True\n",
      "epoch 135 loss is 1.2599087953567505\n",
      "epoch 135 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 135 : params.grad right after loss.backward(): tensor([-0.4824, -0.6837])\n",
      "epoch 135 after parameter update : tensor([2.5776, 4.6391], requires_grad=True), required_grad : True\n",
      "epoch 136 loss is 1.2529667615890503\n",
      "epoch 136 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 136 : params.grad right after loss.backward(): tensor([-0.4765, -0.6705])\n",
      "epoch 136 after parameter update : tensor([2.5824, 4.6458], requires_grad=True), required_grad : True\n",
      "epoch 137 loss is 1.2462574243545532\n",
      "epoch 137 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 137 : params.grad right after loss.backward(): tensor([-0.4706, -0.6577])\n",
      "epoch 137 after parameter update : tensor([2.5871, 4.6524], requires_grad=True), required_grad : True\n",
      "epoch 138 loss is 1.2397724390029907\n",
      "epoch 138 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 138 : params.grad right after loss.backward(): tensor([-0.4648, -0.6450])\n",
      "epoch 138 after parameter update : tensor([2.5917, 4.6588], requires_grad=True), required_grad : True\n",
      "epoch 139 loss is 1.233504056930542\n",
      "epoch 139 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 139 : params.grad right after loss.backward(): tensor([-0.4591, -0.6327])\n",
      "epoch 139 after parameter update : tensor([2.5963, 4.6652], requires_grad=True), required_grad : True\n",
      "epoch 140 loss is 1.2274452447891235\n",
      "epoch 140 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 140 : params.grad right after loss.backward(): tensor([-0.4534, -0.6205])\n",
      "epoch 140 after parameter update : tensor([2.6009, 4.6714], requires_grad=True), required_grad : True\n",
      "epoch 141 loss is 1.2215884923934937\n",
      "epoch 141 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 141 : params.grad right after loss.backward(): tensor([-0.4478, -0.6087])\n",
      "epoch 141 after parameter update : tensor([2.6053, 4.6775], requires_grad=True), required_grad : True\n",
      "epoch 142 loss is 1.215927004814148\n",
      "epoch 142 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 142 : params.grad right after loss.backward(): tensor([-0.4422, -0.5970])\n",
      "epoch 142 after parameter update : tensor([2.6098, 4.6834], requires_grad=True), required_grad : True\n",
      "epoch 143 loss is 1.2104535102844238\n",
      "epoch 143 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 143 : params.grad right after loss.backward(): tensor([-0.4368, -0.5855])\n",
      "epoch 143 after parameter update : tensor([2.6141, 4.6893], requires_grad=True), required_grad : True\n",
      "epoch 144 loss is 1.205161690711975\n",
      "epoch 144 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 144 : params.grad right after loss.backward(): tensor([-0.4313, -0.5743])\n",
      "epoch 144 after parameter update : tensor([2.6184, 4.6950], requires_grad=True), required_grad : True\n",
      "epoch 145 loss is 1.2000458240509033\n",
      "epoch 145 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 145 : params.grad right after loss.backward(): tensor([-0.4260, -0.5633])\n",
      "epoch 145 after parameter update : tensor([2.6227, 4.7007], requires_grad=True), required_grad : True\n",
      "epoch 146 loss is 1.195098876953125\n",
      "epoch 146 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 146 : params.grad right after loss.backward(): tensor([-0.4207, -0.5526])\n",
      "epoch 146 after parameter update : tensor([2.6269, 4.7062], requires_grad=True), required_grad : True\n",
      "epoch 147 loss is 1.1903164386749268\n",
      "epoch 147 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 147 : params.grad right after loss.backward(): tensor([-0.4155, -0.5420])\n",
      "epoch 147 after parameter update : tensor([2.6311, 4.7116], requires_grad=True), required_grad : True\n",
      "epoch 148 loss is 1.1856919527053833\n",
      "epoch 148 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 148 : params.grad right after loss.backward(): tensor([-0.4103, -0.5316])\n",
      "epoch 148 after parameter update : tensor([2.6352, 4.7169], requires_grad=True), required_grad : True\n",
      "epoch 149 loss is 1.181220293045044\n",
      "epoch 149 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 149 : params.grad right after loss.backward(): tensor([-0.4052, -0.5215])\n",
      "epoch 149 after parameter update : tensor([2.6392, 4.7221], requires_grad=True), required_grad : True\n",
      "epoch 150 loss is 1.176895260810852\n",
      "epoch 150 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 150 : params.grad right after loss.backward(): tensor([-0.4001, -0.5115])\n",
      "epoch 150 after parameter update : tensor([2.6432, 4.7273], requires_grad=True), required_grad : True\n",
      "epoch 151 loss is 1.172712802886963\n",
      "epoch 151 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 151 : params.grad right after loss.backward(): tensor([-0.3951, -0.5017])\n",
      "epoch 151 after parameter update : tensor([2.6472, 4.7323], requires_grad=True), required_grad : True\n",
      "epoch 152 loss is 1.1686683893203735\n",
      "epoch 152 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 152 : params.grad right after loss.backward(): tensor([-0.3902, -0.4921])\n",
      "epoch 152 after parameter update : tensor([2.6511, 4.7372], requires_grad=True), required_grad : True\n",
      "epoch 153 loss is 1.1647565364837646\n",
      "epoch 153 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 153 : params.grad right after loss.backward(): tensor([-0.3853, -0.4827])\n",
      "epoch 153 after parameter update : tensor([2.6549, 4.7420], requires_grad=True), required_grad : True\n",
      "epoch 154 loss is 1.160973310470581\n",
      "epoch 154 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 154 : params.grad right after loss.backward(): tensor([-0.3805, -0.4735])\n",
      "epoch 154 after parameter update : tensor([2.6587, 4.7468], requires_grad=True), required_grad : True\n",
      "epoch 155 loss is 1.1573137044906616\n",
      "epoch 155 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 155 : params.grad right after loss.backward(): tensor([-0.3757, -0.4645])\n",
      "epoch 155 after parameter update : tensor([2.6625, 4.7514], requires_grad=True), required_grad : True\n",
      "epoch 156 loss is 1.1537739038467407\n",
      "epoch 156 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 156 : params.grad right after loss.backward(): tensor([-0.3710, -0.4556])\n",
      "epoch 156 after parameter update : tensor([2.6662, 4.7560], requires_grad=True), required_grad : True\n",
      "epoch 157 loss is 1.1503500938415527\n",
      "epoch 157 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 157 : params.grad right after loss.backward(): tensor([-0.3664, -0.4469])\n",
      "epoch 157 after parameter update : tensor([2.6699, 4.7604], requires_grad=True), required_grad : True\n",
      "epoch 158 loss is 1.1470377445220947\n",
      "epoch 158 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 158 : params.grad right after loss.backward(): tensor([-0.3618, -0.4384])\n",
      "epoch 158 after parameter update : tensor([2.6735, 4.7648], requires_grad=True), required_grad : True\n",
      "epoch 159 loss is 1.143833041191101\n",
      "epoch 159 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 159 : params.grad right after loss.backward(): tensor([-0.3572, -0.4300])\n",
      "epoch 159 after parameter update : tensor([2.6770, 4.7691], requires_grad=True), required_grad : True\n",
      "epoch 160 loss is 1.1407338380813599\n",
      "epoch 160 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 160 : params.grad right after loss.backward(): tensor([-0.3528, -0.4218])\n",
      "epoch 160 after parameter update : tensor([2.6806, 4.7733], requires_grad=True), required_grad : True\n",
      "epoch 161 loss is 1.1377344131469727\n",
      "epoch 161 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 161 : params.grad right after loss.backward(): tensor([-0.3483, -0.4138])\n",
      "epoch 161 after parameter update : tensor([2.6841, 4.7775], requires_grad=True), required_grad : True\n",
      "epoch 162 loss is 1.134832501411438\n",
      "epoch 162 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 162 : params.grad right after loss.backward(): tensor([-0.3439, -0.4059])\n",
      "epoch 162 after parameter update : tensor([2.6875, 4.7815], requires_grad=True), required_grad : True\n",
      "epoch 163 loss is 1.132025122642517\n",
      "epoch 163 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 163 : params.grad right after loss.backward(): tensor([-0.3396, -0.3982])\n",
      "epoch 163 after parameter update : tensor([2.6909, 4.7855], requires_grad=True), required_grad : True\n",
      "epoch 164 loss is 1.1293081045150757\n",
      "epoch 164 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 164 : params.grad right after loss.backward(): tensor([-0.3353, -0.3906])\n",
      "epoch 164 after parameter update : tensor([2.6942, 4.7894], requires_grad=True), required_grad : True\n",
      "epoch 165 loss is 1.1266798973083496\n",
      "epoch 165 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 165 : params.grad right after loss.backward(): tensor([-0.3311, -0.3832])\n",
      "epoch 165 after parameter update : tensor([2.6976, 4.7933], requires_grad=True), required_grad : True\n",
      "epoch 166 loss is 1.124135971069336\n",
      "epoch 166 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 166 : params.grad right after loss.backward(): tensor([-0.3269, -0.3759])\n",
      "epoch 166 after parameter update : tensor([2.7008, 4.7970], requires_grad=True), required_grad : True\n",
      "epoch 167 loss is 1.1216740608215332\n",
      "epoch 167 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 167 : params.grad right after loss.backward(): tensor([-0.3228, -0.3688])\n",
      "epoch 167 after parameter update : tensor([2.7041, 4.8007], requires_grad=True), required_grad : True\n",
      "epoch 168 loss is 1.1192917823791504\n",
      "epoch 168 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 168 : params.grad right after loss.backward(): tensor([-0.3187, -0.3618])\n",
      "epoch 168 after parameter update : tensor([2.7072, 4.8043], requires_grad=True), required_grad : True\n",
      "epoch 169 loss is 1.1169863939285278\n",
      "epoch 169 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 169 : params.grad right after loss.backward(): tensor([-0.3147, -0.3549])\n",
      "epoch 169 after parameter update : tensor([2.7104, 4.8079], requires_grad=True), required_grad : True\n",
      "epoch 170 loss is 1.1147550344467163\n",
      "epoch 170 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 170 : params.grad right after loss.backward(): tensor([-0.3107, -0.3481])\n",
      "epoch 170 after parameter update : tensor([2.7135, 4.8113], requires_grad=True), required_grad : True\n",
      "epoch 171 loss is 1.1125954389572144\n",
      "epoch 171 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 171 : params.grad right after loss.backward(): tensor([-0.3068, -0.3415])\n",
      "epoch 171 after parameter update : tensor([2.7166, 4.8148], requires_grad=True), required_grad : True\n",
      "epoch 172 loss is 1.1105047464370728\n",
      "epoch 172 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 172 : params.grad right after loss.backward(): tensor([-0.3029, -0.3351])\n",
      "epoch 172 after parameter update : tensor([2.7196, 4.8181], requires_grad=True), required_grad : True\n",
      "epoch 173 loss is 1.1084814071655273\n",
      "epoch 173 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 173 : params.grad right after loss.backward(): tensor([-0.2991, -0.3287])\n",
      "epoch 173 after parameter update : tensor([2.7226, 4.8214], requires_grad=True), required_grad : True\n",
      "epoch 174 loss is 1.106522560119629\n",
      "epoch 174 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 174 : params.grad right after loss.backward(): tensor([-0.2953, -0.3225])\n",
      "epoch 174 after parameter update : tensor([2.7255, 4.8246], requires_grad=True), required_grad : True\n",
      "epoch 175 loss is 1.104626178741455\n",
      "epoch 175 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 175 : params.grad right after loss.backward(): tensor([-0.2915, -0.3163])\n",
      "epoch 175 after parameter update : tensor([2.7285, 4.8278], requires_grad=True), required_grad : True\n",
      "epoch 176 loss is 1.1027907133102417\n",
      "epoch 176 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 176 : params.grad right after loss.backward(): tensor([-0.2878, -0.3104])\n",
      "epoch 176 after parameter update : tensor([2.7313, 4.8309], requires_grad=True), required_grad : True\n",
      "epoch 177 loss is 1.1010133028030396\n",
      "epoch 177 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 177 : params.grad right after loss.backward(): tensor([-0.2842, -0.3045])\n",
      "epoch 177 after parameter update : tensor([2.7342, 4.8339], requires_grad=True), required_grad : True\n",
      "epoch 178 loss is 1.0992928743362427\n",
      "epoch 178 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 178 : params.grad right after loss.backward(): tensor([-0.2805, -0.2987])\n",
      "epoch 178 after parameter update : tensor([2.7370, 4.8369], requires_grad=True), required_grad : True\n",
      "epoch 179 loss is 1.0976269245147705\n",
      "epoch 179 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 179 : params.grad right after loss.backward(): tensor([-0.2770, -0.2931])\n",
      "epoch 179 after parameter update : tensor([2.7397, 4.8399], requires_grad=True), required_grad : True\n",
      "epoch 180 loss is 1.096014142036438\n",
      "epoch 180 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 180 : params.grad right after loss.backward(): tensor([-0.2735, -0.2875])\n",
      "epoch 180 after parameter update : tensor([2.7425, 4.8427], requires_grad=True), required_grad : True\n",
      "epoch 181 loss is 1.0944522619247437\n",
      "epoch 181 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 181 : params.grad right after loss.backward(): tensor([-0.2700, -0.2821])\n",
      "epoch 181 after parameter update : tensor([2.7452, 4.8455], requires_grad=True), required_grad : True\n",
      "epoch 182 loss is 1.092940092086792\n",
      "epoch 182 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 182 : params.grad right after loss.backward(): tensor([-0.2665, -0.2767])\n",
      "epoch 182 after parameter update : tensor([2.7478, 4.8483], requires_grad=True), required_grad : True\n",
      "epoch 183 loss is 1.0914753675460815\n",
      "epoch 183 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 183 : params.grad right after loss.backward(): tensor([-0.2631, -0.2715])\n",
      "epoch 183 after parameter update : tensor([2.7505, 4.8510], requires_grad=True), required_grad : True\n",
      "epoch 184 loss is 1.090057373046875\n",
      "epoch 184 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 184 : params.grad right after loss.backward(): tensor([-0.2598, -0.2664])\n",
      "epoch 184 after parameter update : tensor([2.7531, 4.8537], requires_grad=True), required_grad : True\n",
      "epoch 185 loss is 1.0886844396591187\n",
      "epoch 185 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 185 : params.grad right after loss.backward(): tensor([-0.2565, -0.2613])\n",
      "epoch 185 after parameter update : tensor([2.7556, 4.8563], requires_grad=True), required_grad : True\n",
      "epoch 186 loss is 1.0873539447784424\n",
      "epoch 186 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 186 : params.grad right after loss.backward(): tensor([-0.2532, -0.2564])\n",
      "epoch 186 after parameter update : tensor([2.7582, 4.8589], requires_grad=True), required_grad : True\n",
      "epoch 187 loss is 1.086065649986267\n",
      "epoch 187 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 187 : params.grad right after loss.backward(): tensor([-0.2499, -0.2516])\n",
      "epoch 187 after parameter update : tensor([2.7607, 4.8614], requires_grad=True), required_grad : True\n",
      "epoch 188 loss is 1.084817886352539\n",
      "epoch 188 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 188 : params.grad right after loss.backward(): tensor([-0.2468, -0.2468])\n",
      "epoch 188 after parameter update : tensor([2.7631, 4.8639], requires_grad=True), required_grad : True\n",
      "epoch 189 loss is 1.0836102962493896\n",
      "epoch 189 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 189 : params.grad right after loss.backward(): tensor([-0.2436, -0.2422])\n",
      "epoch 189 after parameter update : tensor([2.7656, 4.8663], requires_grad=True), required_grad : True\n",
      "epoch 190 loss is 1.0824390649795532\n",
      "epoch 190 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 190 : params.grad right after loss.backward(): tensor([-0.2405, -0.2376])\n",
      "epoch 190 after parameter update : tensor([2.7680, 4.8687], requires_grad=True), required_grad : True\n",
      "epoch 191 loss is 1.0813055038452148\n",
      "epoch 191 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 191 : params.grad right after loss.backward(): tensor([-0.2374, -0.2331])\n",
      "epoch 191 after parameter update : tensor([2.7704, 4.8710], requires_grad=True), required_grad : True\n",
      "epoch 192 loss is 1.080207347869873\n",
      "epoch 192 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 192 : params.grad right after loss.backward(): tensor([-0.2344, -0.2287])\n",
      "epoch 192 after parameter update : tensor([2.7727, 4.8733], requires_grad=True), required_grad : True\n",
      "epoch 193 loss is 1.0791434049606323\n",
      "epoch 193 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 193 : params.grad right after loss.backward(): tensor([-0.2313, -0.2244])\n",
      "epoch 193 after parameter update : tensor([2.7750, 4.8755], requires_grad=True), required_grad : True\n",
      "epoch 194 loss is 1.078113079071045\n",
      "epoch 194 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 194 : params.grad right after loss.backward(): tensor([-0.2284, -0.2202])\n",
      "epoch 194 after parameter update : tensor([2.7773, 4.8777], requires_grad=True), required_grad : True\n",
      "epoch 195 loss is 1.0771148204803467\n",
      "epoch 195 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 195 : params.grad right after loss.backward(): tensor([-0.2254, -0.2160])\n",
      "epoch 195 after parameter update : tensor([2.7795, 4.8799], requires_grad=True), required_grad : True\n",
      "epoch 196 loss is 1.0761466026306152\n",
      "epoch 196 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 196 : params.grad right after loss.backward(): tensor([-0.2226, -0.2120])\n",
      "epoch 196 after parameter update : tensor([2.7818, 4.8820], requires_grad=True), required_grad : True\n",
      "epoch 197 loss is 1.075209617614746\n",
      "epoch 197 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 197 : params.grad right after loss.backward(): tensor([-0.2197, -0.2080])\n",
      "epoch 197 after parameter update : tensor([2.7840, 4.8841], requires_grad=True), required_grad : True\n",
      "epoch 198 loss is 1.0743017196655273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 198 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 198 : params.grad right after loss.backward(): tensor([-0.2169, -0.2041])\n",
      "epoch 198 after parameter update : tensor([2.7861, 4.8861], requires_grad=True), required_grad : True\n",
      "epoch 199 loss is 1.0734214782714844\n",
      "epoch 199 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 199 : params.grad right after loss.backward(): tensor([-0.2141, -0.2002])\n",
      "epoch 199 after parameter update : tensor([2.7883, 4.8881], requires_grad=True), required_grad : True\n",
      "epoch 200 loss is 1.0725690126419067\n",
      "epoch 200 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 200 : params.grad right after loss.backward(): tensor([-0.2113, -0.1965])\n",
      "epoch 200 after parameter update : tensor([2.7904, 4.8901], requires_grad=True), required_grad : True\n",
      "epoch 201 loss is 1.0717427730560303\n",
      "epoch 201 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 201 : params.grad right after loss.backward(): tensor([-0.2086, -0.1928])\n",
      "epoch 201 after parameter update : tensor([2.7925, 4.8920], requires_grad=True), required_grad : True\n",
      "epoch 202 loss is 1.0709422826766968\n",
      "epoch 202 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 202 : params.grad right after loss.backward(): tensor([-0.2059, -0.1892])\n",
      "epoch 202 after parameter update : tensor([2.7945, 4.8939], requires_grad=True), required_grad : True\n",
      "epoch 203 loss is 1.0701663494110107\n",
      "epoch 203 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 203 : params.grad right after loss.backward(): tensor([-0.2033, -0.1856])\n",
      "epoch 203 after parameter update : tensor([2.7966, 4.8958], requires_grad=True), required_grad : True\n",
      "epoch 204 loss is 1.069414496421814\n",
      "epoch 204 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 204 : params.grad right after loss.backward(): tensor([-0.2006, -0.1821])\n",
      "epoch 204 after parameter update : tensor([2.7986, 4.8976], requires_grad=True), required_grad : True\n",
      "epoch 205 loss is 1.0686860084533691\n",
      "epoch 205 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 205 : params.grad right after loss.backward(): tensor([-0.1981, -0.1787])\n",
      "epoch 205 after parameter update : tensor([2.8006, 4.8994], requires_grad=True), required_grad : True\n",
      "epoch 206 loss is 1.0679796934127808\n",
      "epoch 206 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 206 : params.grad right after loss.backward(): tensor([-0.1955, -0.1754])\n",
      "epoch 206 after parameter update : tensor([2.8025, 4.9011], requires_grad=True), required_grad : True\n",
      "epoch 207 loss is 1.0672951936721802\n",
      "epoch 207 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 207 : params.grad right after loss.backward(): tensor([-0.1930, -0.1721])\n",
      "epoch 207 after parameter update : tensor([2.8044, 4.9028], requires_grad=True), required_grad : True\n",
      "epoch 208 loss is 1.0666316747665405\n",
      "epoch 208 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 208 : params.grad right after loss.backward(): tensor([-0.1905, -0.1689])\n",
      "epoch 208 after parameter update : tensor([2.8063, 4.9045], requires_grad=True), required_grad : True\n",
      "epoch 209 loss is 1.0659886598587036\n",
      "epoch 209 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 209 : params.grad right after loss.backward(): tensor([-0.1880, -0.1657])\n",
      "epoch 209 after parameter update : tensor([2.8082, 4.9062], requires_grad=True), required_grad : True\n",
      "epoch 210 loss is 1.0653654336929321\n",
      "epoch 210 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 210 : params.grad right after loss.backward(): tensor([-0.1856, -0.1626])\n",
      "epoch 210 after parameter update : tensor([2.8101, 4.9078], requires_grad=True), required_grad : True\n",
      "epoch 211 loss is 1.0647610425949097\n",
      "epoch 211 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 211 : params.grad right after loss.backward(): tensor([-0.1832, -0.1596])\n",
      "epoch 211 after parameter update : tensor([2.8119, 4.9094], requires_grad=True), required_grad : True\n",
      "epoch 212 loss is 1.0641756057739258\n",
      "epoch 212 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 212 : params.grad right after loss.backward(): tensor([-0.1808, -0.1566])\n",
      "epoch 212 after parameter update : tensor([2.8137, 4.9110], requires_grad=True), required_grad : True\n",
      "epoch 213 loss is 1.0636080503463745\n",
      "epoch 213 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 213 : params.grad right after loss.backward(): tensor([-0.1785, -0.1537])\n",
      "epoch 213 after parameter update : tensor([2.8155, 4.9125], requires_grad=True), required_grad : True\n",
      "epoch 214 loss is 1.0630576610565186\n",
      "epoch 214 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 214 : params.grad right after loss.backward(): tensor([-0.1762, -0.1508])\n",
      "epoch 214 after parameter update : tensor([2.8173, 4.9140], requires_grad=True), required_grad : True\n",
      "epoch 215 loss is 1.0625238418579102\n",
      "epoch 215 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 215 : params.grad right after loss.backward(): tensor([-0.1739, -0.1480])\n",
      "epoch 215 after parameter update : tensor([2.8190, 4.9155], requires_grad=True), required_grad : True\n",
      "epoch 216 loss is 1.0620065927505493\n",
      "epoch 216 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 216 : params.grad right after loss.backward(): tensor([-0.1716, -0.1452])\n",
      "epoch 216 after parameter update : tensor([2.8207, 4.9170], requires_grad=True), required_grad : True\n",
      "epoch 217 loss is 1.0615049600601196\n",
      "epoch 217 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 217 : params.grad right after loss.backward(): tensor([-0.1694, -0.1425])\n",
      "epoch 217 after parameter update : tensor([2.8224, 4.9184], requires_grad=True), required_grad : True\n",
      "epoch 218 loss is 1.0610185861587524\n",
      "epoch 218 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 218 : params.grad right after loss.backward(): tensor([-0.1672, -0.1399])\n",
      "epoch 218 after parameter update : tensor([2.8241, 4.9198], requires_grad=True), required_grad : True\n",
      "epoch 219 loss is 1.0605472326278687\n",
      "epoch 219 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 219 : params.grad right after loss.backward(): tensor([-0.1650, -0.1372])\n",
      "epoch 219 after parameter update : tensor([2.8257, 4.9212], requires_grad=True), required_grad : True\n",
      "epoch 220 loss is 1.0600899457931519\n",
      "epoch 220 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 220 : params.grad right after loss.backward(): tensor([-0.1629, -0.1347])\n",
      "epoch 220 after parameter update : tensor([2.8274, 4.9225], requires_grad=True), required_grad : True\n",
      "epoch 221 loss is 1.059646487236023\n",
      "epoch 221 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 221 : params.grad right after loss.backward(): tensor([-0.1608, -0.1322])\n",
      "epoch 221 after parameter update : tensor([2.8290, 4.9238], requires_grad=True), required_grad : True\n",
      "epoch 222 loss is 1.0592164993286133\n",
      "epoch 222 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 222 : params.grad right after loss.backward(): tensor([-0.1587, -0.1297])\n",
      "epoch 222 after parameter update : tensor([2.8306, 4.9251], requires_grad=True), required_grad : True\n",
      "epoch 223 loss is 1.0587996244430542\n",
      "epoch 223 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 223 : params.grad right after loss.backward(): tensor([-0.1566, -0.1273])\n",
      "epoch 223 after parameter update : tensor([2.8321, 4.9264], requires_grad=True), required_grad : True\n",
      "epoch 224 loss is 1.0583956241607666\n",
      "epoch 224 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 224 : params.grad right after loss.backward(): tensor([-0.1546, -0.1249])\n",
      "epoch 224 after parameter update : tensor([2.8337, 4.9276], requires_grad=True), required_grad : True\n",
      "epoch 225 loss is 1.058003544807434\n",
      "epoch 225 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 225 : params.grad right after loss.backward(): tensor([-0.1526, -0.1226])\n",
      "epoch 225 after parameter update : tensor([2.8352, 4.9289], requires_grad=True), required_grad : True\n",
      "epoch 226 loss is 1.057623267173767\n",
      "epoch 226 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 226 : params.grad right after loss.backward(): tensor([-0.1506, -0.1203])\n",
      "epoch 226 after parameter update : tensor([2.8367, 4.9301], requires_grad=True), required_grad : True\n",
      "epoch 227 loss is 1.0572543144226074\n",
      "epoch 227 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 227 : params.grad right after loss.backward(): tensor([-0.1486, -0.1181])\n",
      "epoch 227 after parameter update : tensor([2.8382, 4.9313], requires_grad=True), required_grad : True\n",
      "epoch 228 loss is 1.0568968057632446\n",
      "epoch 228 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 228 : params.grad right after loss.backward(): tensor([-0.1467, -0.1159])\n",
      "epoch 228 after parameter update : tensor([2.8397, 4.9324], requires_grad=True), required_grad : True\n",
      "epoch 229 loss is 1.0565499067306519\n",
      "epoch 229 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 229 : params.grad right after loss.backward(): tensor([-0.1448, -0.1138])\n",
      "epoch 229 after parameter update : tensor([2.8411, 4.9335], requires_grad=True), required_grad : True\n",
      "epoch 230 loss is 1.0562134981155396\n",
      "epoch 230 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 230 : params.grad right after loss.backward(): tensor([-0.1429, -0.1116])\n",
      "epoch 230 after parameter update : tensor([2.8425, 4.9347], requires_grad=True), required_grad : True\n",
      "epoch 231 loss is 1.0558871030807495\n",
      "epoch 231 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 231 : params.grad right after loss.backward(): tensor([-0.1410, -0.1096])\n",
      "epoch 231 after parameter update : tensor([2.8440, 4.9358], requires_grad=True), required_grad : True\n",
      "epoch 232 loss is 1.0555707216262817\n",
      "epoch 232 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 232 : params.grad right after loss.backward(): tensor([-0.1392, -0.1075])\n",
      "epoch 232 after parameter update : tensor([2.8453, 4.9368], requires_grad=True), required_grad : True\n",
      "epoch 233 loss is 1.0552634000778198\n",
      "epoch 233 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 233 : params.grad right after loss.backward(): tensor([-0.1374, -0.1056])\n",
      "epoch 233 after parameter update : tensor([2.8467, 4.9379], requires_grad=True), required_grad : True\n",
      "epoch 234 loss is 1.054965615272522\n",
      "epoch 234 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 234 : params.grad right after loss.backward(): tensor([-0.1356, -0.1036])\n",
      "epoch 234 after parameter update : tensor([2.8481, 4.9389], requires_grad=True), required_grad : True\n",
      "epoch 235 loss is 1.0546767711639404\n",
      "epoch 235 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 235 : params.grad right after loss.backward(): tensor([-0.1338, -0.1017])\n",
      "epoch 235 after parameter update : tensor([2.8494, 4.9399], requires_grad=True), required_grad : True\n",
      "epoch 236 loss is 1.054396390914917\n",
      "epoch 236 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 236 : params.grad right after loss.backward(): tensor([-0.1321, -0.0998])\n",
      "epoch 236 after parameter update : tensor([2.8507, 4.9409], requires_grad=True), required_grad : True\n",
      "epoch 237 loss is 1.054124116897583\n",
      "epoch 237 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 237 : params.grad right after loss.backward(): tensor([-0.1303, -0.0980])\n",
      "epoch 237 after parameter update : tensor([2.8520, 4.9419], requires_grad=True), required_grad : True\n",
      "epoch 238 loss is 1.0538605451583862\n",
      "epoch 238 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 238 : params.grad right after loss.backward(): tensor([-0.1286, -0.0961])\n",
      "epoch 238 after parameter update : tensor([2.8533, 4.9429], requires_grad=True), required_grad : True\n",
      "epoch 239 loss is 1.0536048412322998\n",
      "epoch 239 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 239 : params.grad right after loss.backward(): tensor([-0.1269, -0.0944])\n",
      "epoch 239 after parameter update : tensor([2.8546, 4.9438], requires_grad=True), required_grad : True\n",
      "epoch 240 loss is 1.0533560514450073\n",
      "epoch 240 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 240 : params.grad right after loss.backward(): tensor([-0.1253, -0.0926])\n",
      "epoch 240 after parameter update : tensor([2.8558, 4.9448], requires_grad=True), required_grad : True\n",
      "epoch 241 loss is 1.0531153678894043\n",
      "epoch 241 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 241 : params.grad right after loss.backward(): tensor([-0.1236, -0.0909])\n",
      "epoch 241 after parameter update : tensor([2.8571, 4.9457], requires_grad=True), required_grad : True\n",
      "epoch 242 loss is 1.0528814792633057\n",
      "epoch 242 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 242 : params.grad right after loss.backward(): tensor([-0.1220, -0.0892])\n",
      "epoch 242 after parameter update : tensor([2.8583, 4.9466], requires_grad=True), required_grad : True\n",
      "epoch 243 loss is 1.0526549816131592\n",
      "epoch 243 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 243 : params.grad right after loss.backward(): tensor([-0.1204, -0.0876])\n",
      "epoch 243 after parameter update : tensor([2.8595, 4.9474], requires_grad=True), required_grad : True\n",
      "epoch 244 loss is 1.0524348020553589\n",
      "epoch 244 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 244 : params.grad right after loss.backward(): tensor([-0.1188, -0.0860])\n",
      "epoch 244 after parameter update : tensor([2.8607, 4.9483], requires_grad=True), required_grad : True\n",
      "epoch 245 loss is 1.0522212982177734\n",
      "epoch 245 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 245 : params.grad right after loss.backward(): tensor([-0.1173, -0.0844])\n",
      "epoch 245 after parameter update : tensor([2.8619, 4.9491], requires_grad=True), required_grad : True\n",
      "epoch 246 loss is 1.0520141124725342\n",
      "epoch 246 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 246 : params.grad right after loss.backward(): tensor([-0.1158, -0.0828])\n",
      "epoch 246 after parameter update : tensor([2.8630, 4.9500], requires_grad=True), required_grad : True\n",
      "epoch 247 loss is 1.051812767982483\n",
      "epoch 247 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 247 : params.grad right after loss.backward(): tensor([-0.1142, -0.0813])\n",
      "epoch 247 after parameter update : tensor([2.8642, 4.9508], requires_grad=True), required_grad : True\n",
      "epoch 248 loss is 1.0516177415847778\n",
      "epoch 248 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 248 : params.grad right after loss.backward(): tensor([-0.1127, -0.0798])\n",
      "epoch 248 after parameter update : tensor([2.8653, 4.9516], requires_grad=True), required_grad : True\n",
      "epoch 249 loss is 1.0514283180236816\n",
      "epoch 249 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 249 : params.grad right after loss.backward(): tensor([-0.1113, -0.0783])\n",
      "epoch 249 after parameter update : tensor([2.8664, 4.9524], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 250 loss is 1.0512444972991943\n",
      "epoch 250 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 250 : params.grad right after loss.backward(): tensor([-0.1098, -0.0769])\n",
      "epoch 250 after parameter update : tensor([2.8675, 4.9531], requires_grad=True), required_grad : True\n",
      "epoch 251 loss is 1.0510663986206055\n",
      "epoch 251 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 251 : params.grad right after loss.backward(): tensor([-0.1084, -0.0755])\n",
      "epoch 251 after parameter update : tensor([2.8686, 4.9539], requires_grad=True), required_grad : True\n",
      "epoch 252 loss is 1.0508931875228882\n",
      "epoch 252 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 252 : params.grad right after loss.backward(): tensor([-0.1069, -0.0741])\n",
      "epoch 252 after parameter update : tensor([2.8697, 4.9546], requires_grad=True), required_grad : True\n",
      "epoch 253 loss is 1.0507254600524902\n",
      "epoch 253 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 253 : params.grad right after loss.backward(): tensor([-0.1055, -0.0727])\n",
      "epoch 253 after parameter update : tensor([2.8707, 4.9553], requires_grad=True), required_grad : True\n",
      "epoch 254 loss is 1.0505621433258057\n",
      "epoch 254 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 254 : params.grad right after loss.backward(): tensor([-0.1041, -0.0714])\n",
      "epoch 254 after parameter update : tensor([2.8718, 4.9561], requires_grad=True), required_grad : True\n",
      "epoch 255 loss is 1.0504038333892822\n",
      "epoch 255 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 255 : params.grad right after loss.backward(): tensor([-0.1028, -0.0701])\n",
      "epoch 255 after parameter update : tensor([2.8728, 4.9568], requires_grad=True), required_grad : True\n",
      "epoch 256 loss is 1.0502501726150513\n",
      "epoch 256 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 256 : params.grad right after loss.backward(): tensor([-0.1014, -0.0688])\n",
      "epoch 256 after parameter update : tensor([2.8738, 4.9575], requires_grad=True), required_grad : True\n",
      "epoch 257 loss is 1.0501009225845337\n",
      "epoch 257 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 257 : params.grad right after loss.backward(): tensor([-0.1001, -0.0676])\n",
      "epoch 257 after parameter update : tensor([2.8748, 4.9581], requires_grad=True), required_grad : True\n",
      "epoch 258 loss is 1.0499564409255981\n",
      "epoch 258 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 258 : params.grad right after loss.backward(): tensor([-0.0988, -0.0663])\n",
      "epoch 258 after parameter update : tensor([2.8758, 4.9588], requires_grad=True), required_grad : True\n",
      "epoch 259 loss is 1.0498160123825073\n",
      "epoch 259 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 259 : params.grad right after loss.backward(): tensor([-0.0975, -0.0651])\n",
      "epoch 259 after parameter update : tensor([2.8768, 4.9594], requires_grad=True), required_grad : True\n",
      "epoch 260 loss is 1.0496795177459717\n",
      "epoch 260 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 260 : params.grad right after loss.backward(): tensor([-0.0962, -0.0639])\n",
      "epoch 260 after parameter update : tensor([2.8777, 4.9601], requires_grad=True), required_grad : True\n",
      "epoch 261 loss is 1.0495470762252808\n",
      "epoch 261 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 261 : params.grad right after loss.backward(): tensor([-0.0949, -0.0627])\n",
      "epoch 261 after parameter update : tensor([2.8787, 4.9607], requires_grad=True), required_grad : True\n",
      "epoch 262 loss is 1.049418568611145\n",
      "epoch 262 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 262 : params.grad right after loss.backward(): tensor([-0.0937, -0.0616])\n",
      "epoch 262 after parameter update : tensor([2.8796, 4.9613], requires_grad=True), required_grad : True\n",
      "epoch 263 loss is 1.0492939949035645\n",
      "epoch 263 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 263 : params.grad right after loss.backward(): tensor([-0.0924, -0.0605])\n",
      "epoch 263 after parameter update : tensor([2.8805, 4.9619], requires_grad=True), required_grad : True\n",
      "epoch 264 loss is 1.0491728782653809\n",
      "epoch 264 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 264 : params.grad right after loss.backward(): tensor([-0.0912, -0.0594])\n",
      "epoch 264 after parameter update : tensor([2.8814, 4.9625], requires_grad=True), required_grad : True\n",
      "epoch 265 loss is 1.0490553379058838\n",
      "epoch 265 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 265 : params.grad right after loss.backward(): tensor([-0.0900, -0.0583])\n",
      "epoch 265 after parameter update : tensor([2.8823, 4.9631], requires_grad=True), required_grad : True\n",
      "epoch 266 loss is 1.0489410161972046\n",
      "epoch 266 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 266 : params.grad right after loss.backward(): tensor([-0.0888, -0.0572])\n",
      "epoch 266 after parameter update : tensor([2.8832, 4.9637], requires_grad=True), required_grad : True\n",
      "epoch 267 loss is 1.0488303899765015\n",
      "epoch 267 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 267 : params.grad right after loss.backward(): tensor([-0.0876, -0.0562])\n",
      "epoch 267 after parameter update : tensor([2.8841, 4.9642], requires_grad=True), required_grad : True\n",
      "epoch 268 loss is 1.0487229824066162\n",
      "epoch 268 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 268 : params.grad right after loss.backward(): tensor([-0.0865, -0.0552])\n",
      "epoch 268 after parameter update : tensor([2.8850, 4.9648], requires_grad=True), required_grad : True\n",
      "epoch 269 loss is 1.0486183166503906\n",
      "epoch 269 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 269 : params.grad right after loss.backward(): tensor([-0.0853, -0.0541])\n",
      "epoch 269 after parameter update : tensor([2.8858, 4.9653], requires_grad=True), required_grad : True\n",
      "epoch 270 loss is 1.048517107963562\n",
      "epoch 270 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 270 : params.grad right after loss.backward(): tensor([-0.0842, -0.0532])\n",
      "epoch 270 after parameter update : tensor([2.8867, 4.9659], requires_grad=True), required_grad : True\n",
      "epoch 271 loss is 1.048418402671814\n",
      "epoch 271 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 271 : params.grad right after loss.backward(): tensor([-0.0831, -0.0522])\n",
      "epoch 271 after parameter update : tensor([2.8875, 4.9664], requires_grad=True), required_grad : True\n",
      "epoch 272 loss is 1.0483227968215942\n",
      "epoch 272 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 272 : params.grad right after loss.backward(): tensor([-0.0820, -0.0512])\n",
      "epoch 272 after parameter update : tensor([2.8883, 4.9669], requires_grad=True), required_grad : True\n",
      "epoch 273 loss is 1.0482299327850342\n",
      "epoch 273 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 273 : params.grad right after loss.backward(): tensor([-0.0809, -0.0503])\n",
      "epoch 273 after parameter update : tensor([2.8891, 4.9674], requires_grad=True), required_grad : True\n",
      "epoch 274 loss is 1.0481396913528442\n",
      "epoch 274 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 274 : params.grad right after loss.backward(): tensor([-0.0799, -0.0494])\n",
      "epoch 274 after parameter update : tensor([2.8899, 4.9679], requires_grad=True), required_grad : True\n",
      "epoch 275 loss is 1.048052430152893\n",
      "epoch 275 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 275 : params.grad right after loss.backward(): tensor([-0.0788, -0.0485])\n",
      "epoch 275 after parameter update : tensor([2.8907, 4.9684], requires_grad=True), required_grad : True\n",
      "epoch 276 loss is 1.0479673147201538\n",
      "epoch 276 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 276 : params.grad right after loss.backward(): tensor([-0.0778, -0.0476])\n",
      "epoch 276 after parameter update : tensor([2.8915, 4.9689], requires_grad=True), required_grad : True\n",
      "epoch 277 loss is 1.0478850603103638\n",
      "epoch 277 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 277 : params.grad right after loss.backward(): tensor([-0.0767, -0.0468])\n",
      "epoch 277 after parameter update : tensor([2.8923, 4.9693], requires_grad=True), required_grad : True\n",
      "epoch 278 loss is 1.047804355621338\n",
      "epoch 278 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 278 : params.grad right after loss.backward(): tensor([-0.0757, -0.0459])\n",
      "epoch 278 after parameter update : tensor([2.8930, 4.9698], requires_grad=True), required_grad : True\n",
      "epoch 279 loss is 1.0477267503738403\n",
      "epoch 279 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 279 : params.grad right after loss.backward(): tensor([-0.0747, -0.0451])\n",
      "epoch 279 after parameter update : tensor([2.8938, 4.9702], requires_grad=True), required_grad : True\n",
      "epoch 280 loss is 1.0476514101028442\n",
      "epoch 280 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 280 : params.grad right after loss.backward(): tensor([-0.0737, -0.0443])\n",
      "epoch 280 after parameter update : tensor([2.8945, 4.9707], requires_grad=True), required_grad : True\n",
      "epoch 281 loss is 1.04757821559906\n",
      "epoch 281 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 281 : params.grad right after loss.backward(): tensor([-0.0727, -0.0435])\n",
      "epoch 281 after parameter update : tensor([2.8952, 4.9711], requires_grad=True), required_grad : True\n",
      "epoch 282 loss is 1.0475066900253296\n",
      "epoch 282 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 282 : params.grad right after loss.backward(): tensor([-0.0718, -0.0427])\n",
      "epoch 282 after parameter update : tensor([2.8959, 4.9715], requires_grad=True), required_grad : True\n",
      "epoch 283 loss is 1.0474374294281006\n",
      "epoch 283 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 283 : params.grad right after loss.backward(): tensor([-0.0708, -0.0419])\n",
      "epoch 283 after parameter update : tensor([2.8967, 4.9720], requires_grad=True), required_grad : True\n",
      "epoch 284 loss is 1.0473703145980835\n",
      "epoch 284 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 284 : params.grad right after loss.backward(): tensor([-0.0699, -0.0411])\n",
      "epoch 284 after parameter update : tensor([2.8974, 4.9724], requires_grad=True), required_grad : True\n",
      "epoch 285 loss is 1.0473048686981201\n",
      "epoch 285 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 285 : params.grad right after loss.backward(): tensor([-0.0690, -0.0404])\n",
      "epoch 285 after parameter update : tensor([2.8980, 4.9728], requires_grad=True), required_grad : True\n",
      "epoch 286 loss is 1.0472415685653687\n",
      "epoch 286 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 286 : params.grad right after loss.backward(): tensor([-0.0680, -0.0397])\n",
      "epoch 286 after parameter update : tensor([2.8987, 4.9732], requires_grad=True), required_grad : True\n",
      "epoch 287 loss is 1.0471800565719604\n",
      "epoch 287 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 287 : params.grad right after loss.backward(): tensor([-0.0671, -0.0390])\n",
      "epoch 287 after parameter update : tensor([2.8994, 4.9736], requires_grad=True), required_grad : True\n",
      "epoch 288 loss is 1.0471199750900269\n",
      "epoch 288 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 288 : params.grad right after loss.backward(): tensor([-0.0662, -0.0382])\n",
      "epoch 288 after parameter update : tensor([2.9001, 4.9739], requires_grad=True), required_grad : True\n",
      "epoch 289 loss is 1.0470620393753052\n",
      "epoch 289 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 289 : params.grad right after loss.backward(): tensor([-0.0654, -0.0376])\n",
      "epoch 289 after parameter update : tensor([2.9007, 4.9743], requires_grad=True), required_grad : True\n",
      "epoch 290 loss is 1.0470056533813477\n",
      "epoch 290 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 290 : params.grad right after loss.backward(): tensor([-0.0645, -0.0369])\n",
      "epoch 290 after parameter update : tensor([2.9014, 4.9747], requires_grad=True), required_grad : True\n",
      "epoch 291 loss is 1.0469505786895752\n",
      "epoch 291 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 291 : params.grad right after loss.backward(): tensor([-0.0636, -0.0362])\n",
      "epoch 291 after parameter update : tensor([2.9020, 4.9750], requires_grad=True), required_grad : True\n",
      "epoch 292 loss is 1.0468974113464355\n",
      "epoch 292 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 292 : params.grad right after loss.backward(): tensor([-0.0628, -0.0356])\n",
      "epoch 292 after parameter update : tensor([2.9026, 4.9754], requires_grad=True), required_grad : True\n",
      "epoch 293 loss is 1.0468460321426392\n",
      "epoch 293 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 293 : params.grad right after loss.backward(): tensor([-0.0620, -0.0349])\n",
      "epoch 293 after parameter update : tensor([2.9032, 4.9758], requires_grad=True), required_grad : True\n",
      "epoch 294 loss is 1.0467954874038696\n",
      "epoch 294 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 294 : params.grad right after loss.backward(): tensor([-0.0611, -0.0343])\n",
      "epoch 294 after parameter update : tensor([2.9038, 4.9761], requires_grad=True), required_grad : True\n",
      "epoch 295 loss is 1.0467469692230225\n",
      "epoch 295 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 295 : params.grad right after loss.backward(): tensor([-0.0603, -0.0337])\n",
      "epoch 295 after parameter update : tensor([2.9045, 4.9764], requires_grad=True), required_grad : True\n",
      "epoch 296 loss is 1.0466992855072021\n",
      "epoch 296 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 296 : params.grad right after loss.backward(): tensor([-0.0595, -0.0331])\n",
      "epoch 296 after parameter update : tensor([2.9050, 4.9768], requires_grad=True), required_grad : True\n",
      "epoch 297 loss is 1.0466538667678833\n",
      "epoch 297 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 297 : params.grad right after loss.backward(): tensor([-0.0587, -0.0325])\n",
      "epoch 297 after parameter update : tensor([2.9056, 4.9771], requires_grad=True), required_grad : True\n",
      "epoch 298 loss is 1.0466086864471436\n",
      "epoch 298 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 298 : params.grad right after loss.backward(): tensor([-0.0580, -0.0319])\n",
      "epoch 298 after parameter update : tensor([2.9062, 4.9774], requires_grad=True), required_grad : True\n",
      "epoch 299 loss is 1.046565294265747\n",
      "epoch 299 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 299 : params.grad right after loss.backward(): tensor([-0.0572, -0.0313])\n",
      "epoch 299 after parameter update : tensor([2.9068, 4.9777], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 300 loss is 1.0465229749679565\n",
      "epoch 300 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 300 : params.grad right after loss.backward(): tensor([-0.0564, -0.0308])\n",
      "epoch 300 after parameter update : tensor([2.9074, 4.9780], requires_grad=True), required_grad : True\n",
      "epoch 301 loss is 1.046481966972351\n",
      "epoch 301 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 301 : params.grad right after loss.backward(): tensor([-0.0557, -0.0302])\n",
      "epoch 301 after parameter update : tensor([2.9079, 4.9783], requires_grad=True), required_grad : True\n",
      "epoch 302 loss is 1.0464423894882202\n",
      "epoch 302 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 302 : params.grad right after loss.backward(): tensor([-0.0549, -0.0297])\n",
      "epoch 302 after parameter update : tensor([2.9085, 4.9786], requires_grad=True), required_grad : True\n",
      "epoch 303 loss is 1.046403408050537\n",
      "epoch 303 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 303 : params.grad right after loss.backward(): tensor([-0.0542, -0.0291])\n",
      "epoch 303 after parameter update : tensor([2.9090, 4.9789], requires_grad=True), required_grad : True\n",
      "epoch 304 loss is 1.0463658571243286\n",
      "epoch 304 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 304 : params.grad right after loss.backward(): tensor([-0.0535, -0.0286])\n",
      "epoch 304 after parameter update : tensor([2.9095, 4.9792], requires_grad=True), required_grad : True\n",
      "epoch 305 loss is 1.046329379081726\n",
      "epoch 305 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 305 : params.grad right after loss.backward(): tensor([-0.0528, -0.0281])\n",
      "epoch 305 after parameter update : tensor([2.9101, 4.9795], requires_grad=True), required_grad : True\n",
      "epoch 306 loss is 1.0462937355041504\n",
      "epoch 306 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 306 : params.grad right after loss.backward(): tensor([-0.0521, -0.0276])\n",
      "epoch 306 after parameter update : tensor([2.9106, 4.9798], requires_grad=True), required_grad : True\n",
      "epoch 307 loss is 1.0462590456008911\n",
      "epoch 307 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 307 : params.grad right after loss.backward(): tensor([-0.0514, -0.0271])\n",
      "epoch 307 after parameter update : tensor([2.9111, 4.9800], requires_grad=True), required_grad : True\n",
      "epoch 308 loss is 1.0462257862091064\n",
      "epoch 308 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 308 : params.grad right after loss.backward(): tensor([-0.0507, -0.0266])\n",
      "epoch 308 after parameter update : tensor([2.9116, 4.9803], requires_grad=True), required_grad : True\n",
      "epoch 309 loss is 1.046193242073059\n",
      "epoch 309 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 309 : params.grad right after loss.backward(): tensor([-0.0500, -0.0262])\n",
      "epoch 309 after parameter update : tensor([2.9121, 4.9806], requires_grad=True), required_grad : True\n",
      "epoch 310 loss is 1.0461615324020386\n",
      "epoch 310 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 310 : params.grad right after loss.backward(): tensor([-0.0493, -0.0257])\n",
      "epoch 310 after parameter update : tensor([2.9126, 4.9808], requires_grad=True), required_grad : True\n",
      "epoch 311 loss is 1.0461310148239136\n",
      "epoch 311 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 311 : params.grad right after loss.backward(): tensor([-0.0487, -0.0252])\n",
      "epoch 311 after parameter update : tensor([2.9131, 4.9811], requires_grad=True), required_grad : True\n",
      "epoch 312 loss is 1.0461008548736572\n",
      "epoch 312 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 312 : params.grad right after loss.backward(): tensor([-0.0480, -0.0248])\n",
      "epoch 312 after parameter update : tensor([2.9136, 4.9813], requires_grad=True), required_grad : True\n",
      "epoch 313 loss is 1.0460724830627441\n",
      "epoch 313 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 313 : params.grad right after loss.backward(): tensor([-0.0474, -0.0243])\n",
      "epoch 313 after parameter update : tensor([2.9140, 4.9816], requires_grad=True), required_grad : True\n",
      "epoch 314 loss is 1.046043872833252\n",
      "epoch 314 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 314 : params.grad right after loss.backward(): tensor([-0.0468, -0.0239])\n",
      "epoch 314 after parameter update : tensor([2.9145, 4.9818], requires_grad=True), required_grad : True\n",
      "epoch 315 loss is 1.0460165739059448\n",
      "epoch 315 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 315 : params.grad right after loss.backward(): tensor([-0.0461, -0.0235])\n",
      "epoch 315 after parameter update : tensor([2.9150, 4.9820], requires_grad=True), required_grad : True\n",
      "epoch 316 loss is 1.045989751815796\n",
      "epoch 316 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 316 : params.grad right after loss.backward(): tensor([-0.0455, -0.0231])\n",
      "epoch 316 after parameter update : tensor([2.9154, 4.9823], requires_grad=True), required_grad : True\n",
      "epoch 317 loss is 1.0459641218185425\n",
      "epoch 317 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 317 : params.grad right after loss.backward(): tensor([-0.0449, -0.0227])\n",
      "epoch 317 after parameter update : tensor([2.9159, 4.9825], requires_grad=True), required_grad : True\n",
      "epoch 318 loss is 1.0459389686584473\n",
      "epoch 318 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 318 : params.grad right after loss.backward(): tensor([-0.0443, -0.0223])\n",
      "epoch 318 after parameter update : tensor([2.9163, 4.9827], requires_grad=True), required_grad : True\n",
      "epoch 319 loss is 1.0459144115447998\n",
      "epoch 319 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 319 : params.grad right after loss.backward(): tensor([-0.0437, -0.0219])\n",
      "epoch 319 after parameter update : tensor([2.9167, 4.9829], requires_grad=True), required_grad : True\n",
      "epoch 320 loss is 1.0458906888961792\n",
      "epoch 320 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 320 : params.grad right after loss.backward(): tensor([-0.0431, -0.0215])\n",
      "epoch 320 after parameter update : tensor([2.9172, 4.9831], requires_grad=True), required_grad : True\n",
      "epoch 321 loss is 1.0458680391311646\n",
      "epoch 321 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 321 : params.grad right after loss.backward(): tensor([-0.0426, -0.0211])\n",
      "epoch 321 after parameter update : tensor([2.9176, 4.9834], requires_grad=True), required_grad : True\n",
      "epoch 322 loss is 1.04584538936615\n",
      "epoch 322 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 322 : params.grad right after loss.backward(): tensor([-0.0420, -0.0207])\n",
      "epoch 322 after parameter update : tensor([2.9180, 4.9836], requires_grad=True), required_grad : True\n",
      "epoch 323 loss is 1.0458234548568726\n",
      "epoch 323 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 323 : params.grad right after loss.backward(): tensor([-0.0414, -0.0204])\n",
      "epoch 323 after parameter update : tensor([2.9184, 4.9838], requires_grad=True), required_grad : True\n",
      "epoch 324 loss is 1.0458024740219116\n",
      "epoch 324 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 324 : params.grad right after loss.backward(): tensor([-0.0409, -0.0200])\n",
      "epoch 324 after parameter update : tensor([2.9188, 4.9840], requires_grad=True), required_grad : True\n",
      "epoch 325 loss is 1.0457818508148193\n",
      "epoch 325 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 325 : params.grad right after loss.backward(): tensor([-0.0403, -0.0196])\n",
      "epoch 325 after parameter update : tensor([2.9193, 4.9842], requires_grad=True), required_grad : True\n",
      "epoch 326 loss is 1.0457619428634644\n",
      "epoch 326 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 326 : params.grad right after loss.backward(): tensor([-0.0398, -0.0193])\n",
      "epoch 326 after parameter update : tensor([2.9197, 4.9844], requires_grad=True), required_grad : True\n",
      "epoch 327 loss is 1.045742392539978\n",
      "epoch 327 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 327 : params.grad right after loss.backward(): tensor([-0.0393, -0.0190])\n",
      "epoch 327 after parameter update : tensor([2.9200, 4.9845], requires_grad=True), required_grad : True\n",
      "epoch 328 loss is 1.045723795890808\n",
      "epoch 328 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 328 : params.grad right after loss.backward(): tensor([-0.0387, -0.0186])\n",
      "epoch 328 after parameter update : tensor([2.9204, 4.9847], requires_grad=True), required_grad : True\n",
      "epoch 329 loss is 1.0457053184509277\n",
      "epoch 329 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 329 : params.grad right after loss.backward(): tensor([-0.0382, -0.0183])\n",
      "epoch 329 after parameter update : tensor([2.9208, 4.9849], requires_grad=True), required_grad : True\n",
      "epoch 330 loss is 1.0456873178482056\n",
      "epoch 330 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 330 : params.grad right after loss.backward(): tensor([-0.0377, -0.0180])\n",
      "epoch 330 after parameter update : tensor([2.9212, 4.9851], requires_grad=True), required_grad : True\n",
      "epoch 331 loss is 1.0456702709197998\n",
      "epoch 331 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 331 : params.grad right after loss.backward(): tensor([-0.0372, -0.0177])\n",
      "epoch 331 after parameter update : tensor([2.9216, 4.9853], requires_grad=True), required_grad : True\n",
      "epoch 332 loss is 1.0456535816192627\n",
      "epoch 332 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 332 : params.grad right after loss.backward(): tensor([-0.0367, -0.0173])\n",
      "epoch 332 after parameter update : tensor([2.9219, 4.9854], requires_grad=True), required_grad : True\n",
      "epoch 333 loss is 1.0456370115280151\n",
      "epoch 333 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 333 : params.grad right after loss.backward(): tensor([-0.0362, -0.0170])\n",
      "epoch 333 after parameter update : tensor([2.9223, 4.9856], requires_grad=True), required_grad : True\n",
      "epoch 334 loss is 1.045621395111084\n",
      "epoch 334 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 334 : params.grad right after loss.backward(): tensor([-0.0357, -0.0167])\n",
      "epoch 334 after parameter update : tensor([2.9226, 4.9858], requires_grad=True), required_grad : True\n",
      "epoch 335 loss is 1.0456054210662842\n",
      "epoch 335 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 335 : params.grad right after loss.backward(): tensor([-0.0352, -0.0164])\n",
      "epoch 335 after parameter update : tensor([2.9230, 4.9860], requires_grad=True), required_grad : True\n",
      "epoch 336 loss is 1.0455904006958008\n",
      "epoch 336 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 336 : params.grad right after loss.backward(): tensor([-0.0348, -0.0162])\n",
      "epoch 336 after parameter update : tensor([2.9233, 4.9861], requires_grad=True), required_grad : True\n",
      "epoch 337 loss is 1.0455762147903442\n",
      "epoch 337 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 337 : params.grad right after loss.backward(): tensor([-0.0343, -0.0159])\n",
      "epoch 337 after parameter update : tensor([2.9237, 4.9863], requires_grad=True), required_grad : True\n",
      "epoch 338 loss is 1.0455620288848877\n",
      "epoch 338 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 338 : params.grad right after loss.backward(): tensor([-0.0338, -0.0156])\n",
      "epoch 338 after parameter update : tensor([2.9240, 4.9864], requires_grad=True), required_grad : True\n",
      "epoch 339 loss is 1.0455483198165894\n",
      "epoch 339 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 339 : params.grad right after loss.backward(): tensor([-0.0334, -0.0153])\n",
      "epoch 339 after parameter update : tensor([2.9244, 4.9866], requires_grad=True), required_grad : True\n",
      "epoch 340 loss is 1.045534610748291\n",
      "epoch 340 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 340 : params.grad right after loss.backward(): tensor([-0.0329, -0.0150])\n",
      "epoch 340 after parameter update : tensor([2.9247, 4.9867], requires_grad=True), required_grad : True\n",
      "epoch 341 loss is 1.0455214977264404\n",
      "epoch 341 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 341 : params.grad right after loss.backward(): tensor([-0.0325, -0.0148])\n",
      "epoch 341 after parameter update : tensor([2.9250, 4.9869], requires_grad=True), required_grad : True\n",
      "epoch 342 loss is 1.0455089807510376\n",
      "epoch 342 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 342 : params.grad right after loss.backward(): tensor([-0.0321, -0.0145])\n",
      "epoch 342 after parameter update : tensor([2.9253, 4.9870], requires_grad=True), required_grad : True\n",
      "epoch 343 loss is 1.0454967021942139\n",
      "epoch 343 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 343 : params.grad right after loss.backward(): tensor([-0.0316, -0.0143])\n",
      "epoch 343 after parameter update : tensor([2.9257, 4.9872], requires_grad=True), required_grad : True\n",
      "epoch 344 loss is 1.045485019683838\n",
      "epoch 344 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 344 : params.grad right after loss.backward(): tensor([-0.0312, -0.0140])\n",
      "epoch 344 after parameter update : tensor([2.9260, 4.9873], requires_grad=True), required_grad : True\n",
      "epoch 345 loss is 1.0454732179641724\n",
      "epoch 345 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 345 : params.grad right after loss.backward(): tensor([-0.0308, -0.0138])\n",
      "epoch 345 after parameter update : tensor([2.9263, 4.9874], requires_grad=True), required_grad : True\n",
      "epoch 346 loss is 1.045461893081665\n",
      "epoch 346 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 346 : params.grad right after loss.backward(): tensor([-0.0304, -0.0135])\n",
      "epoch 346 after parameter update : tensor([2.9266, 4.9876], requires_grad=True), required_grad : True\n",
      "epoch 347 loss is 1.0454509258270264\n",
      "epoch 347 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 347 : params.grad right after loss.backward(): tensor([-0.0300, -0.0133])\n",
      "epoch 347 after parameter update : tensor([2.9269, 4.9877], requires_grad=True), required_grad : True\n",
      "epoch 348 loss is 1.0454399585723877\n",
      "epoch 348 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 348 : params.grad right after loss.backward(): tensor([-0.0296, -0.0131])\n",
      "epoch 348 after parameter update : tensor([2.9272, 4.9878], requires_grad=True), required_grad : True\n",
      "epoch 349 loss is 1.0454295873641968\n",
      "epoch 349 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 349 : params.grad right after loss.backward(): tensor([-0.0292, -0.0128])\n",
      "epoch 349 after parameter update : tensor([2.9275, 4.9880], requires_grad=True), required_grad : True\n",
      "epoch 350 loss is 1.045419692993164\n",
      "epoch 350 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 350 : params.grad right after loss.backward(): tensor([-0.0288, -0.0126])\n",
      "epoch 350 after parameter update : tensor([2.9278, 4.9881], requires_grad=True), required_grad : True\n",
      "epoch 351 loss is 1.0454096794128418\n",
      "epoch 351 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 351 : params.grad right after loss.backward(): tensor([-0.0284, -0.0124])\n",
      "epoch 351 after parameter update : tensor([2.9280, 4.9882], requires_grad=True), required_grad : True\n",
      "epoch 352 loss is 1.0454001426696777\n",
      "epoch 352 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 352 : params.grad right after loss.backward(): tensor([-0.0280, -0.0122])\n",
      "epoch 352 after parameter update : tensor([2.9283, 4.9883], requires_grad=True), required_grad : True\n",
      "epoch 353 loss is 1.0453912019729614\n",
      "epoch 353 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 353 : params.grad right after loss.backward(): tensor([-0.0276, -0.0120])\n",
      "epoch 353 after parameter update : tensor([2.9286, 4.9885], requires_grad=True), required_grad : True\n",
      "epoch 354 loss is 1.0453821420669556\n",
      "epoch 354 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 354 : params.grad right after loss.backward(): tensor([-0.0273, -0.0118])\n",
      "epoch 354 after parameter update : tensor([2.9289, 4.9886], requires_grad=True), required_grad : True\n",
      "epoch 355 loss is 1.0453732013702393\n",
      "epoch 355 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 355 : params.grad right after loss.backward(): tensor([-0.0269, -0.0116])\n",
      "epoch 355 after parameter update : tensor([2.9291, 4.9887], requires_grad=True), required_grad : True\n",
      "epoch 356 loss is 1.0453647375106812\n",
      "epoch 356 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 356 : params.grad right after loss.backward(): tensor([-0.0265, -0.0114])\n",
      "epoch 356 after parameter update : tensor([2.9294, 4.9888], requires_grad=True), required_grad : True\n",
      "epoch 357 loss is 1.0453565120697021\n",
      "epoch 357 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 357 : params.grad right after loss.backward(): tensor([-0.0262, -0.0112])\n",
      "epoch 357 after parameter update : tensor([2.9297, 4.9889], requires_grad=True), required_grad : True\n",
      "epoch 358 loss is 1.0453484058380127\n",
      "epoch 358 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 358 : params.grad right after loss.backward(): tensor([-0.0258, -0.0110])\n",
      "epoch 358 after parameter update : tensor([2.9299, 4.9890], requires_grad=True), required_grad : True\n",
      "epoch 359 loss is 1.0453407764434814\n",
      "epoch 359 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 359 : params.grad right after loss.backward(): tensor([-0.0255, -0.0108])\n",
      "epoch 359 after parameter update : tensor([2.9302, 4.9891], requires_grad=True), required_grad : True\n",
      "epoch 360 loss is 1.0453331470489502\n",
      "epoch 360 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 360 : params.grad right after loss.backward(): tensor([-0.0251, -0.0106])\n",
      "epoch 360 after parameter update : tensor([2.9304, 4.9892], requires_grad=True), required_grad : True\n",
      "epoch 361 loss is 1.045325756072998\n",
      "epoch 361 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 361 : params.grad right after loss.backward(): tensor([-0.0248, -0.0104])\n",
      "epoch 361 after parameter update : tensor([2.9307, 4.9893], requires_grad=True), required_grad : True\n",
      "epoch 362 loss is 1.0453187227249146\n",
      "epoch 362 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 362 : params.grad right after loss.backward(): tensor([-0.0245, -0.0102])\n",
      "epoch 362 after parameter update : tensor([2.9309, 4.9895], requires_grad=True), required_grad : True\n",
      "epoch 363 loss is 1.0453115701675415\n",
      "epoch 363 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 363 : params.grad right after loss.backward(): tensor([-0.0241, -0.0101])\n",
      "epoch 363 after parameter update : tensor([2.9312, 4.9896], requires_grad=True), required_grad : True\n",
      "epoch 364 loss is 1.045304775238037\n",
      "epoch 364 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 364 : params.grad right after loss.backward(): tensor([-0.0238, -0.0099])\n",
      "epoch 364 after parameter update : tensor([2.9314, 4.9897], requires_grad=True), required_grad : True\n",
      "epoch 365 loss is 1.0452982187271118\n",
      "epoch 365 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 365 : params.grad right after loss.backward(): tensor([-0.0235, -0.0097])\n",
      "epoch 365 after parameter update : tensor([2.9316, 4.9897], requires_grad=True), required_grad : True\n",
      "epoch 366 loss is 1.045291781425476\n",
      "epoch 366 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 366 : params.grad right after loss.backward(): tensor([-0.0232, -0.0095])\n",
      "epoch 366 after parameter update : tensor([2.9319, 4.9898], requires_grad=True), required_grad : True\n",
      "epoch 367 loss is 1.0452854633331299\n",
      "epoch 367 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 367 : params.grad right after loss.backward(): tensor([-0.0229, -0.0094])\n",
      "epoch 367 after parameter update : tensor([2.9321, 4.9899], requires_grad=True), required_grad : True\n",
      "epoch 368 loss is 1.0452795028686523\n",
      "epoch 368 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 368 : params.grad right after loss.backward(): tensor([-0.0226, -0.0092])\n",
      "epoch 368 after parameter update : tensor([2.9323, 4.9900], requires_grad=True), required_grad : True\n",
      "epoch 369 loss is 1.0452735424041748\n",
      "epoch 369 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 369 : params.grad right after loss.backward(): tensor([-0.0223, -0.0091])\n",
      "epoch 369 after parameter update : tensor([2.9325, 4.9901], requires_grad=True), required_grad : True\n",
      "epoch 370 loss is 1.045267939567566\n",
      "epoch 370 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 370 : params.grad right after loss.backward(): tensor([-0.0220, -0.0089])\n",
      "epoch 370 after parameter update : tensor([2.9328, 4.9902], requires_grad=True), required_grad : True\n",
      "epoch 371 loss is 1.045262336730957\n",
      "epoch 371 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 371 : params.grad right after loss.backward(): tensor([-0.0217, -0.0087])\n",
      "epoch 371 after parameter update : tensor([2.9330, 4.9903], requires_grad=True), required_grad : True\n",
      "epoch 372 loss is 1.0452569723129272\n",
      "epoch 372 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 372 : params.grad right after loss.backward(): tensor([-0.0214, -0.0086])\n",
      "epoch 372 after parameter update : tensor([2.9332, 4.9904], requires_grad=True), required_grad : True\n",
      "epoch 373 loss is 1.045251488685608\n",
      "epoch 373 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 373 : params.grad right after loss.backward(): tensor([-0.0211, -0.0084])\n",
      "epoch 373 after parameter update : tensor([2.9334, 4.9905], requires_grad=True), required_grad : True\n",
      "epoch 374 loss is 1.0452464818954468\n",
      "epoch 374 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 374 : params.grad right after loss.backward(): tensor([-0.0208, -0.0083])\n",
      "epoch 374 after parameter update : tensor([2.9336, 4.9906], requires_grad=True), required_grad : True\n",
      "epoch 375 loss is 1.045241355895996\n",
      "epoch 375 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 375 : params.grad right after loss.backward(): tensor([-0.0205, -0.0082])\n",
      "epoch 375 after parameter update : tensor([2.9338, 4.9906], requires_grad=True), required_grad : True\n",
      "epoch 376 loss is 1.045236587524414\n",
      "epoch 376 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 376 : params.grad right after loss.backward(): tensor([-0.0202, -0.0080])\n",
      "epoch 376 after parameter update : tensor([2.9340, 4.9907], requires_grad=True), required_grad : True\n",
      "epoch 377 loss is 1.045231819152832\n",
      "epoch 377 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 377 : params.grad right after loss.backward(): tensor([-0.0200, -0.0079])\n",
      "epoch 377 after parameter update : tensor([2.9342, 4.9908], requires_grad=True), required_grad : True\n",
      "epoch 378 loss is 1.04522705078125\n",
      "epoch 378 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 378 : params.grad right after loss.backward(): tensor([-0.0197, -0.0077])\n",
      "epoch 378 after parameter update : tensor([2.9344, 4.9909], requires_grad=True), required_grad : True\n",
      "epoch 379 loss is 1.0452228784561157\n",
      "epoch 379 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 379 : params.grad right after loss.backward(): tensor([-0.0194, -0.0076])\n",
      "epoch 379 after parameter update : tensor([2.9346, 4.9909], requires_grad=True), required_grad : True\n",
      "epoch 380 loss is 1.0452184677124023\n",
      "epoch 380 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 380 : params.grad right after loss.backward(): tensor([-0.0192, -0.0075])\n",
      "epoch 380 after parameter update : tensor([2.9348, 4.9910], requires_grad=True), required_grad : True\n",
      "epoch 381 loss is 1.0452144145965576\n",
      "epoch 381 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 381 : params.grad right after loss.backward(): tensor([-0.0189, -0.0074])\n",
      "epoch 381 after parameter update : tensor([2.9350, 4.9911], requires_grad=True), required_grad : True\n",
      "epoch 382 loss is 1.045210361480713\n",
      "epoch 382 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 382 : params.grad right after loss.backward(): tensor([-0.0187, -0.0072])\n",
      "epoch 382 after parameter update : tensor([2.9352, 4.9912], requires_grad=True), required_grad : True\n",
      "epoch 383 loss is 1.0452063083648682\n",
      "epoch 383 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 383 : params.grad right after loss.backward(): tensor([-0.0184, -0.0071])\n",
      "epoch 383 after parameter update : tensor([2.9354, 4.9912], requires_grad=True), required_grad : True\n",
      "epoch 384 loss is 1.0452021360397339\n",
      "epoch 384 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 384 : params.grad right after loss.backward(): tensor([-0.0182, -0.0070])\n",
      "epoch 384 after parameter update : tensor([2.9355, 4.9913], requires_grad=True), required_grad : True\n",
      "epoch 385 loss is 1.0451987981796265\n",
      "epoch 385 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 385 : params.grad right after loss.backward(): tensor([-0.0179, -0.0069])\n",
      "epoch 385 after parameter update : tensor([2.9357, 4.9914], requires_grad=True), required_grad : True\n",
      "epoch 386 loss is 1.0451951026916504\n",
      "epoch 386 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 386 : params.grad right after loss.backward(): tensor([-0.0177, -0.0068])\n",
      "epoch 386 after parameter update : tensor([2.9359, 4.9914], requires_grad=True), required_grad : True\n",
      "epoch 387 loss is 1.0451915264129639\n",
      "epoch 387 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 387 : params.grad right after loss.backward(): tensor([-0.0174, -0.0066])\n",
      "epoch 387 after parameter update : tensor([2.9361, 4.9915], requires_grad=True), required_grad : True\n",
      "epoch 388 loss is 1.0451878309249878\n",
      "epoch 388 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 388 : params.grad right after loss.backward(): tensor([-0.0172, -0.0065])\n",
      "epoch 388 after parameter update : tensor([2.9362, 4.9916], requires_grad=True), required_grad : True\n",
      "epoch 389 loss is 1.0451847314834595\n",
      "epoch 389 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 389 : params.grad right after loss.backward(): tensor([-0.0170, -0.0064])\n",
      "epoch 389 after parameter update : tensor([2.9364, 4.9916], requires_grad=True), required_grad : True\n",
      "epoch 390 loss is 1.045181155204773\n",
      "epoch 390 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 390 : params.grad right after loss.backward(): tensor([-0.0167, -0.0063])\n",
      "epoch 390 after parameter update : tensor([2.9366, 4.9917], requires_grad=True), required_grad : True\n",
      "epoch 391 loss is 1.0451782941818237\n",
      "epoch 391 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 391 : params.grad right after loss.backward(): tensor([-0.0165, -0.0062])\n",
      "epoch 391 after parameter update : tensor([2.9367, 4.9918], requires_grad=True), required_grad : True\n",
      "epoch 392 loss is 1.0451751947402954\n",
      "epoch 392 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 392 : params.grad right after loss.backward(): tensor([-0.0163, -0.0061])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 392 after parameter update : tensor([2.9369, 4.9918], requires_grad=True), required_grad : True\n",
      "epoch 393 loss is 1.045172095298767\n",
      "epoch 393 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 393 : params.grad right after loss.backward(): tensor([-0.0161, -0.0060])\n",
      "epoch 393 after parameter update : tensor([2.9371, 4.9919], requires_grad=True), required_grad : True\n",
      "epoch 394 loss is 1.0451695919036865\n",
      "epoch 394 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 394 : params.grad right after loss.backward(): tensor([-0.0158, -0.0059])\n",
      "epoch 394 after parameter update : tensor([2.9372, 4.9919], requires_grad=True), required_grad : True\n",
      "epoch 395 loss is 1.0451663732528687\n",
      "epoch 395 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 395 : params.grad right after loss.backward(): tensor([-0.0156, -0.0058])\n",
      "epoch 395 after parameter update : tensor([2.9374, 4.9920], requires_grad=True), required_grad : True\n",
      "epoch 396 loss is 1.045163631439209\n",
      "epoch 396 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 396 : params.grad right after loss.backward(): tensor([-0.0154, -0.0057])\n",
      "epoch 396 after parameter update : tensor([2.9375, 4.9921], requires_grad=True), required_grad : True\n",
      "epoch 397 loss is 1.0451606512069702\n",
      "epoch 397 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 397 : params.grad right after loss.backward(): tensor([-0.0152, -0.0056])\n",
      "epoch 397 after parameter update : tensor([2.9377, 4.9921], requires_grad=True), required_grad : True\n",
      "epoch 398 loss is 1.0451585054397583\n",
      "epoch 398 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 398 : params.grad right after loss.backward(): tensor([-0.0150, -0.0055])\n",
      "epoch 398 after parameter update : tensor([2.9378, 4.9922], requires_grad=True), required_grad : True\n",
      "epoch 399 loss is 1.0451557636260986\n",
      "epoch 399 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 399 : params.grad right after loss.backward(): tensor([-0.0148, -0.0054])\n",
      "epoch 399 after parameter update : tensor([2.9380, 4.9922], requires_grad=True), required_grad : True\n",
      "epoch 400 loss is 1.0451533794403076\n",
      "epoch 400 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 400 : params.grad right after loss.backward(): tensor([-0.0146, -0.0053])\n",
      "epoch 400 after parameter update : tensor([2.9381, 4.9923], requires_grad=True), required_grad : True\n",
      "epoch 401 loss is 1.0451511144638062\n",
      "epoch 401 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 401 : params.grad right after loss.backward(): tensor([-0.0144, -0.0052])\n",
      "epoch 401 after parameter update : tensor([2.9383, 4.9923], requires_grad=True), required_grad : True\n",
      "epoch 402 loss is 1.0451486110687256\n",
      "epoch 402 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 402 : params.grad right after loss.backward(): tensor([-0.0142, -0.0051])\n",
      "epoch 402 after parameter update : tensor([2.9384, 4.9924], requires_grad=True), required_grad : True\n",
      "epoch 403 loss is 1.0451462268829346\n",
      "epoch 403 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 403 : params.grad right after loss.backward(): tensor([-0.0140, -0.0051])\n",
      "epoch 403 after parameter update : tensor([2.9386, 4.9924], requires_grad=True), required_grad : True\n",
      "epoch 404 loss is 1.0451440811157227\n",
      "epoch 404 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 404 : params.grad right after loss.backward(): tensor([-0.0138, -0.0050])\n",
      "epoch 404 after parameter update : tensor([2.9387, 4.9925], requires_grad=True), required_grad : True\n",
      "epoch 405 loss is 1.0451418161392212\n",
      "epoch 405 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 405 : params.grad right after loss.backward(): tensor([-0.0136, -0.0049])\n",
      "epoch 405 after parameter update : tensor([2.9388, 4.9925], requires_grad=True), required_grad : True\n",
      "epoch 406 loss is 1.045140027999878\n",
      "epoch 406 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 406 : params.grad right after loss.backward(): tensor([-0.0135, -0.0048])\n",
      "epoch 406 after parameter update : tensor([2.9390, 4.9926], requires_grad=True), required_grad : True\n",
      "epoch 407 loss is 1.045137882232666\n",
      "epoch 407 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 407 : params.grad right after loss.backward(): tensor([-0.0133, -0.0047])\n",
      "epoch 407 after parameter update : tensor([2.9391, 4.9926], requires_grad=True), required_grad : True\n",
      "epoch 408 loss is 1.0451358556747437\n",
      "epoch 408 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 408 : params.grad right after loss.backward(): tensor([-0.0131, -0.0046])\n",
      "epoch 408 after parameter update : tensor([2.9392, 4.9927], requires_grad=True), required_grad : True\n",
      "epoch 409 loss is 1.0451340675354004\n",
      "epoch 409 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 409 : params.grad right after loss.backward(): tensor([-0.0129, -0.0046])\n",
      "epoch 409 after parameter update : tensor([2.9394, 4.9927], requires_grad=True), required_grad : True\n",
      "epoch 410 loss is 1.0451323986053467\n",
      "epoch 410 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 410 : params.grad right after loss.backward(): tensor([-0.0127, -0.0045])\n",
      "epoch 410 after parameter update : tensor([2.9395, 4.9928], requires_grad=True), required_grad : True\n",
      "epoch 411 loss is 1.0451303720474243\n",
      "epoch 411 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 411 : params.grad right after loss.backward(): tensor([-0.0126, -0.0044])\n",
      "epoch 411 after parameter update : tensor([2.9396, 4.9928], requires_grad=True), required_grad : True\n",
      "epoch 412 loss is 1.045128345489502\n",
      "epoch 412 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 412 : params.grad right after loss.backward(): tensor([-0.0124, -0.0043])\n",
      "epoch 412 after parameter update : tensor([2.9397, 4.9928], requires_grad=True), required_grad : True\n",
      "epoch 413 loss is 1.0451265573501587\n",
      "epoch 413 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 413 : params.grad right after loss.backward(): tensor([-0.0122, -0.0043])\n",
      "epoch 413 after parameter update : tensor([2.9399, 4.9929], requires_grad=True), required_grad : True\n",
      "epoch 414 loss is 1.0451250076293945\n",
      "epoch 414 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 414 : params.grad right after loss.backward(): tensor([-0.0121, -0.0042])\n",
      "epoch 414 after parameter update : tensor([2.9400, 4.9929], requires_grad=True), required_grad : True\n",
      "epoch 415 loss is 1.0451236963272095\n",
      "epoch 415 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 415 : params.grad right after loss.backward(): tensor([-0.0119, -0.0041])\n",
      "epoch 415 after parameter update : tensor([2.9401, 4.9930], requires_grad=True), required_grad : True\n",
      "epoch 416 loss is 1.045121431350708\n",
      "epoch 416 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 416 : params.grad right after loss.backward(): tensor([-0.0117, -0.0041])\n",
      "epoch 416 after parameter update : tensor([2.9402, 4.9930], requires_grad=True), required_grad : True\n",
      "epoch 417 loss is 1.0451205968856812\n",
      "epoch 417 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 417 : params.grad right after loss.backward(): tensor([-0.0116, -0.0040])\n",
      "epoch 417 after parameter update : tensor([2.9403, 4.9931], requires_grad=True), required_grad : True\n",
      "epoch 418 loss is 1.0451189279556274\n",
      "epoch 418 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 418 : params.grad right after loss.backward(): tensor([-0.0114, -0.0039])\n",
      "epoch 418 after parameter update : tensor([2.9404, 4.9931], requires_grad=True), required_grad : True\n",
      "epoch 419 loss is 1.0451173782348633\n",
      "epoch 419 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 419 : params.grad right after loss.backward(): tensor([-0.0113, -0.0039])\n",
      "epoch 419 after parameter update : tensor([2.9406, 4.9931], requires_grad=True), required_grad : True\n",
      "epoch 420 loss is 1.0451159477233887\n",
      "epoch 420 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 420 : params.grad right after loss.backward(): tensor([-0.0111, -0.0038])\n",
      "epoch 420 after parameter update : tensor([2.9407, 4.9932], requires_grad=True), required_grad : True\n",
      "epoch 421 loss is 1.045114517211914\n",
      "epoch 421 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 421 : params.grad right after loss.backward(): tensor([-0.0110, -0.0037])\n",
      "epoch 421 after parameter update : tensor([2.9408, 4.9932], requires_grad=True), required_grad : True\n",
      "epoch 422 loss is 1.0451133251190186\n",
      "epoch 422 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 422 : params.grad right after loss.backward(): tensor([-0.0108, -0.0037])\n",
      "epoch 422 after parameter update : tensor([2.9409, 4.9932], requires_grad=True), required_grad : True\n",
      "epoch 423 loss is 1.0451122522354126\n",
      "epoch 423 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 423 : params.grad right after loss.backward(): tensor([-0.0107, -0.0036])\n",
      "epoch 423 after parameter update : tensor([2.9410, 4.9933], requires_grad=True), required_grad : True\n",
      "epoch 424 loss is 1.045110821723938\n",
      "epoch 424 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 424 : params.grad right after loss.backward(): tensor([-0.0105, -0.0035])\n",
      "epoch 424 after parameter update : tensor([2.9411, 4.9933], requires_grad=True), required_grad : True\n",
      "epoch 425 loss is 1.0451093912124634\n",
      "epoch 425 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 425 : params.grad right after loss.backward(): tensor([-0.0104, -0.0035])\n",
      "epoch 425 after parameter update : tensor([2.9412, 4.9933], requires_grad=True), required_grad : True\n",
      "epoch 426 loss is 1.045108437538147\n",
      "epoch 426 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 426 : params.grad right after loss.backward(): tensor([-0.0102, -0.0034])\n",
      "epoch 426 after parameter update : tensor([2.9413, 4.9934], requires_grad=True), required_grad : True\n",
      "epoch 427 loss is 1.045107126235962\n",
      "epoch 427 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 427 : params.grad right after loss.backward(): tensor([-0.0101, -0.0034])\n",
      "epoch 427 after parameter update : tensor([2.9414, 4.9934], requires_grad=True), required_grad : True\n",
      "epoch 428 loss is 1.0451061725616455\n",
      "epoch 428 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 428 : params.grad right after loss.backward(): tensor([-0.0100, -0.0033])\n",
      "epoch 428 after parameter update : tensor([2.9415, 4.9935], requires_grad=True), required_grad : True\n",
      "epoch 429 loss is 1.04510498046875\n",
      "epoch 429 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 429 : params.grad right after loss.backward(): tensor([-0.0098, -0.0033])\n",
      "epoch 429 after parameter update : tensor([2.9416, 4.9935], requires_grad=True), required_grad : True\n",
      "epoch 430 loss is 1.0451037883758545\n",
      "epoch 430 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 430 : params.grad right after loss.backward(): tensor([-0.0097, -0.0032])\n",
      "epoch 430 after parameter update : tensor([2.9417, 4.9935], requires_grad=True), required_grad : True\n",
      "epoch 431 loss is 1.045102834701538\n",
      "epoch 431 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 431 : params.grad right after loss.backward(): tensor([-0.0096, -0.0032])\n",
      "epoch 431 after parameter update : tensor([2.9418, 4.9935], requires_grad=True), required_grad : True\n",
      "epoch 432 loss is 1.0451018810272217\n",
      "epoch 432 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 432 : params.grad right after loss.backward(): tensor([-0.0094, -0.0031])\n",
      "epoch 432 after parameter update : tensor([2.9419, 4.9936], requires_grad=True), required_grad : True\n",
      "epoch 433 loss is 1.0451008081436157\n",
      "epoch 433 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 433 : params.grad right after loss.backward(): tensor([-0.0093, -0.0030])\n",
      "epoch 433 after parameter update : tensor([2.9420, 4.9936], requires_grad=True), required_grad : True\n",
      "epoch 434 loss is 1.0450997352600098\n",
      "epoch 434 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 434 : params.grad right after loss.backward(): tensor([-0.0092, -0.0030])\n",
      "epoch 434 after parameter update : tensor([2.9421, 4.9936], requires_grad=True), required_grad : True\n",
      "epoch 435 loss is 1.045098900794983\n",
      "epoch 435 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 435 : params.grad right after loss.backward(): tensor([-0.0091, -0.0029])\n",
      "epoch 435 after parameter update : tensor([2.9422, 4.9937], requires_grad=True), required_grad : True\n",
      "epoch 436 loss is 1.045097827911377\n",
      "epoch 436 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 436 : params.grad right after loss.backward(): tensor([-0.0089, -0.0029])\n",
      "epoch 436 after parameter update : tensor([2.9423, 4.9937], requires_grad=True), required_grad : True\n",
      "epoch 437 loss is 1.0450972318649292\n",
      "epoch 437 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 437 : params.grad right after loss.backward(): tensor([-0.0088, -0.0029])\n",
      "epoch 437 after parameter update : tensor([2.9423, 4.9937], requires_grad=True), required_grad : True\n",
      "epoch 438 loss is 1.0450962781906128\n",
      "epoch 438 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 438 : params.grad right after loss.backward(): tensor([-0.0087, -0.0028])\n",
      "epoch 438 after parameter update : tensor([2.9424, 4.9938], requires_grad=True), required_grad : True\n",
      "epoch 439 loss is 1.0450953245162964\n",
      "epoch 439 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 439 : params.grad right after loss.backward(): tensor([-0.0086, -0.0028])\n",
      "epoch 439 after parameter update : tensor([2.9425, 4.9938], requires_grad=True), required_grad : True\n",
      "epoch 440 loss is 1.045094609260559\n",
      "epoch 440 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 440 : params.grad right after loss.backward(): tensor([-0.0085, -0.0027])\n",
      "epoch 440 after parameter update : tensor([2.9426, 4.9938], requires_grad=True), required_grad : True\n",
      "epoch 441 loss is 1.0450936555862427\n",
      "epoch 441 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 441 : params.grad right after loss.backward(): tensor([-0.0083, -0.0027])\n",
      "epoch 441 after parameter update : tensor([2.9427, 4.9938], requires_grad=True), required_grad : True\n",
      "epoch 442 loss is 1.0450934171676636\n",
      "epoch 442 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 442 : params.grad right after loss.backward(): tensor([-0.0082, -0.0026])\n",
      "epoch 442 after parameter update : tensor([2.9428, 4.9939], requires_grad=True), required_grad : True\n",
      "epoch 443 loss is 1.0450924634933472\n",
      "epoch 443 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 443 : params.grad right after loss.backward(): tensor([-0.0081, -0.0026])\n",
      "epoch 443 after parameter update : tensor([2.9429, 4.9939], requires_grad=True), required_grad : True\n",
      "epoch 444 loss is 1.0450917482376099\n",
      "epoch 444 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 444 : params.grad right after loss.backward(): tensor([-0.0080, -0.0025])\n",
      "epoch 444 after parameter update : tensor([2.9429, 4.9939], requires_grad=True), required_grad : True\n",
      "epoch 445 loss is 1.045091152191162\n",
      "epoch 445 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 445 : params.grad right after loss.backward(): tensor([-0.0079, -0.0025])\n",
      "epoch 445 after parameter update : tensor([2.9430, 4.9939], requires_grad=True), required_grad : True\n",
      "epoch 446 loss is 1.0450901985168457\n",
      "epoch 446 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 446 : params.grad right after loss.backward(): tensor([-0.0078, -0.0025])\n",
      "epoch 446 after parameter update : tensor([2.9431, 4.9940], requires_grad=True), required_grad : True\n",
      "epoch 447 loss is 1.045089602470398\n",
      "epoch 447 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 447 : params.grad right after loss.backward(): tensor([-0.0077, -0.0024])\n",
      "epoch 447 after parameter update : tensor([2.9432, 4.9940], requires_grad=True), required_grad : True\n",
      "epoch 448 loss is 1.0450892448425293\n",
      "epoch 448 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 448 : params.grad right after loss.backward(): tensor([-0.0076, -0.0024])\n",
      "epoch 448 after parameter update : tensor([2.9432, 4.9940], requires_grad=True), required_grad : True\n",
      "epoch 449 loss is 1.045088291168213\n",
      "epoch 449 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 449 : params.grad right after loss.backward(): tensor([-0.0075, -0.0023])\n",
      "epoch 449 after parameter update : tensor([2.9433, 4.9940], requires_grad=True), required_grad : True\n",
      "epoch 450 loss is 1.0450879335403442\n",
      "epoch 450 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 450 : params.grad right after loss.backward(): tensor([-0.0074, -0.0023])\n",
      "epoch 450 after parameter update : tensor([2.9434, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 451 loss is 1.045087218284607\n",
      "epoch 451 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 451 : params.grad right after loss.backward(): tensor([-0.0073, -0.0023])\n",
      "epoch 451 after parameter update : tensor([2.9435, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 452 loss is 1.0450866222381592\n",
      "epoch 452 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 452 : params.grad right after loss.backward(): tensor([-0.0072, -0.0022])\n",
      "epoch 452 after parameter update : tensor([2.9435, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 453 loss is 1.045086145401001\n",
      "epoch 453 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 453 : params.grad right after loss.backward(): tensor([-0.0071, -0.0022])\n",
      "epoch 453 after parameter update : tensor([2.9436, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 454 loss is 1.0450855493545532\n",
      "epoch 454 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 454 : params.grad right after loss.backward(): tensor([-0.0070, -0.0022])\n",
      "epoch 454 after parameter update : tensor([2.9437, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 455 loss is 1.0450849533081055\n",
      "epoch 455 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 455 : params.grad right after loss.backward(): tensor([-0.0069, -0.0021])\n",
      "epoch 455 after parameter update : tensor([2.9437, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 456 loss is 1.045084834098816\n",
      "epoch 456 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 456 : params.grad right after loss.backward(): tensor([-0.0068, -0.0021])\n",
      "epoch 456 after parameter update : tensor([2.9438, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 457 loss is 1.0450841188430786\n",
      "epoch 457 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 457 : params.grad right after loss.backward(): tensor([-0.0067, -0.0020])\n",
      "epoch 457 after parameter update : tensor([2.9439, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 458 loss is 1.0450838804244995\n",
      "epoch 458 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 458 : params.grad right after loss.backward(): tensor([-0.0066, -0.0020])\n",
      "epoch 458 after parameter update : tensor([2.9439, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 459 loss is 1.045082926750183\n",
      "epoch 459 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 459 : params.grad right after loss.backward(): tensor([-0.0065, -0.0020])\n",
      "epoch 459 after parameter update : tensor([2.9440, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 460 loss is 1.0450825691223145\n",
      "epoch 460 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 460 : params.grad right after loss.backward(): tensor([-0.0064, -0.0020])\n",
      "epoch 460 after parameter update : tensor([2.9441, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 461 loss is 1.0450819730758667\n",
      "epoch 461 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 461 : params.grad right after loss.backward(): tensor([-0.0064, -0.0019])\n",
      "epoch 461 after parameter update : tensor([2.9441, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 462 loss is 1.045081615447998\n",
      "epoch 462 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 462 : params.grad right after loss.backward(): tensor([-0.0063, -0.0019])\n",
      "epoch 462 after parameter update : tensor([2.9442, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 463 loss is 1.0450812578201294\n",
      "epoch 463 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 463 : params.grad right after loss.backward(): tensor([-0.0062, -0.0019])\n",
      "epoch 463 after parameter update : tensor([2.9443, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 464 loss is 1.0450806617736816\n",
      "epoch 464 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 464 : params.grad right after loss.backward(): tensor([-0.0061, -0.0018])\n",
      "epoch 464 after parameter update : tensor([2.9443, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 465 loss is 1.0450809001922607\n",
      "epoch 465 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 465 : params.grad right after loss.backward(): tensor([-0.0060, -0.0018])\n",
      "epoch 465 after parameter update : tensor([2.9444, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 466 loss is 1.0450798273086548\n",
      "epoch 466 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 466 : params.grad right after loss.backward(): tensor([-0.0059, -0.0018])\n",
      "epoch 466 after parameter update : tensor([2.9444, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 467 loss is 1.0450797080993652\n",
      "epoch 467 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 467 : params.grad right after loss.backward(): tensor([-0.0059, -0.0017])\n",
      "epoch 467 after parameter update : tensor([2.9445, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 468 loss is 1.0450793504714966\n",
      "epoch 468 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 468 : params.grad right after loss.backward(): tensor([-0.0058, -0.0017])\n",
      "epoch 468 after parameter update : tensor([2.9446, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 469 loss is 1.045078992843628\n",
      "epoch 469 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 469 : params.grad right after loss.backward(): tensor([-0.0057, -0.0017])\n",
      "epoch 469 after parameter update : tensor([2.9446, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 470 loss is 1.0450786352157593\n",
      "epoch 470 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 470 : params.grad right after loss.backward(): tensor([-0.0056, -0.0017])\n",
      "epoch 470 after parameter update : tensor([2.9447, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 471 loss is 1.0450783967971802\n",
      "epoch 471 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 471 : params.grad right after loss.backward(): tensor([-0.0055, -0.0016])\n",
      "epoch 471 after parameter update : tensor([2.9447, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 472 loss is 1.045078158378601\n",
      "epoch 472 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 472 : params.grad right after loss.backward(): tensor([-0.0055, -0.0016])\n",
      "epoch 472 after parameter update : tensor([2.9448, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 473 loss is 1.0450778007507324\n",
      "epoch 473 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 473 : params.grad right after loss.backward(): tensor([-0.0054, -0.0016])\n",
      "epoch 473 after parameter update : tensor([2.9448, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 474 loss is 1.0450775623321533\n",
      "epoch 474 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 474 : params.grad right after loss.backward(): tensor([-0.0053, -0.0016])\n",
      "epoch 474 after parameter update : tensor([2.9449, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 475 loss is 1.0450770854949951\n",
      "epoch 475 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 475 : params.grad right after loss.backward(): tensor([-0.0052, -0.0015])\n",
      "epoch 475 after parameter update : tensor([2.9449, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 476 loss is 1.0450764894485474\n",
      "epoch 476 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 476 : params.grad right after loss.backward(): tensor([-0.0052, -0.0015])\n",
      "epoch 476 after parameter update : tensor([2.9450, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 477 loss is 1.0450761318206787\n",
      "epoch 477 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 477 : params.grad right after loss.backward(): tensor([-0.0051, -0.0015])\n",
      "epoch 477 after parameter update : tensor([2.9450, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 478 loss is 1.0450764894485474\n",
      "epoch 478 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 478 : params.grad right after loss.backward(): tensor([-0.0050, -0.0015])\n",
      "epoch 478 after parameter update : tensor([2.9451, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 479 loss is 1.04507577419281\n",
      "epoch 479 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 479 : params.grad right after loss.backward(): tensor([-0.0050, -0.0014])\n",
      "epoch 479 after parameter update : tensor([2.9451, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 480 loss is 1.0450756549835205\n",
      "epoch 480 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 480 : params.grad right after loss.backward(): tensor([-0.0049, -0.0014])\n",
      "epoch 480 after parameter update : tensor([2.9452, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 481 loss is 1.0450751781463623\n",
      "epoch 481 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 481 : params.grad right after loss.backward(): tensor([-0.0048, -0.0014])\n",
      "epoch 481 after parameter update : tensor([2.9452, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 482 loss is 1.0450754165649414\n",
      "epoch 482 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 482 : params.grad right after loss.backward(): tensor([-0.0048, -0.0014])\n",
      "epoch 482 after parameter update : tensor([2.9453, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 483 loss is 1.0450749397277832\n",
      "epoch 483 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 483 : params.grad right after loss.backward(): tensor([-0.0047, -0.0013])\n",
      "epoch 483 after parameter update : tensor([2.9453, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 484 loss is 1.0450745820999146\n",
      "epoch 484 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 484 : params.grad right after loss.backward(): tensor([-0.0046, -0.0013])\n",
      "epoch 484 after parameter update : tensor([2.9454, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 485 loss is 1.0450741052627563\n",
      "epoch 485 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 485 : params.grad right after loss.backward(): tensor([-0.0046, -0.0013])\n",
      "epoch 485 after parameter update : tensor([2.9454, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 486 loss is 1.0450741052627563\n",
      "epoch 486 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 486 : params.grad right after loss.backward(): tensor([-0.0045, -0.0013])\n",
      "epoch 486 after parameter update : tensor([2.9455, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 487 loss is 1.0450737476348877\n",
      "epoch 487 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 487 : params.grad right after loss.backward(): tensor([-0.0045, -0.0013])\n",
      "epoch 487 after parameter update : tensor([2.9455, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 488 loss is 1.0450737476348877\n",
      "epoch 488 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 488 : params.grad right after loss.backward(): tensor([-0.0044, -0.0012])\n",
      "epoch 488 after parameter update : tensor([2.9456, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 489 loss is 1.0450735092163086\n",
      "epoch 489 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 489 : params.grad right after loss.backward(): tensor([-0.0043, -0.0012])\n",
      "epoch 489 after parameter update : tensor([2.9456, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 490 loss is 1.0450732707977295\n",
      "epoch 490 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 490 : params.grad right after loss.backward(): tensor([-0.0043, -0.0012])\n",
      "epoch 490 after parameter update : tensor([2.9457, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 491 loss is 1.0450729131698608\n",
      "epoch 491 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 491 : params.grad right after loss.backward(): tensor([-0.0042, -0.0012])\n",
      "epoch 491 after parameter update : tensor([2.9457, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 492 loss is 1.0450727939605713\n",
      "epoch 492 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 492 : params.grad right after loss.backward(): tensor([-0.0042, -0.0012])\n",
      "epoch 492 after parameter update : tensor([2.9457, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 493 loss is 1.0450726747512817\n",
      "epoch 493 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 493 : params.grad right after loss.backward(): tensor([-0.0041, -0.0011])\n",
      "epoch 493 after parameter update : tensor([2.9458, 4.9948], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 494 loss is 1.0450724363327026\n",
      "epoch 494 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 494 : params.grad right after loss.backward(): tensor([-0.0040, -0.0011])\n",
      "epoch 494 after parameter update : tensor([2.9458, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 495 loss is 1.0450724363327026\n",
      "epoch 495 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 495 : params.grad right after loss.backward(): tensor([-0.0040, -0.0011])\n",
      "epoch 495 after parameter update : tensor([2.9459, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 496 loss is 1.0450724363327026\n",
      "epoch 496 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 496 : params.grad right after loss.backward(): tensor([-0.0039, -0.0011])\n",
      "epoch 496 after parameter update : tensor([2.9459, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 497 loss is 1.045072078704834\n",
      "epoch 497 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 497 : params.grad right after loss.backward(): tensor([-0.0039, -0.0011])\n",
      "epoch 497 after parameter update : tensor([2.9459, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 498 loss is 1.0450718402862549\n",
      "epoch 498 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 498 : params.grad right after loss.backward(): tensor([-0.0038, -0.0011])\n",
      "epoch 498 after parameter update : tensor([2.9460, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 499 loss is 1.0450718402862549\n",
      "epoch 499 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 499 : params.grad right after loss.backward(): tensor([-0.0038, -0.0010])\n",
      "epoch 499 after parameter update : tensor([2.9460, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 500 loss is 1.0450716018676758\n",
      "epoch 500 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 500 : params.grad right after loss.backward(): tensor([-0.0037, -0.0010])\n",
      "epoch 500 after parameter update : tensor([2.9460, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 501 loss is 1.0450714826583862\n",
      "epoch 501 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 501 : params.grad right after loss.backward(): tensor([-0.0037, -0.0010])\n",
      "epoch 501 after parameter update : tensor([2.9461, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 502 loss is 1.0450712442398071\n",
      "epoch 502 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 502 : params.grad right after loss.backward(): tensor([-0.0036, -0.0010])\n",
      "epoch 502 after parameter update : tensor([2.9461, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 503 loss is 1.0450713634490967\n",
      "epoch 503 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 503 : params.grad right after loss.backward(): tensor([-0.0036, -0.0010])\n",
      "epoch 503 after parameter update : tensor([2.9462, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 504 loss is 1.045071005821228\n",
      "epoch 504 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 504 : params.grad right after loss.backward(): tensor([-0.0035, -0.0010])\n",
      "epoch 504 after parameter update : tensor([2.9462, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 505 loss is 1.0450706481933594\n",
      "epoch 505 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 505 : params.grad right after loss.backward(): tensor([-0.0035, -0.0009])\n",
      "epoch 505 after parameter update : tensor([2.9462, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 506 loss is 1.0450705289840698\n",
      "epoch 506 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 506 : params.grad right after loss.backward(): tensor([-0.0034, -0.0009])\n",
      "epoch 506 after parameter update : tensor([2.9463, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 507 loss is 1.0450706481933594\n",
      "epoch 507 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 507 : params.grad right after loss.backward(): tensor([-0.0034, -0.0009])\n",
      "epoch 507 after parameter update : tensor([2.9463, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 508 loss is 1.0450705289840698\n",
      "epoch 508 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 508 : params.grad right after loss.backward(): tensor([-0.0033, -0.0009])\n",
      "epoch 508 after parameter update : tensor([2.9463, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 509 loss is 1.0450702905654907\n",
      "epoch 509 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 509 : params.grad right after loss.backward(): tensor([-0.0033, -0.0009])\n",
      "epoch 509 after parameter update : tensor([2.9464, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 510 loss is 1.0450702905654907\n",
      "epoch 510 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 510 : params.grad right after loss.backward(): tensor([-0.0032, -0.0009])\n",
      "epoch 510 after parameter update : tensor([2.9464, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 511 loss is 1.0450700521469116\n",
      "epoch 511 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 511 : params.grad right after loss.backward(): tensor([-0.0032, -0.0009])\n",
      "epoch 511 after parameter update : tensor([2.9464, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 512 loss is 1.0450701713562012\n",
      "epoch 512 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 512 : params.grad right after loss.backward(): tensor([-0.0032, -0.0008])\n",
      "epoch 512 after parameter update : tensor([2.9465, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 513 loss is 1.0450698137283325\n",
      "epoch 513 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 513 : params.grad right after loss.backward(): tensor([-0.0031, -0.0008])\n",
      "epoch 513 after parameter update : tensor([2.9465, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 514 loss is 1.045069932937622\n",
      "epoch 514 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 514 : params.grad right after loss.backward(): tensor([-0.0031, -0.0008])\n",
      "epoch 514 after parameter update : tensor([2.9465, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 515 loss is 1.045069694519043\n",
      "epoch 515 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 515 : params.grad right after loss.backward(): tensor([-0.0030, -0.0008])\n",
      "epoch 515 after parameter update : tensor([2.9465, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 516 loss is 1.0450695753097534\n",
      "epoch 516 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 516 : params.grad right after loss.backward(): tensor([-0.0030, -0.0008])\n",
      "epoch 516 after parameter update : tensor([2.9466, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 517 loss is 1.0450698137283325\n",
      "epoch 517 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 517 : params.grad right after loss.backward(): tensor([-0.0029, -0.0008])\n",
      "epoch 517 after parameter update : tensor([2.9466, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 518 loss is 1.0450692176818848\n",
      "epoch 518 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 518 : params.grad right after loss.backward(): tensor([-0.0029, -0.0008])\n",
      "epoch 518 after parameter update : tensor([2.9466, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 519 loss is 1.0450694561004639\n",
      "epoch 519 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 519 : params.grad right after loss.backward(): tensor([-0.0029, -0.0008])\n",
      "epoch 519 after parameter update : tensor([2.9467, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 520 loss is 1.0450694561004639\n",
      "epoch 520 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 520 : params.grad right after loss.backward(): tensor([-0.0028, -0.0007])\n",
      "epoch 520 after parameter update : tensor([2.9467, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 521 loss is 1.0450693368911743\n",
      "epoch 521 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 521 : params.grad right after loss.backward(): tensor([-0.0028, -0.0007])\n",
      "epoch 521 after parameter update : tensor([2.9467, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 522 loss is 1.0450688600540161\n",
      "epoch 522 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 522 : params.grad right after loss.backward(): tensor([-0.0028, -0.0007])\n",
      "epoch 522 after parameter update : tensor([2.9467, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 523 loss is 1.0450690984725952\n",
      "epoch 523 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 523 : params.grad right after loss.backward(): tensor([-0.0027, -0.0007])\n",
      "epoch 523 after parameter update : tensor([2.9468, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 524 loss is 1.0450689792633057\n",
      "epoch 524 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 524 : params.grad right after loss.backward(): tensor([-0.0027, -0.0007])\n",
      "epoch 524 after parameter update : tensor([2.9468, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 525 loss is 1.0450688600540161\n",
      "epoch 525 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 525 : params.grad right after loss.backward(): tensor([-0.0026, -0.0007])\n",
      "epoch 525 after parameter update : tensor([2.9468, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 526 loss is 1.0450687408447266\n",
      "epoch 526 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 526 : params.grad right after loss.backward(): tensor([-0.0026, -0.0007])\n",
      "epoch 526 after parameter update : tensor([2.9469, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 527 loss is 1.0450690984725952\n",
      "epoch 527 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 527 : params.grad right after loss.backward(): tensor([-0.0026, -0.0007])\n",
      "epoch 527 after parameter update : tensor([2.9469, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 528 loss is 1.045068621635437\n",
      "epoch 528 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 528 : params.grad right after loss.backward(): tensor([-0.0025, -0.0007])\n",
      "epoch 528 after parameter update : tensor([2.9469, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 529 loss is 1.0450685024261475\n",
      "epoch 529 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 529 : params.grad right after loss.backward(): tensor([-0.0025, -0.0006])\n",
      "epoch 529 after parameter update : tensor([2.9469, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 530 loss is 1.045068621635437\n",
      "epoch 530 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 530 : params.grad right after loss.backward(): tensor([-0.0025, -0.0006])\n",
      "epoch 530 after parameter update : tensor([2.9470, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 531 loss is 1.045068621635437\n",
      "epoch 531 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 531 : params.grad right after loss.backward(): tensor([-0.0024, -0.0006])\n",
      "epoch 531 after parameter update : tensor([2.9470, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 532 loss is 1.045068383216858\n",
      "epoch 532 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 532 : params.grad right after loss.backward(): tensor([-0.0024, -0.0006])\n",
      "epoch 532 after parameter update : tensor([2.9470, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 533 loss is 1.0450685024261475\n",
      "epoch 533 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 533 : params.grad right after loss.backward(): tensor([-0.0024, -0.0006])\n",
      "epoch 533 after parameter update : tensor([2.9470, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 534 loss is 1.0450682640075684\n",
      "epoch 534 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 534 : params.grad right after loss.backward(): tensor([-0.0023, -0.0006])\n",
      "epoch 534 after parameter update : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 535 loss is 1.0450682640075684\n",
      "epoch 535 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 535 : params.grad right after loss.backward(): tensor([-0.0023, -0.0006])\n",
      "epoch 535 after parameter update : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 536 loss is 1.0450681447982788\n",
      "epoch 536 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 536 : params.grad right after loss.backward(): tensor([-0.0023, -0.0006])\n",
      "epoch 536 after parameter update : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 537 loss is 1.0450681447982788\n",
      "epoch 537 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 537 : params.grad right after loss.backward(): tensor([-0.0022, -0.0006])\n",
      "epoch 537 after parameter update : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 538 loss is 1.0450680255889893\n",
      "epoch 538 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 538 : params.grad right after loss.backward(): tensor([-0.0022, -0.0006])\n",
      "epoch 538 after parameter update : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 539 loss is 1.0450676679611206\n",
      "epoch 539 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 539 : params.grad right after loss.backward(): tensor([-0.0022, -0.0006])\n",
      "epoch 539 after parameter update : tensor([2.9472, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 540 loss is 1.0450677871704102\n",
      "epoch 540 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 540 : params.grad right after loss.backward(): tensor([-0.0022, -0.0005])\n",
      "epoch 540 after parameter update : tensor([2.9472, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 541 loss is 1.0450676679611206\n",
      "epoch 541 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 541 : params.grad right after loss.backward(): tensor([-0.0021, -0.0005])\n",
      "epoch 541 after parameter update : tensor([2.9472, 4.9951], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 542 loss is 1.0450679063796997\n",
      "epoch 542 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 542 : params.grad right after loss.backward(): tensor([-0.0021, -0.0005])\n",
      "epoch 542 after parameter update : tensor([2.9472, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 543 loss is 1.0450677871704102\n",
      "epoch 543 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 543 : params.grad right after loss.backward(): tensor([-0.0021, -0.0005])\n",
      "epoch 543 after parameter update : tensor([2.9472, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 544 loss is 1.0450677871704102\n",
      "epoch 544 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 544 : params.grad right after loss.backward(): tensor([-0.0020, -0.0005])\n",
      "epoch 544 after parameter update : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 545 loss is 1.0450677871704102\n",
      "epoch 545 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 545 : params.grad right after loss.backward(): tensor([-0.0020, -0.0005])\n",
      "epoch 545 after parameter update : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 546 loss is 1.0450676679611206\n",
      "epoch 546 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 546 : params.grad right after loss.backward(): tensor([-0.0020, -0.0005])\n",
      "epoch 546 after parameter update : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 547 loss is 1.0450677871704102\n",
      "epoch 547 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 547 : params.grad right after loss.backward(): tensor([-0.0020, -0.0005])\n",
      "epoch 547 after parameter update : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 548 loss is 1.0450677871704102\n",
      "epoch 548 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 548 : params.grad right after loss.backward(): tensor([-0.0019, -0.0005])\n",
      "epoch 548 after parameter update : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 549 loss is 1.045067548751831\n",
      "epoch 549 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 549 : params.grad right after loss.backward(): tensor([-0.0019, -0.0005])\n",
      "epoch 549 after parameter update : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 550 loss is 1.0450674295425415\n",
      "epoch 550 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 550 : params.grad right after loss.backward(): tensor([-0.0019, -0.0005])\n",
      "epoch 550 after parameter update : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 551 loss is 1.045067310333252\n",
      "epoch 551 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 551 : params.grad right after loss.backward(): tensor([-0.0018, -0.0005])\n",
      "epoch 551 after parameter update : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 552 loss is 1.045067548751831\n",
      "epoch 552 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 552 : params.grad right after loss.backward(): tensor([-0.0018, -0.0004])\n",
      "epoch 552 after parameter update : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 553 loss is 1.0450671911239624\n",
      "epoch 553 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 553 : params.grad right after loss.backward(): tensor([-0.0018, -0.0004])\n",
      "epoch 553 after parameter update : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 554 loss is 1.0450671911239624\n",
      "epoch 554 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 554 : params.grad right after loss.backward(): tensor([-0.0018, -0.0004])\n",
      "epoch 554 after parameter update : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 555 loss is 1.0450670719146729\n",
      "epoch 555 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 555 : params.grad right after loss.backward(): tensor([-0.0018, -0.0004])\n",
      "epoch 555 after parameter update : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 556 loss is 1.0450671911239624\n",
      "epoch 556 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 556 : params.grad right after loss.backward(): tensor([-0.0017, -0.0004])\n",
      "epoch 556 after parameter update : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 557 loss is 1.0450671911239624\n",
      "epoch 557 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 557 : params.grad right after loss.backward(): tensor([-0.0017, -0.0004])\n",
      "epoch 557 after parameter update : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 558 loss is 1.0450669527053833\n",
      "epoch 558 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 558 : params.grad right after loss.backward(): tensor([-0.0017, -0.0004])\n",
      "epoch 558 after parameter update : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 559 loss is 1.0450670719146729\n",
      "epoch 559 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 559 : params.grad right after loss.backward(): tensor([-0.0017, -0.0004])\n",
      "epoch 559 after parameter update : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 560 loss is 1.0450668334960938\n",
      "epoch 560 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 560 : params.grad right after loss.backward(): tensor([-0.0016, -0.0004])\n",
      "epoch 560 after parameter update : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 561 loss is 1.0450669527053833\n",
      "epoch 561 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 561 : params.grad right after loss.backward(): tensor([-0.0016, -0.0004])\n",
      "epoch 561 after parameter update : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 562 loss is 1.0450670719146729\n",
      "epoch 562 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 562 : params.grad right after loss.backward(): tensor([-0.0016, -0.0004])\n",
      "epoch 562 after parameter update : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 563 loss is 1.0450669527053833\n",
      "epoch 563 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 563 : params.grad right after loss.backward(): tensor([-0.0016, -0.0004])\n",
      "epoch 563 after parameter update : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 564 loss is 1.0450671911239624\n",
      "epoch 564 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 564 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 564 after parameter update : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 565 loss is 1.0450670719146729\n",
      "epoch 565 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 565 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 565 after parameter update : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 566 loss is 1.0450670719146729\n",
      "epoch 566 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 566 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 566 after parameter update : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 567 loss is 1.0450670719146729\n",
      "epoch 567 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 567 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 567 after parameter update : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 568 loss is 1.0450671911239624\n",
      "epoch 568 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 568 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 568 after parameter update : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 569 loss is 1.0450670719146729\n",
      "epoch 569 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 569 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 569 after parameter update : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 570 loss is 1.0450669527053833\n",
      "epoch 570 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 570 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 570 after parameter update : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 571 loss is 1.045067310333252\n",
      "epoch 571 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 571 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 571 after parameter update : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 572 loss is 1.0450668334960938\n",
      "epoch 572 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 572 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 572 after parameter update : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 573 loss is 1.0450667142868042\n",
      "epoch 573 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 573 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 573 after parameter update : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 574 loss is 1.0450669527053833\n",
      "epoch 574 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 574 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 574 after parameter update : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 575 loss is 1.0450669527053833\n",
      "epoch 575 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 575 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 575 after parameter update : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 576 loss is 1.0450669527053833\n",
      "epoch 576 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 576 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 576 after parameter update : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 577 loss is 1.0450669527053833\n",
      "epoch 577 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 577 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 577 after parameter update : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 578 loss is 1.0450669527053833\n",
      "epoch 578 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 578 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 578 after parameter update : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 579 loss is 1.0450667142868042\n",
      "epoch 579 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 579 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 579 after parameter update : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 580 loss is 1.0450668334960938\n",
      "epoch 580 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 580 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 580 after parameter update : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 581 loss is 1.0450667142868042\n",
      "epoch 581 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 581 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 581 after parameter update : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 582 loss is 1.045066475868225\n",
      "epoch 582 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 582 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 582 after parameter update : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 583 loss is 1.0450668334960938\n",
      "epoch 583 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 583 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 583 after parameter update : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 584 loss is 1.0450665950775146\n",
      "epoch 584 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 584 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 584 after parameter update : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 585 loss is 1.0450668334960938\n",
      "epoch 585 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 585 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 585 after parameter update : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 586 loss is 1.045066475868225\n",
      "epoch 586 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 586 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 586 after parameter update : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 587 loss is 1.0450665950775146\n",
      "epoch 587 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 587 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 587 after parameter update : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 588 loss is 1.0450667142868042\n",
      "epoch 588 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 588 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 588 after parameter update : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 589 loss is 1.0450667142868042\n",
      "epoch 589 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 589 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 589 after parameter update : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 590 loss is 1.0450668334960938\n",
      "epoch 590 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 590 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 590 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 591 loss is 1.045066475868225\n",
      "epoch 591 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 591 : params.grad right after loss.backward(): tensor([-0.0011, -0.0002])\n",
      "epoch 591 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 592 loss is 1.0450665950775146\n",
      "epoch 592 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 592 : params.grad right after loss.backward(): tensor([-0.0011, -0.0002])\n",
      "epoch 592 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 593 loss is 1.0450667142868042\n",
      "epoch 593 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 593 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 593 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 594 loss is 1.045066475868225\n",
      "epoch 594 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 594 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 594 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 595 loss is 1.045066475868225\n",
      "epoch 595 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 595 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 595 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 596 loss is 1.0450665950775146\n",
      "epoch 596 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 596 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 596 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 597 loss is 1.0450667142868042\n",
      "epoch 597 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 597 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 597 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 598 loss is 1.0450665950775146\n",
      "epoch 598 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 598 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 598 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 599 loss is 1.0450667142868042\n",
      "epoch 599 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 599 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 599 after parameter update : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 600 loss is 1.045066475868225\n",
      "epoch 600 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 600 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 600 after parameter update : tensor([2.9481, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 601 loss is 1.0450663566589355\n",
      "epoch 601 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 601 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 601 after parameter update : tensor([2.9481, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 602 loss is 1.045066475868225\n",
      "epoch 602 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 602 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 602 after parameter update : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 603 loss is 1.045066475868225\n",
      "epoch 603 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 603 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 603 after parameter update : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 604 loss is 1.045066475868225\n",
      "epoch 604 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 604 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 604 after parameter update : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 605 loss is 1.0450665950775146\n",
      "epoch 605 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 605 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 605 after parameter update : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 606 loss is 1.045066475868225\n",
      "epoch 606 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 606 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 606 after parameter update : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 607 loss is 1.0450663566589355\n",
      "epoch 607 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 607 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 607 after parameter update : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 608 loss is 1.0450663566589355\n",
      "epoch 608 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 608 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 608 after parameter update : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 609 loss is 1.045066475868225\n",
      "epoch 609 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 609 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 609 after parameter update : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 610 loss is 1.0450663566589355\n",
      "epoch 610 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 610 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 610 after parameter update : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 611 loss is 1.0450667142868042\n",
      "epoch 611 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 611 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 611 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 612 loss is 1.045066475868225\n",
      "epoch 612 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 612 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 612 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 613 loss is 1.045066475868225\n",
      "epoch 613 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 613 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 613 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 614 loss is 1.045066237449646\n",
      "epoch 614 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 614 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 614 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 615 loss is 1.0450665950775146\n",
      "epoch 615 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 615 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 615 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 616 loss is 1.045066237449646\n",
      "epoch 616 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 616 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 616 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 617 loss is 1.045066237449646\n",
      "epoch 617 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 617 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 617 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 618 loss is 1.0450663566589355\n",
      "epoch 618 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 618 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 618 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 619 loss is 1.0450663566589355\n",
      "epoch 619 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 619 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 619 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 620 loss is 1.0450661182403564\n",
      "epoch 620 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 620 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 620 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 621 loss is 1.0450665950775146\n",
      "epoch 621 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 621 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 621 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 622 loss is 1.0450663566589355\n",
      "epoch 622 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 622 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 622 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 623 loss is 1.045066237449646\n",
      "epoch 623 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 623 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 623 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 624 loss is 1.045066475868225\n",
      "epoch 624 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 624 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 624 after parameter update : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 625 loss is 1.045066475868225\n",
      "epoch 625 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 625 : params.grad right after loss.backward(): tensor([-0.0007, -0.0001])\n",
      "epoch 625 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 626 loss is 1.045066475868225\n",
      "epoch 626 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 626 : params.grad right after loss.backward(): tensor([-0.0007, -0.0001])\n",
      "epoch 626 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 627 loss is 1.0450663566589355\n",
      "epoch 627 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 627 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 627 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 628 loss is 1.045066475868225\n",
      "epoch 628 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 628 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 628 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 629 loss is 1.045066475868225\n",
      "epoch 629 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 629 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 629 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 630 loss is 1.0450663566589355\n",
      "epoch 630 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 630 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 630 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 631 loss is 1.0450661182403564\n",
      "epoch 631 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 631 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 631 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 632 loss is 1.0450663566589355\n",
      "epoch 632 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 632 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 632 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 633 loss is 1.0450663566589355\n",
      "epoch 633 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 633 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 633 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 634 loss is 1.045066237449646\n",
      "epoch 634 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 634 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 634 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 635 loss is 1.0450663566589355\n",
      "epoch 635 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 635 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 635 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 636 loss is 1.0450661182403564\n",
      "epoch 636 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 636 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 636 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 637 loss is 1.045066237449646\n",
      "epoch 637 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 637 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 637 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 638 loss is 1.045066237449646\n",
      "epoch 638 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 638 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 638 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 639 loss is 1.0450663566589355\n",
      "epoch 639 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 639 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 639 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 640 loss is 1.0450663566589355\n",
      "epoch 640 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 640 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 640 after parameter update : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 641 loss is 1.0450661182403564\n",
      "epoch 641 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 641 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 641 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 642 loss is 1.0450663566589355\n",
      "epoch 642 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 642 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 642 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 643 loss is 1.0450667142868042\n",
      "epoch 643 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 643 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 643 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 644 loss is 1.0450665950775146\n",
      "epoch 644 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 644 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 644 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 645 loss is 1.0450661182403564\n",
      "epoch 645 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 645 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 645 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 646 loss is 1.045066237449646\n",
      "epoch 646 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 646 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 646 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 647 loss is 1.045066237449646\n",
      "epoch 647 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 647 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 647 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 648 loss is 1.045066237449646\n",
      "epoch 648 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 648 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 648 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 649 loss is 1.045066237449646\n",
      "epoch 649 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 649 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 649 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 650 loss is 1.045066475868225\n",
      "epoch 650 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 650 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 650 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 651 loss is 1.045066237449646\n",
      "epoch 651 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 651 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 651 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 652 loss is 1.0450663566589355\n",
      "epoch 652 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 652 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 652 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 653 loss is 1.0450661182403564\n",
      "epoch 653 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 653 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 653 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 654 loss is 1.0450661182403564\n",
      "epoch 654 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 654 : params.grad right after loss.backward(): tensor([-4.4786e-04, -9.8750e-05])\n",
      "epoch 654 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 655 loss is 1.0450665950775146\n",
      "epoch 655 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 655 : params.grad right after loss.backward(): tensor([-4.4162e-04, -9.7252e-05])\n",
      "epoch 655 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 656 loss is 1.0450663566589355\n",
      "epoch 656 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 656 : params.grad right after loss.backward(): tensor([-4.3545e-04, -9.5934e-05])\n",
      "epoch 656 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 657 loss is 1.0450658798217773\n",
      "epoch 657 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 657 : params.grad right after loss.backward(): tensor([-4.2957e-04, -9.4522e-05])\n",
      "epoch 657 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 658 loss is 1.0450661182403564\n",
      "epoch 658 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 658 : params.grad right after loss.backward(): tensor([-4.2372e-04, -9.3088e-05])\n",
      "epoch 658 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 659 loss is 1.045066237449646\n",
      "epoch 659 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 659 : params.grad right after loss.backward(): tensor([-4.1781e-04, -9.1664e-05])\n",
      "epoch 659 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 660 loss is 1.045066237449646\n",
      "epoch 660 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 660 : params.grad right after loss.backward(): tensor([-4.1197e-04, -9.0294e-05])\n",
      "epoch 660 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 661 loss is 1.0450661182403564\n",
      "epoch 661 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 661 : params.grad right after loss.backward(): tensor([-4.0637e-04, -8.8792e-05])\n",
      "epoch 661 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 662 loss is 1.045066237449646\n",
      "epoch 662 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 662 : params.grad right after loss.backward(): tensor([-4.0084e-04, -8.7366e-05])\n",
      "epoch 662 after parameter update : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 663 loss is 1.0450661182403564\n",
      "epoch 663 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 663 : params.grad right after loss.backward(): tensor([-3.9530e-04, -8.5931e-05])\n",
      "epoch 663 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 664 loss is 1.045066237449646\n",
      "epoch 664 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 664 : params.grad right after loss.backward(): tensor([-3.8984e-04, -8.4519e-05])\n",
      "epoch 664 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 665 loss is 1.0450661182403564\n",
      "epoch 665 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 665 : params.grad right after loss.backward(): tensor([-3.8462e-04, -8.3040e-05])\n",
      "epoch 665 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 666 loss is 1.045066237449646\n",
      "epoch 666 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 666 : params.grad right after loss.backward(): tensor([-3.7942e-04, -8.1558e-05])\n",
      "epoch 666 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 667 loss is 1.045065999031067\n",
      "epoch 667 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 667 : params.grad right after loss.backward(): tensor([-3.7416e-04, -8.0042e-05])\n",
      "epoch 667 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 668 loss is 1.0450663566589355\n",
      "epoch 668 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 668 : params.grad right after loss.backward(): tensor([-3.6897e-04, -7.8574e-05])\n",
      "epoch 668 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 669 loss is 1.045066237449646\n",
      "epoch 669 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 669 : params.grad right after loss.backward(): tensor([-3.6409e-04, -7.7099e-05])\n",
      "epoch 669 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 670 loss is 1.0450661182403564\n",
      "epoch 670 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 670 : params.grad right after loss.backward(): tensor([-3.5921e-04, -7.5623e-05])\n",
      "epoch 670 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 671 loss is 1.0450661182403564\n",
      "epoch 671 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 671 : params.grad right after loss.backward(): tensor([-3.5427e-04, -7.4059e-05])\n",
      "epoch 671 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 672 loss is 1.045066237449646\n",
      "epoch 672 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 672 : params.grad right after loss.backward(): tensor([-3.4945e-04, -7.2543e-05])\n",
      "epoch 672 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 673 loss is 1.045066237449646\n",
      "epoch 673 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 673 : params.grad right after loss.backward(): tensor([-3.4463e-04, -7.1082e-05])\n",
      "epoch 673 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 674 loss is 1.0450658798217773\n",
      "epoch 674 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 674 : params.grad right after loss.backward(): tensor([-3.4003e-04, -7.0516e-05])\n",
      "epoch 674 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 675 loss is 1.0450663566589355\n",
      "epoch 675 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 675 : params.grad right after loss.backward(): tensor([-3.3545e-04, -6.9939e-05])\n",
      "epoch 675 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 676 loss is 1.0450663566589355\n",
      "epoch 676 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 676 : params.grad right after loss.backward(): tensor([-3.3083e-04, -6.9387e-05])\n",
      "epoch 676 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 677 loss is 1.0450665950775146\n",
      "epoch 677 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 677 : params.grad right after loss.backward(): tensor([-3.2627e-04, -6.8773e-05])\n",
      "epoch 677 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 678 loss is 1.045065999031067\n",
      "epoch 678 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 678 : params.grad right after loss.backward(): tensor([-3.2165e-04, -6.8203e-05])\n",
      "epoch 678 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 679 loss is 1.0450661182403564\n",
      "epoch 679 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 679 : params.grad right after loss.backward(): tensor([-3.1740e-04, -6.7640e-05])\n",
      "epoch 679 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 680 loss is 1.0450657606124878\n",
      "epoch 680 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 680 : params.grad right after loss.backward(): tensor([-3.1313e-04, -6.7048e-05])\n",
      "epoch 680 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 681 loss is 1.0450663566589355\n",
      "epoch 681 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 681 : params.grad right after loss.backward(): tensor([-3.0889e-04, -6.6422e-05])\n",
      "epoch 681 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 682 loss is 1.045065999031067\n",
      "epoch 682 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 682 : params.grad right after loss.backward(): tensor([-3.0448e-04, -6.5800e-05])\n",
      "epoch 682 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 683 loss is 1.045066237449646\n",
      "epoch 683 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 683 : params.grad right after loss.backward(): tensor([-3.0036e-04, -6.5237e-05])\n",
      "epoch 683 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 684 loss is 1.0450661182403564\n",
      "epoch 684 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 684 : params.grad right after loss.backward(): tensor([-2.9604e-04, -6.4638e-05])\n",
      "epoch 684 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 685 loss is 1.045065999031067\n",
      "epoch 685 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 685 : params.grad right after loss.backward(): tensor([-2.9210e-04, -6.3967e-05])\n",
      "epoch 685 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 686 loss is 1.0450661182403564\n",
      "epoch 686 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 686 : params.grad right after loss.backward(): tensor([-2.8820e-04, -6.3341e-05])\n",
      "epoch 686 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 687 loss is 1.0450661182403564\n",
      "epoch 687 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 687 : params.grad right after loss.backward(): tensor([-2.8422e-04, -6.2745e-05])\n",
      "epoch 687 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 688 loss is 1.0450663566589355\n",
      "epoch 688 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 688 : params.grad right after loss.backward(): tensor([-2.8035e-04, -6.2101e-05])\n",
      "epoch 688 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 689 loss is 1.0450663566589355\n",
      "epoch 689 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 689 : params.grad right after loss.backward(): tensor([-2.7639e-04, -6.1456e-05])\n",
      "epoch 689 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 690 loss is 1.045066475868225\n",
      "epoch 690 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 690 : params.grad right after loss.backward(): tensor([-2.7241e-04, -6.0849e-05])\n",
      "epoch 690 after parameter update : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 691 loss is 1.0450663566589355\n",
      "epoch 691 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 691 : params.grad right after loss.backward(): tensor([-2.6885e-04, -6.0167e-05])\n",
      "epoch 691 after parameter update : tensor([2.9485, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 692 loss is 1.045066237449646\n",
      "epoch 692 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 692 : params.grad right after loss.backward(): tensor([-2.6525e-04, -5.9515e-05])\n",
      "epoch 692 after parameter update : tensor([2.9485, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 693 loss is 1.0450663566589355\n",
      "epoch 693 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 693 : params.grad right after loss.backward(): tensor([-2.6166e-04, -5.8811e-05])\n",
      "epoch 693 after parameter update : tensor([2.9485, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 694 loss is 1.045066237449646\n",
      "epoch 694 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 694 : params.grad right after loss.backward(): tensor([-2.5812e-04, -5.8256e-05])\n",
      "epoch 694 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 695 loss is 1.045065999031067\n",
      "epoch 695 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 695 : params.grad right after loss.backward(): tensor([-2.5443e-04, -5.7533e-05])\n",
      "epoch 695 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 696 loss is 1.045066237449646\n",
      "epoch 696 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 696 : params.grad right after loss.backward(): tensor([-2.5089e-04, -5.6908e-05])\n",
      "epoch 696 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 697 loss is 1.0450661182403564\n",
      "epoch 697 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 697 : params.grad right after loss.backward(): tensor([-2.4721e-04, -5.6230e-05])\n",
      "epoch 697 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 698 loss is 1.0450661182403564\n",
      "epoch 698 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 698 : params.grad right after loss.backward(): tensor([-2.4394e-04, -5.5522e-05])\n",
      "epoch 698 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 699 loss is 1.0450661182403564\n",
      "epoch 699 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 699 : params.grad right after loss.backward(): tensor([-2.4074e-04, -5.4885e-05])\n",
      "epoch 699 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 700 loss is 1.045066237449646\n",
      "epoch 700 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 700 : params.grad right after loss.backward(): tensor([-2.3744e-04, -5.4181e-05])\n",
      "epoch 700 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 701 loss is 1.0450661182403564\n",
      "epoch 701 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 701 : params.grad right after loss.backward(): tensor([-2.3419e-04, -5.3532e-05])\n",
      "epoch 701 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 702 loss is 1.0450661182403564\n",
      "epoch 702 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 702 : params.grad right after loss.backward(): tensor([-2.3093e-04, -5.2828e-05])\n",
      "epoch 702 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 703 loss is 1.0450663566589355\n",
      "epoch 703 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 703 : params.grad right after loss.backward(): tensor([-2.2765e-04, -5.2113e-05])\n",
      "epoch 703 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 704 loss is 1.045066237449646\n",
      "epoch 704 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 704 : params.grad right after loss.backward(): tensor([-2.2434e-04, -5.1424e-05])\n",
      "epoch 704 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 705 loss is 1.0450663566589355\n",
      "epoch 705 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 705 : params.grad right after loss.backward(): tensor([-2.2151e-04, -5.0776e-05])\n",
      "epoch 705 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 706 loss is 1.0450663566589355\n",
      "epoch 706 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 706 : params.grad right after loss.backward(): tensor([-2.1850e-04, -5.0016e-05])\n",
      "epoch 706 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 707 loss is 1.0450661182403564\n",
      "epoch 707 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 707 : params.grad right after loss.backward(): tensor([-2.1563e-04, -4.9386e-05])\n",
      "epoch 707 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 708 loss is 1.0450663566589355\n",
      "epoch 708 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 708 : params.grad right after loss.backward(): tensor([-2.1264e-04, -4.8626e-05])\n",
      "epoch 708 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 709 loss is 1.045065999031067\n",
      "epoch 709 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 709 : params.grad right after loss.backward(): tensor([-2.0968e-04, -4.7944e-05])\n",
      "epoch 709 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 710 loss is 1.0450661182403564\n",
      "epoch 710 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 710 : params.grad right after loss.backward(): tensor([-2.0681e-04, -4.7136e-05])\n",
      "epoch 710 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 711 loss is 1.0450661182403564\n",
      "epoch 711 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 711 : params.grad right after loss.backward(): tensor([-2.0382e-04, -4.6484e-05])\n",
      "epoch 711 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 712 loss is 1.0450661182403564\n",
      "epoch 712 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 712 : params.grad right after loss.backward(): tensor([-2.0090e-04, -4.5754e-05])\n",
      "epoch 712 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 713 loss is 1.0450661182403564\n",
      "epoch 713 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 713 : params.grad right after loss.backward(): tensor([-1.9825e-04, -4.4979e-05])\n",
      "epoch 713 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 714 loss is 1.045066237449646\n",
      "epoch 714 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 714 : params.grad right after loss.backward(): tensor([-1.9572e-04, -4.4353e-05])\n",
      "epoch 714 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 715 loss is 1.045066237449646\n",
      "epoch 715 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 715 : params.grad right after loss.backward(): tensor([-1.9313e-04, -4.3623e-05])\n",
      "epoch 715 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 716 loss is 1.0450661182403564\n",
      "epoch 716 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 716 : params.grad right after loss.backward(): tensor([-1.9053e-04, -4.2856e-05])\n",
      "epoch 716 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 717 loss is 1.045065999031067\n",
      "epoch 717 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 717 : params.grad right after loss.backward(): tensor([-1.8790e-04, -4.2107e-05])\n",
      "epoch 717 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 718 loss is 1.0450658798217773\n",
      "epoch 718 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 718 : params.grad right after loss.backward(): tensor([-1.8536e-04, -4.1399e-05])\n",
      "epoch 718 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 719 loss is 1.045065999031067\n",
      "epoch 719 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 719 : params.grad right after loss.backward(): tensor([-1.8272e-04, -4.0673e-05])\n",
      "epoch 719 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 720 loss is 1.0450661182403564\n",
      "epoch 720 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 720 : params.grad right after loss.backward(): tensor([-1.8013e-04, -3.9965e-05])\n",
      "epoch 720 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 721 loss is 1.0450663566589355\n",
      "epoch 721 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 721 : params.grad right after loss.backward(): tensor([-1.7749e-04, -3.9168e-05])\n",
      "epoch 721 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 722 loss is 1.0450661182403564\n",
      "epoch 722 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 722 : params.grad right after loss.backward(): tensor([-1.7518e-04, -3.8389e-05])\n",
      "epoch 722 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 723 loss is 1.045065999031067\n",
      "epoch 723 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 723 : params.grad right after loss.backward(): tensor([-1.7292e-04, -3.7581e-05])\n",
      "epoch 723 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 724 loss is 1.0450658798217773\n",
      "epoch 724 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 724 : params.grad right after loss.backward(): tensor([-1.7072e-04, -3.6996e-05])\n",
      "epoch 724 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 725 loss is 1.0450661182403564\n",
      "epoch 725 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 725 : params.grad right after loss.backward(): tensor([-1.6843e-04, -3.6068e-05])\n",
      "epoch 725 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 726 loss is 1.045065999031067\n",
      "epoch 726 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 726 : params.grad right after loss.backward(): tensor([-1.6610e-04, -3.5387e-05])\n",
      "epoch 726 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 727 loss is 1.0450661182403564\n",
      "epoch 727 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 727 : params.grad right after loss.backward(): tensor([-1.6388e-04, -3.4615e-05])\n",
      "epoch 727 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 728 loss is 1.0450663566589355\n",
      "epoch 728 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 728 : params.grad right after loss.backward(): tensor([-1.6152e-04, -3.3833e-05])\n",
      "epoch 728 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 729 loss is 1.045066237449646\n",
      "epoch 729 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 729 : params.grad right after loss.backward(): tensor([-1.5932e-04, -3.3036e-05])\n",
      "epoch 729 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 730 loss is 1.0450661182403564\n",
      "epoch 730 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 730 : params.grad right after loss.backward(): tensor([-1.5705e-04, -3.2276e-05])\n",
      "epoch 730 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 731 loss is 1.0450661182403564\n",
      "epoch 731 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 731 : params.grad right after loss.backward(): tensor([-1.5478e-04, -3.1497e-05])\n",
      "epoch 731 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 732 loss is 1.045065999031067\n",
      "epoch 732 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 732 : params.grad right after loss.backward(): tensor([-1.5280e-04, -3.0745e-05])\n",
      "epoch 732 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 733 loss is 1.0450661182403564\n",
      "epoch 733 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 733 : params.grad right after loss.backward(): tensor([-1.5088e-04, -2.9933e-05])\n",
      "epoch 733 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 734 loss is 1.0450661182403564\n",
      "epoch 734 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 734 : params.grad right after loss.backward(): tensor([-1.4895e-04, -2.9095e-05])\n",
      "epoch 734 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 735 loss is 1.0450663566589355\n",
      "epoch 735 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 735 : params.grad right after loss.backward(): tensor([-1.4701e-04, -2.8342e-05])\n",
      "epoch 735 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 736 loss is 1.0450663566589355\n",
      "epoch 736 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 736 : params.grad right after loss.backward(): tensor([-1.4511e-04, -2.7582e-05])\n",
      "epoch 736 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 737 loss is 1.0450663566589355\n",
      "epoch 737 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 737 : params.grad right after loss.backward(): tensor([-1.4311e-04, -2.6781e-05])\n",
      "epoch 737 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 738 loss is 1.0450663566589355\n",
      "epoch 738 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 738 : params.grad right after loss.backward(): tensor([-1.4125e-04, -2.6029e-05])\n",
      "epoch 738 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 739 loss is 1.0450661182403564\n",
      "epoch 739 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 739 : params.grad right after loss.backward(): tensor([-1.3924e-04, -2.5161e-05])\n",
      "epoch 739 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 740 loss is 1.0450663566589355\n",
      "epoch 740 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 740 : params.grad right after loss.backward(): tensor([-1.3734e-04, -2.4371e-05])\n",
      "epoch 740 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 741 loss is 1.0450663566589355\n",
      "epoch 741 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 741 : params.grad right after loss.backward(): tensor([-1.3535e-04, -2.3596e-05])\n",
      "epoch 741 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 742 loss is 1.045066237449646\n",
      "epoch 742 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 742 : params.grad right after loss.backward(): tensor([-1.3338e-04, -2.3756e-05])\n",
      "epoch 742 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 743 loss is 1.0450663566589355\n",
      "epoch 743 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 743 : params.grad right after loss.backward(): tensor([-1.3141e-04, -2.3942e-05])\n",
      "epoch 743 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 744 loss is 1.0450663566589355\n",
      "epoch 744 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 744 : params.grad right after loss.backward(): tensor([-1.2943e-04, -2.3123e-05])\n",
      "epoch 744 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 745 loss is 1.045066237449646\n",
      "epoch 745 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 745 : params.grad right after loss.backward(): tensor([-1.2786e-04, -2.3324e-05])\n",
      "epoch 745 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 746 loss is 1.0450661182403564\n",
      "epoch 746 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 746 : params.grad right after loss.backward(): tensor([-1.2617e-04, -2.3458e-05])\n",
      "epoch 746 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 747 loss is 1.0450661182403564\n",
      "epoch 747 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 747 : params.grad right after loss.backward(): tensor([-1.2445e-04, -2.3540e-05])\n",
      "epoch 747 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 748 loss is 1.0450661182403564\n",
      "epoch 748 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 748 : params.grad right after loss.backward(): tensor([-1.2278e-04, -2.3637e-05])\n",
      "epoch 748 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 749 loss is 1.045065999031067\n",
      "epoch 749 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 749 : params.grad right after loss.backward(): tensor([-1.2112e-04, -2.3790e-05])\n",
      "epoch 749 after parameter update : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 750 loss is 1.0450661182403564\n",
      "epoch 750 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 750 : params.grad right after loss.backward(): tensor([-1.1941e-04, -2.3924e-05])\n",
      "epoch 750 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 751 loss is 1.045065999031067\n",
      "epoch 751 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 751 : params.grad right after loss.backward(): tensor([-1.1788e-04, -2.3130e-05])\n",
      "epoch 751 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 752 loss is 1.0450658798217773\n",
      "epoch 752 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 752 : params.grad right after loss.backward(): tensor([-1.1622e-04, -2.3268e-05])\n",
      "epoch 752 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 753 loss is 1.045065999031067\n",
      "epoch 753 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 753 : params.grad right after loss.backward(): tensor([-1.1457e-04, -2.3413e-05])\n",
      "epoch 753 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 754 loss is 1.0450663566589355\n",
      "epoch 754 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 754 : params.grad right after loss.backward(): tensor([-1.1293e-04, -2.3525e-05])\n",
      "epoch 754 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 755 loss is 1.0450661182403564\n",
      "epoch 755 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 755 : params.grad right after loss.backward(): tensor([-1.1123e-04, -2.3667e-05])\n",
      "epoch 755 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 756 loss is 1.0450663566589355\n",
      "epoch 756 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 756 : params.grad right after loss.backward(): tensor([-1.0961e-04, -2.3831e-05])\n",
      "epoch 756 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 757 loss is 1.0450663566589355\n",
      "epoch 757 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 757 : params.grad right after loss.backward(): tensor([-1.0789e-04, -2.3939e-05])\n",
      "epoch 757 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 758 loss is 1.0450661182403564\n",
      "epoch 758 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 758 : params.grad right after loss.backward(): tensor([-1.0638e-04, -2.3197e-05])\n",
      "epoch 758 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 759 loss is 1.045066475868225\n",
      "epoch 759 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 759 : params.grad right after loss.backward(): tensor([-1.0502e-04, -2.3283e-05])\n",
      "epoch 759 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 760 loss is 1.045066237449646\n",
      "epoch 760 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 760 : params.grad right after loss.backward(): tensor([-1.0359e-04, -2.3298e-05])\n",
      "epoch 760 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 761 loss is 1.045066237449646\n",
      "epoch 761 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 761 : params.grad right after loss.backward(): tensor([-1.0229e-04, -2.3410e-05])\n",
      "epoch 761 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 762 loss is 1.045065999031067\n",
      "epoch 762 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 762 : params.grad right after loss.backward(): tensor([-1.0095e-04, -2.3540e-05])\n",
      "epoch 762 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 763 loss is 1.045065999031067\n",
      "epoch 763 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 763 : params.grad right after loss.backward(): tensor([-9.9726e-05, -2.3689e-05])\n",
      "epoch 763 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 764 loss is 1.045065999031067\n",
      "epoch 764 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 764 : params.grad right after loss.backward(): tensor([-9.8363e-05, -2.3834e-05])\n",
      "epoch 764 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 765 loss is 1.0450661182403564\n",
      "epoch 765 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 765 : params.grad right after loss.backward(): tensor([-9.7066e-05, -2.3913e-05])\n",
      "epoch 765 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 766 loss is 1.0450663566589355\n",
      "epoch 766 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 766 : params.grad right after loss.backward(): tensor([-9.5777e-05, -2.3086e-05])\n",
      "epoch 766 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 767 loss is 1.0450661182403564\n",
      "epoch 767 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 767 : params.grad right after loss.backward(): tensor([-9.4481e-05, -2.3205e-05])\n",
      "epoch 767 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 768 loss is 1.0450661182403564\n",
      "epoch 768 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 768 : params.grad right after loss.backward(): tensor([-9.3035e-05, -2.3209e-05])\n",
      "epoch 768 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 769 loss is 1.0450661182403564\n",
      "epoch 769 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 769 : params.grad right after loss.backward(): tensor([-9.1717e-05, -2.3384e-05])\n",
      "epoch 769 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 770 loss is 1.0450661182403564\n",
      "epoch 770 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 770 : params.grad right after loss.backward(): tensor([-9.0428e-05, -2.3469e-05])\n",
      "epoch 770 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 771 loss is 1.0450661182403564\n",
      "epoch 771 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 771 : params.grad right after loss.backward(): tensor([-8.9057e-05, -2.3544e-05])\n",
      "epoch 771 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 772 loss is 1.0450663566589355\n",
      "epoch 772 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 772 : params.grad right after loss.backward(): tensor([-8.7760e-05, -2.3693e-05])\n",
      "epoch 772 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 773 loss is 1.0450663566589355\n",
      "epoch 773 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 773 : params.grad right after loss.backward(): tensor([-8.6427e-05, -2.3793e-05])\n",
      "epoch 773 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 774 loss is 1.0450663566589355\n",
      "epoch 774 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 774 : params.grad right after loss.backward(): tensor([-8.5078e-05, -2.3909e-05])\n",
      "epoch 774 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 775 loss is 1.045066237449646\n",
      "epoch 775 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 775 : params.grad right after loss.backward(): tensor([-8.3767e-05, -2.3015e-05])\n",
      "epoch 775 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 776 loss is 1.0450661182403564\n",
      "epoch 776 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 776 : params.grad right after loss.backward(): tensor([-8.2500e-05, -2.3164e-05])\n",
      "epoch 776 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 777 loss is 1.0450663566589355\n",
      "epoch 777 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 777 : params.grad right after loss.backward(): tensor([-8.1509e-05, -2.3283e-05])\n",
      "epoch 777 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 778 loss is 1.0450663566589355\n",
      "epoch 778 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 778 : params.grad right after loss.backward(): tensor([-8.0504e-05, -2.3369e-05])\n",
      "epoch 778 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 779 loss is 1.0450663566589355\n",
      "epoch 779 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 779 : params.grad right after loss.backward(): tensor([-7.9483e-05, -2.3380e-05])\n",
      "epoch 779 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 780 loss is 1.0450663566589355\n",
      "epoch 780 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 780 : params.grad right after loss.backward(): tensor([-7.8529e-05, -2.3488e-05])\n",
      "epoch 780 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 781 loss is 1.0450663566589355\n",
      "epoch 781 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 781 : params.grad right after loss.backward(): tensor([-7.7531e-05, -2.3596e-05])\n",
      "epoch 781 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 782 loss is 1.045066237449646\n",
      "epoch 782 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 782 : params.grad right after loss.backward(): tensor([-7.6540e-05, -2.3670e-05])\n",
      "epoch 782 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 783 loss is 1.0450663566589355\n",
      "epoch 783 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 783 : params.grad right after loss.backward(): tensor([-7.5571e-05, -2.3771e-05])\n",
      "epoch 783 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 784 loss is 1.0450661182403564\n",
      "epoch 784 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 784 : params.grad right after loss.backward(): tensor([-7.4476e-05, -2.3793e-05])\n",
      "epoch 784 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 785 loss is 1.045066237449646\n",
      "epoch 785 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 785 : params.grad right after loss.backward(): tensor([-7.3560e-05, -2.3965e-05])\n",
      "epoch 785 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 786 loss is 1.045066237449646\n",
      "epoch 786 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 786 : params.grad right after loss.backward(): tensor([-7.2658e-05, -2.3045e-05])\n",
      "epoch 786 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 787 loss is 1.0450658798217773\n",
      "epoch 787 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 787 : params.grad right after loss.backward(): tensor([-7.1563e-05, -2.3115e-05])\n",
      "epoch 787 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 788 loss is 1.0450658798217773\n",
      "epoch 788 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 788 : params.grad right after loss.backward(): tensor([-7.0646e-05, -2.3257e-05])\n",
      "epoch 788 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 789 loss is 1.0450661182403564\n",
      "epoch 789 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 789 : params.grad right after loss.backward(): tensor([-6.9641e-05, -2.3313e-05])\n",
      "epoch 789 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 790 loss is 1.0450663566589355\n",
      "epoch 790 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 790 : params.grad right after loss.backward(): tensor([-6.8620e-05, -2.3365e-05])\n",
      "epoch 790 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 791 loss is 1.045066237449646\n",
      "epoch 791 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 791 : params.grad right after loss.backward(): tensor([-6.7629e-05, -2.3421e-05])\n",
      "epoch 791 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 792 loss is 1.0450658798217773\n",
      "epoch 792 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 792 : params.grad right after loss.backward(): tensor([-6.6638e-05, -2.3495e-05])\n",
      "epoch 792 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 793 loss is 1.0450661182403564\n",
      "epoch 793 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 793 : params.grad right after loss.backward(): tensor([-6.5617e-05, -2.3637e-05])\n",
      "epoch 793 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 794 loss is 1.0450657606124878\n",
      "epoch 794 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 794 : params.grad right after loss.backward(): tensor([-6.4656e-05, -2.3723e-05])\n",
      "epoch 794 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 795 loss is 1.0450656414031982\n",
      "epoch 795 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 795 : params.grad right after loss.backward(): tensor([-6.3628e-05, -2.3782e-05])\n",
      "epoch 795 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 796 loss is 1.0450658798217773\n",
      "epoch 796 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 796 : params.grad right after loss.backward(): tensor([-6.2667e-05, -2.3823e-05])\n",
      "epoch 796 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 797 loss is 1.045066237449646\n",
      "epoch 797 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 797 : params.grad right after loss.backward(): tensor([-6.1624e-05, -2.3924e-05])\n",
      "epoch 797 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 798 loss is 1.0450663566589355\n",
      "epoch 798 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 798 : params.grad right after loss.backward(): tensor([-6.0655e-05, -2.3067e-05])\n",
      "epoch 798 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 799 loss is 1.0450661182403564\n",
      "epoch 799 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 799 : params.grad right after loss.backward(): tensor([-5.9694e-05, -2.3142e-05])\n",
      "epoch 799 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 800 loss is 1.0450661182403564\n",
      "epoch 800 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 800 : params.grad right after loss.backward(): tensor([-5.8651e-05, -2.3216e-05])\n",
      "epoch 800 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 801 loss is 1.045065999031067\n",
      "epoch 801 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 801 : params.grad right after loss.backward(): tensor([-5.8055e-05, -2.3305e-05])\n",
      "epoch 801 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 802 loss is 1.0450658798217773\n",
      "epoch 802 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 802 : params.grad right after loss.backward(): tensor([-5.7355e-05, -2.3317e-05])\n",
      "epoch 802 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 803 loss is 1.0450658798217773\n",
      "epoch 803 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 803 : params.grad right after loss.backward(): tensor([-5.6736e-05, -2.3402e-05])\n",
      "epoch 803 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 804 loss is 1.0450661182403564\n",
      "epoch 804 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 804 : params.grad right after loss.backward(): tensor([-5.6073e-05, -2.3406e-05])\n",
      "epoch 804 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 805 loss is 1.0450658798217773\n",
      "epoch 805 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 805 : params.grad right after loss.backward(): tensor([-5.5395e-05, -2.3492e-05])\n",
      "epoch 805 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 806 loss is 1.0450656414031982\n",
      "epoch 806 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 806 : params.grad right after loss.backward(): tensor([-5.4702e-05, -2.3540e-05])\n",
      "epoch 806 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 807 loss is 1.0450658798217773\n",
      "epoch 807 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 807 : params.grad right after loss.backward(): tensor([-5.4039e-05, -2.3581e-05])\n",
      "epoch 807 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 808 loss is 1.0450661182403564\n",
      "epoch 808 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 808 : params.grad right after loss.backward(): tensor([-5.3450e-05, -2.3656e-05])\n",
      "epoch 808 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 809 loss is 1.045065999031067\n",
      "epoch 809 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 809 : params.grad right after loss.backward(): tensor([-5.2646e-05, -2.3603e-05])\n",
      "epoch 809 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 810 loss is 1.0450661182403564\n",
      "epoch 810 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 810 : params.grad right after loss.backward(): tensor([-5.2176e-05, -2.3816e-05])\n",
      "epoch 810 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 811 loss is 1.0450658798217773\n",
      "epoch 811 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 811 : params.grad right after loss.backward(): tensor([-5.1327e-05, -2.3756e-05])\n",
      "epoch 811 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 812 loss is 1.0450661182403564\n",
      "epoch 812 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 812 : params.grad right after loss.backward(): tensor([-5.0791e-05, -2.3954e-05])\n",
      "epoch 812 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 813 loss is 1.0450663566589355\n",
      "epoch 813 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 813 : params.grad right after loss.backward(): tensor([-5.0008e-05, -2.2952e-05])\n",
      "epoch 813 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 814 loss is 1.045066237449646\n",
      "epoch 814 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 814 : params.grad right after loss.backward(): tensor([-4.9479e-05, -2.3082e-05])\n",
      "epoch 814 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 815 loss is 1.0450661182403564\n",
      "epoch 815 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 815 : params.grad right after loss.backward(): tensor([-4.8764e-05, -2.3093e-05])\n",
      "epoch 815 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 816 loss is 1.0450661182403564\n",
      "epoch 816 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 816 : params.grad right after loss.backward(): tensor([-4.8108e-05, -2.3138e-05])\n",
      "epoch 816 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 817 loss is 1.0450661182403564\n",
      "epoch 817 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 817 : params.grad right after loss.backward(): tensor([-4.7497e-05, -2.3261e-05])\n",
      "epoch 817 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 818 loss is 1.0450661182403564\n",
      "epoch 818 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 818 : params.grad right after loss.backward(): tensor([-4.6805e-05, -2.3272e-05])\n",
      "epoch 818 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 819 loss is 1.0450661182403564\n",
      "epoch 819 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 819 : params.grad right after loss.backward(): tensor([-4.6119e-05, -2.3369e-05])\n",
      "epoch 819 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 820 loss is 1.0450661182403564\n",
      "epoch 820 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 820 : params.grad right after loss.backward(): tensor([-4.5471e-05, -2.3354e-05])\n",
      "epoch 820 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 821 loss is 1.0450661182403564\n",
      "epoch 821 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 821 : params.grad right after loss.backward(): tensor([-4.4815e-05, -2.3440e-05])\n",
      "epoch 821 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 822 loss is 1.0450661182403564\n",
      "epoch 822 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 822 : params.grad right after loss.backward(): tensor([-4.4145e-05, -2.3458e-05])\n",
      "epoch 822 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 823 loss is 1.045066237449646\n",
      "epoch 823 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 823 : params.grad right after loss.backward(): tensor([-4.3452e-05, -2.3529e-05])\n",
      "epoch 823 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 824 loss is 1.0450663566589355\n",
      "epoch 824 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 824 : params.grad right after loss.backward(): tensor([-4.2789e-05, -2.3518e-05])\n",
      "epoch 824 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 825 loss is 1.0450663566589355\n",
      "epoch 825 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 825 : params.grad right after loss.backward(): tensor([-4.2088e-05, -2.3581e-05])\n",
      "epoch 825 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 826 loss is 1.0450661182403564\n",
      "epoch 826 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 826 : params.grad right after loss.backward(): tensor([-4.1507e-05, -2.3678e-05])\n",
      "epoch 826 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 827 loss is 1.0450661182403564\n",
      "epoch 827 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 827 : params.grad right after loss.backward(): tensor([-4.0837e-05, -2.3689e-05])\n",
      "epoch 827 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 828 loss is 1.045066237449646\n",
      "epoch 828 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 828 : params.grad right after loss.backward(): tensor([-4.0129e-05, -2.3790e-05])\n",
      "epoch 828 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 829 loss is 1.0450663566589355\n",
      "epoch 829 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 829 : params.grad right after loss.backward(): tensor([-3.9540e-05, -2.3905e-05])\n",
      "epoch 829 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 830 loss is 1.045065999031067\n",
      "epoch 830 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 830 : params.grad right after loss.backward(): tensor([-3.8870e-05, -2.2952e-05])\n",
      "epoch 830 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 831 loss is 1.0450661182403564\n",
      "epoch 831 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 831 : params.grad right after loss.backward(): tensor([-3.8214e-05, -2.2966e-05])\n",
      "epoch 831 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 832 loss is 1.045065999031067\n",
      "epoch 832 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 832 : params.grad right after loss.backward(): tensor([-3.7581e-05, -2.3026e-05])\n",
      "epoch 832 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 833 loss is 1.0450661182403564\n",
      "epoch 833 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 833 : params.grad right after loss.backward(): tensor([-3.6828e-05, -2.3060e-05])\n",
      "epoch 833 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 834 loss is 1.0450661182403564\n",
      "epoch 834 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 834 : params.grad right after loss.backward(): tensor([-3.6240e-05, -2.3138e-05])\n",
      "epoch 834 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 835 loss is 1.0450661182403564\n",
      "epoch 835 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 835 : params.grad right after loss.backward(): tensor([-3.5584e-05, -2.3238e-05])\n",
      "epoch 835 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 836 loss is 1.0450663566589355\n",
      "epoch 836 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 836 : params.grad right after loss.backward(): tensor([-3.5211e-05, -2.3201e-05])\n",
      "epoch 836 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 837 loss is 1.045066237449646\n",
      "epoch 837 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 837 : params.grad right after loss.backward(): tensor([-3.4891e-05, -2.3253e-05])\n",
      "epoch 837 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 838 loss is 1.0450663566589355\n",
      "epoch 838 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 838 : params.grad right after loss.backward(): tensor([-3.4548e-05, -2.3220e-05])\n",
      "epoch 838 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 839 loss is 1.0450663566589355\n",
      "epoch 839 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 839 : params.grad right after loss.backward(): tensor([-3.4280e-05, -2.3406e-05])\n",
      "epoch 839 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 840 loss is 1.0450663566589355\n",
      "epoch 840 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 840 : params.grad right after loss.backward(): tensor([-3.3870e-05, -2.3395e-05])\n",
      "epoch 840 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 841 loss is 1.0450663566589355\n",
      "epoch 841 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 841 : params.grad right after loss.backward(): tensor([-3.3557e-05, -2.3369e-05])\n",
      "epoch 841 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 842 loss is 1.045066475868225\n",
      "epoch 842 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 842 : params.grad right after loss.backward(): tensor([-3.3237e-05, -2.3410e-05])\n",
      "epoch 842 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 843 loss is 1.045066475868225\n",
      "epoch 843 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 843 : params.grad right after loss.backward(): tensor([-3.2872e-05, -2.3425e-05])\n",
      "epoch 843 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 844 loss is 1.045066475868225\n",
      "epoch 844 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 844 : params.grad right after loss.backward(): tensor([-3.2596e-05, -2.3521e-05])\n",
      "epoch 844 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 845 loss is 1.0450663566589355\n",
      "epoch 845 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 845 : params.grad right after loss.backward(): tensor([-3.2254e-05, -2.3551e-05])\n",
      "epoch 845 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 846 loss is 1.0450661182403564\n",
      "epoch 846 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 846 : params.grad right after loss.backward(): tensor([-3.1829e-05, -2.3499e-05])\n",
      "epoch 846 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 847 loss is 1.045066237449646\n",
      "epoch 847 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 847 : params.grad right after loss.backward(): tensor([-3.1538e-05, -2.3521e-05])\n",
      "epoch 847 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 848 loss is 1.0450663566589355\n",
      "epoch 848 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 848 : params.grad right after loss.backward(): tensor([-3.1248e-05, -2.3585e-05])\n",
      "epoch 848 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 849 loss is 1.0450663566589355\n",
      "epoch 849 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 849 : params.grad right after loss.backward(): tensor([-3.0912e-05, -2.3648e-05])\n",
      "epoch 849 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 850 loss is 1.045066237449646\n",
      "epoch 850 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 850 : params.grad right after loss.backward(): tensor([-3.0585e-05, -2.3652e-05])\n",
      "epoch 850 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 851 loss is 1.0450661182403564\n",
      "epoch 851 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 851 : params.grad right after loss.backward(): tensor([-3.0234e-05, -2.3644e-05])\n",
      "epoch 851 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 852 loss is 1.0450661182403564\n",
      "epoch 852 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 852 : params.grad right after loss.backward(): tensor([-2.9825e-05, -2.3648e-05])\n",
      "epoch 852 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 853 loss is 1.0450661182403564\n",
      "epoch 853 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 853 : params.grad right after loss.backward(): tensor([-2.9460e-05, -2.3652e-05])\n",
      "epoch 853 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 854 loss is 1.045066237449646\n",
      "epoch 854 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 854 : params.grad right after loss.backward(): tensor([-2.9214e-05, -2.3749e-05])\n",
      "epoch 854 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 855 loss is 1.045066237449646\n",
      "epoch 855 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 855 : params.grad right after loss.backward(): tensor([-2.8923e-05, -2.3756e-05])\n",
      "epoch 855 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 856 loss is 1.0450661182403564\n",
      "epoch 856 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 856 : params.grad right after loss.backward(): tensor([-2.8618e-05, -2.3846e-05])\n",
      "epoch 856 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 857 loss is 1.0450663566589355\n",
      "epoch 857 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 857 : params.grad right after loss.backward(): tensor([-2.8297e-05, -2.2862e-05])\n",
      "epoch 857 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 858 loss is 1.045066475868225\n",
      "epoch 858 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 858 : params.grad right after loss.backward(): tensor([-2.7962e-05, -2.2881e-05])\n",
      "epoch 858 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 859 loss is 1.0450663566589355\n",
      "epoch 859 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 859 : params.grad right after loss.backward(): tensor([-2.7701e-05, -2.2940e-05])\n",
      "epoch 859 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 860 loss is 1.0450663566589355\n",
      "epoch 860 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 860 : params.grad right after loss.backward(): tensor([-2.7306e-05, -2.2981e-05])\n",
      "epoch 860 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 861 loss is 1.0450663566589355\n",
      "epoch 861 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 861 : params.grad right after loss.backward(): tensor([-2.6911e-05, -2.2978e-05])\n",
      "epoch 861 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 862 loss is 1.0450663566589355\n",
      "epoch 862 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 862 : params.grad right after loss.backward(): tensor([-2.6651e-05, -2.3026e-05])\n",
      "epoch 862 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 863 loss is 1.0450663566589355\n",
      "epoch 863 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 863 : params.grad right after loss.backward(): tensor([-2.6330e-05, -2.3004e-05])\n",
      "epoch 863 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 864 loss is 1.0450663566589355\n",
      "epoch 864 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 864 : params.grad right after loss.backward(): tensor([-2.6017e-05, -2.3086e-05])\n",
      "epoch 864 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 865 loss is 1.045066237449646\n",
      "epoch 865 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 865 : params.grad right after loss.backward(): tensor([-2.5667e-05, -2.3108e-05])\n",
      "epoch 865 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 866 loss is 1.0450663566589355\n",
      "epoch 866 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 866 : params.grad right after loss.backward(): tensor([-2.5205e-05, -2.3074e-05])\n",
      "epoch 866 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 867 loss is 1.0450663566589355\n",
      "epoch 867 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 867 : params.grad right after loss.backward(): tensor([-2.4982e-05, -2.3123e-05])\n",
      "epoch 867 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 868 loss is 1.0450661182403564\n",
      "epoch 868 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 868 : params.grad right after loss.backward(): tensor([-2.4654e-05, -2.3182e-05])\n",
      "epoch 868 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 869 loss is 1.0450661182403564\n",
      "epoch 869 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 869 : params.grad right after loss.backward(): tensor([-2.4334e-05, -2.3212e-05])\n",
      "epoch 869 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 870 loss is 1.0450663566589355\n",
      "epoch 870 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 870 : params.grad right after loss.backward(): tensor([-2.3931e-05, -2.3201e-05])\n",
      "epoch 870 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 871 loss is 1.045066237449646\n",
      "epoch 871 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 871 : params.grad right after loss.backward(): tensor([-2.3603e-05, -2.3171e-05])\n",
      "epoch 871 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 872 loss is 1.045066237449646\n",
      "epoch 872 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 872 : params.grad right after loss.backward(): tensor([-2.3291e-05, -2.3238e-05])\n",
      "epoch 872 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 873 loss is 1.045066237449646\n",
      "epoch 873 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 873 : params.grad right after loss.backward(): tensor([-2.3030e-05, -2.3276e-05])\n",
      "epoch 873 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 874 loss is 1.0450661182403564\n",
      "epoch 874 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 874 : params.grad right after loss.backward(): tensor([-2.2694e-05, -2.3320e-05])\n",
      "epoch 874 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 875 loss is 1.0450663566589355\n",
      "epoch 875 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 875 : params.grad right after loss.backward(): tensor([-2.2277e-05, -2.3358e-05])\n",
      "epoch 875 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 876 loss is 1.045066237449646\n",
      "epoch 876 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 876 : params.grad right after loss.backward(): tensor([-2.1949e-05, -2.3395e-05])\n",
      "epoch 876 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 877 loss is 1.045066237449646\n",
      "epoch 877 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 877 : params.grad right after loss.backward(): tensor([-2.1666e-05, -2.3391e-05])\n",
      "epoch 877 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 878 loss is 1.0450661182403564\n",
      "epoch 878 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 878 : params.grad right after loss.backward(): tensor([-2.1331e-05, -2.3473e-05])\n",
      "epoch 878 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 879 loss is 1.0450661182403564\n",
      "epoch 879 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 879 : params.grad right after loss.backward(): tensor([-2.0966e-05, -2.3458e-05])\n",
      "epoch 879 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 880 loss is 1.045065999031067\n",
      "epoch 880 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 880 : params.grad right after loss.backward(): tensor([-2.0579e-05, -2.3492e-05])\n",
      "epoch 880 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 881 loss is 1.0450661182403564\n",
      "epoch 881 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 881 : params.grad right after loss.backward(): tensor([-2.0318e-05, -2.3533e-05])\n",
      "epoch 881 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 882 loss is 1.0450663566589355\n",
      "epoch 882 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 882 : params.grad right after loss.backward(): tensor([-1.9997e-05, -2.3536e-05])\n",
      "epoch 882 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 883 loss is 1.0450663566589355\n",
      "epoch 883 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 883 : params.grad right after loss.backward(): tensor([-1.9714e-05, -2.3589e-05])\n",
      "epoch 883 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 884 loss is 1.045066237449646\n",
      "epoch 884 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 884 : params.grad right after loss.backward(): tensor([-1.9401e-05, -2.3626e-05])\n",
      "epoch 884 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 885 loss is 1.0450663566589355\n",
      "epoch 885 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 885 : params.grad right after loss.backward(): tensor([-1.8954e-05, -2.3622e-05])\n",
      "epoch 885 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 886 loss is 1.045066475868225\n",
      "epoch 886 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 886 : params.grad right after loss.backward(): tensor([-1.8641e-05, -2.3618e-05])\n",
      "epoch 886 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 887 loss is 1.045066237449646\n",
      "epoch 887 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 887 : params.grad right after loss.backward(): tensor([-1.8314e-05, -2.3656e-05])\n",
      "epoch 887 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 888 loss is 1.0450663566589355\n",
      "epoch 888 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 888 : params.grad right after loss.backward(): tensor([-1.8045e-05, -2.3723e-05])\n",
      "epoch 888 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 889 loss is 1.045066237449646\n",
      "epoch 889 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 889 : params.grad right after loss.backward(): tensor([-1.7688e-05, -2.3693e-05])\n",
      "epoch 889 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 890 loss is 1.0450663566589355\n",
      "epoch 890 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 890 : params.grad right after loss.backward(): tensor([-1.7345e-05, -2.3730e-05])\n",
      "epoch 890 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 891 loss is 1.0450663566589355\n",
      "epoch 891 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 891 : params.grad right after loss.backward(): tensor([-1.7039e-05, -2.3723e-05])\n",
      "epoch 891 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 892 loss is 1.0450663566589355\n",
      "epoch 892 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 892 : params.grad right after loss.backward(): tensor([-1.6689e-05, -2.3741e-05])\n",
      "epoch 892 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 893 loss is 1.0450663566589355\n",
      "epoch 893 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 893 : params.grad right after loss.backward(): tensor([-1.6354e-05, -2.3801e-05])\n",
      "epoch 893 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 894 loss is 1.0450663566589355\n",
      "epoch 894 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 894 : params.grad right after loss.backward(): tensor([-1.6019e-05, -2.3860e-05])\n",
      "epoch 894 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 895 loss is 1.045066237449646\n",
      "epoch 895 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 895 : params.grad right after loss.backward(): tensor([-1.5721e-05, -2.2929e-05])\n",
      "epoch 895 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 896 loss is 1.045066237449646\n",
      "epoch 896 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 896 : params.grad right after loss.backward(): tensor([-1.5378e-05, -2.2970e-05])\n",
      "epoch 896 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 897 loss is 1.045066237449646\n",
      "epoch 897 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 897 : params.grad right after loss.backward(): tensor([-1.5110e-05, -2.3007e-05])\n",
      "epoch 897 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 898 loss is 1.0450661182403564\n",
      "epoch 898 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 898 : params.grad right after loss.backward(): tensor([-1.4745e-05, -2.2996e-05])\n",
      "epoch 898 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 899 loss is 1.0450661182403564\n",
      "epoch 899 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 899 : params.grad right after loss.backward(): tensor([-1.4447e-05, -2.3063e-05])\n",
      "epoch 899 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 900 loss is 1.0450661182403564\n",
      "epoch 900 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 900 : params.grad right after loss.backward(): tensor([-1.4059e-05, -2.3056e-05])\n",
      "epoch 900 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 901 loss is 1.045066237449646\n",
      "epoch 901 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 901 : params.grad right after loss.backward(): tensor([-1.3724e-05, -2.3048e-05])\n",
      "epoch 901 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 902 loss is 1.0450663566589355\n",
      "epoch 902 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 902 : params.grad right after loss.backward(): tensor([-1.3441e-05, -2.3171e-05])\n",
      "epoch 902 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 903 loss is 1.0450663566589355\n",
      "epoch 903 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 903 : params.grad right after loss.backward(): tensor([-1.3091e-05, -2.3182e-05])\n",
      "epoch 903 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 904 loss is 1.045066237449646\n",
      "epoch 904 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 904 : params.grad right after loss.backward(): tensor([-1.2763e-05, -2.3223e-05])\n",
      "epoch 904 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 905 loss is 1.0450663566589355\n",
      "epoch 905 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 905 : params.grad right after loss.backward(): tensor([-1.2398e-05, -2.3216e-05])\n",
      "epoch 905 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 906 loss is 1.0450663566589355\n",
      "epoch 906 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 906 : params.grad right after loss.backward(): tensor([-1.2062e-05, -2.3276e-05])\n",
      "epoch 906 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 907 loss is 1.0450663566589355\n",
      "epoch 907 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 907 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 907 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 908 loss is 1.0450663566589355\n",
      "epoch 908 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 908 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 908 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 909 loss is 1.0450663566589355\n",
      "epoch 909 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 909 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 909 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 910 loss is 1.0450663566589355\n",
      "epoch 910 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 910 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 910 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 911 loss is 1.0450663566589355\n",
      "epoch 911 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 911 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 911 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 912 loss is 1.0450663566589355\n",
      "epoch 912 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 912 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 912 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 913 loss is 1.0450663566589355\n",
      "epoch 913 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 913 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 913 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 914 loss is 1.0450663566589355\n",
      "epoch 914 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 914 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 914 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 915 loss is 1.0450663566589355\n",
      "epoch 915 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 915 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 915 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 916 loss is 1.0450663566589355\n",
      "epoch 916 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 916 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 916 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 917 loss is 1.0450663566589355\n",
      "epoch 917 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 917 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 917 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 918 loss is 1.0450663566589355\n",
      "epoch 918 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 918 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 918 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 919 loss is 1.0450663566589355\n",
      "epoch 919 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 919 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 919 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 920 loss is 1.0450663566589355\n",
      "epoch 920 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 920 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 920 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 921 loss is 1.0450663566589355\n",
      "epoch 921 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 921 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 921 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 922 loss is 1.0450663566589355\n",
      "epoch 922 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 922 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 922 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 923 loss is 1.0450663566589355\n",
      "epoch 923 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 923 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 923 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 924 loss is 1.0450663566589355\n",
      "epoch 924 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 924 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 924 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 925 loss is 1.0450663566589355\n",
      "epoch 925 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 925 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 925 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 926 loss is 1.0450663566589355\n",
      "epoch 926 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 926 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 926 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 927 loss is 1.0450663566589355\n",
      "epoch 927 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 927 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 927 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 928 loss is 1.0450663566589355\n",
      "epoch 928 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 928 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 928 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 929 loss is 1.0450663566589355\n",
      "epoch 929 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 929 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 929 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 930 loss is 1.0450663566589355\n",
      "epoch 930 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 930 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 930 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 931 loss is 1.0450663566589355\n",
      "epoch 931 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 931 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 931 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 932 loss is 1.0450663566589355\n",
      "epoch 932 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 932 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 932 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 933 loss is 1.0450663566589355\n",
      "epoch 933 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 933 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 933 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 934 loss is 1.0450663566589355\n",
      "epoch 934 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 934 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 934 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 935 loss is 1.0450663566589355\n",
      "epoch 935 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 935 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 935 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 936 loss is 1.0450663566589355\n",
      "epoch 936 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 936 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 936 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 937 loss is 1.0450663566589355\n",
      "epoch 937 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 937 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 937 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 938 loss is 1.0450663566589355\n",
      "epoch 938 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 938 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 938 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 939 loss is 1.0450663566589355\n",
      "epoch 939 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 939 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 939 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 940 loss is 1.0450663566589355\n",
      "epoch 940 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 940 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 940 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 941 loss is 1.0450663566589355\n",
      "epoch 941 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 941 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 941 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 942 loss is 1.0450663566589355\n",
      "epoch 942 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 942 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 942 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 943 loss is 1.0450663566589355\n",
      "epoch 943 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 943 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 943 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 944 loss is 1.0450663566589355\n",
      "epoch 944 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 944 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 944 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 945 loss is 1.0450663566589355\n",
      "epoch 945 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 945 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 945 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 946 loss is 1.0450663566589355\n",
      "epoch 946 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 946 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 946 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 947 loss is 1.0450663566589355\n",
      "epoch 947 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 947 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 947 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 948 loss is 1.0450663566589355\n",
      "epoch 948 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 948 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 948 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 949 loss is 1.0450663566589355\n",
      "epoch 949 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 949 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 949 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 950 loss is 1.0450663566589355\n",
      "epoch 950 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 950 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 950 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 951 loss is 1.0450663566589355\n",
      "epoch 951 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 951 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 951 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 952 loss is 1.0450663566589355\n",
      "epoch 952 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 952 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 952 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 953 loss is 1.0450663566589355\n",
      "epoch 953 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 953 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 953 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 954 loss is 1.0450663566589355\n",
      "epoch 954 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 954 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 954 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 955 loss is 1.0450663566589355\n",
      "epoch 955 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 955 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 955 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 956 loss is 1.0450663566589355\n",
      "epoch 956 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 956 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 956 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 957 loss is 1.0450663566589355\n",
      "epoch 957 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 957 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 957 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 958 loss is 1.0450663566589355\n",
      "epoch 958 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 958 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 958 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 959 loss is 1.0450663566589355\n",
      "epoch 959 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 959 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 959 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 960 loss is 1.0450663566589355\n",
      "epoch 960 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 960 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 960 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 961 loss is 1.0450663566589355\n",
      "epoch 961 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 961 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 961 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 962 loss is 1.0450663566589355\n",
      "epoch 962 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 962 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 962 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 963 loss is 1.0450663566589355\n",
      "epoch 963 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 963 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 963 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 964 loss is 1.0450663566589355\n",
      "epoch 964 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 964 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 964 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 965 loss is 1.0450663566589355\n",
      "epoch 965 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 965 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 965 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 966 loss is 1.0450663566589355\n",
      "epoch 966 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 966 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 966 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 967 loss is 1.0450663566589355\n",
      "epoch 967 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 967 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 967 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 968 loss is 1.0450663566589355\n",
      "epoch 968 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 968 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 968 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 969 loss is 1.0450663566589355\n",
      "epoch 969 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 969 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 969 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 970 loss is 1.0450663566589355\n",
      "epoch 970 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 970 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 970 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 971 loss is 1.0450663566589355\n",
      "epoch 971 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 971 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 971 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 972 loss is 1.0450663566589355\n",
      "epoch 972 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 972 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 972 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 973 loss is 1.0450663566589355\n",
      "epoch 973 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 973 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 973 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 974 loss is 1.0450663566589355\n",
      "epoch 974 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 974 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 974 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 975 loss is 1.0450663566589355\n",
      "epoch 975 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 975 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 975 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 976 loss is 1.0450663566589355\n",
      "epoch 976 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 976 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 976 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 977 loss is 1.0450663566589355\n",
      "epoch 977 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 977 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 977 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 978 loss is 1.0450663566589355\n",
      "epoch 978 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 978 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 978 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 979 loss is 1.0450663566589355\n",
      "epoch 979 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 979 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 979 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 980 loss is 1.0450663566589355\n",
      "epoch 980 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 980 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 980 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 981 loss is 1.0450663566589355\n",
      "epoch 981 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 981 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 981 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 982 loss is 1.0450663566589355\n",
      "epoch 982 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 982 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 982 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 983 loss is 1.0450663566589355\n",
      "epoch 983 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 983 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 983 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 984 loss is 1.0450663566589355\n",
      "epoch 984 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 984 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 984 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 985 loss is 1.0450663566589355\n",
      "epoch 985 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 985 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 985 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 986 loss is 1.0450663566589355\n",
      "epoch 986 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 986 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 986 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 987 loss is 1.0450663566589355\n",
      "epoch 987 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 987 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 987 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 988 loss is 1.0450663566589355\n",
      "epoch 988 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 988 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 988 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 989 loss is 1.0450663566589355\n",
      "epoch 989 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 989 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 989 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 990 loss is 1.0450663566589355\n",
      "epoch 990 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 990 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 990 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 991 loss is 1.0450663566589355\n",
      "epoch 991 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 991 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 991 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 992 loss is 1.0450663566589355\n",
      "epoch 992 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 992 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 992 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 993 loss is 1.0450663566589355\n",
      "epoch 993 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 993 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 993 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 994 loss is 1.0450663566589355\n",
      "epoch 994 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 994 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 994 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 995 loss is 1.0450663566589355\n",
      "epoch 995 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 995 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 995 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 996 loss is 1.0450663566589355\n",
      "epoch 996 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 996 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 996 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 997 loss is 1.0450663566589355\n",
      "epoch 997 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 997 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 997 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 998 loss is 1.0450663566589355\n",
      "epoch 998 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 998 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 998 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 999 loss is 1.0450663566589355\n",
      "epoch 999 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 999 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 999 after parameter update : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n"
     ]
    }
   ],
   "source": [
    "params = torch.tensor([1.0,0.0], requires_grad=True)\n",
    "epochs=1000\n",
    "train_loop(model,loss_fn2,params,x,y,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dea5e58",
   "metadata": {},
   "source": [
    "# Using optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8240a06b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b239dfe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = torch.tensor([1.0,0.0], requires_grad=True)\n",
    "sgd = optim.SGD([params], lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2ed68996",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loss_fn, params,optimizer, x, y_true, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        y_pred = model(x, *params)\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        print(f\"epoch {epoch} loss is {loss}\")\n",
    "        print(f\"epoch {epoch} params.grad right before loss.backward() : {params.grad}\")\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        print(f\"epoch {epoch} : params.grad right after loss.backward(): {params.grad}\")\n",
    "        optimizer.step()\n",
    "        print(f\"epoch {epoch} after optimizer.step() : {params}, required_grad : {params.requires_grad}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc4cc6bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss is 27.537952423095703\n",
      "epoch 0 params.grad right before loss.backward() : None\n",
      "epoch 0 : params.grad right after loss.backward(): tensor([-2.1467, -9.7693])\n",
      "epoch 0 after optimizer.step() : tensor([1.0215, 0.0977], requires_grad=True), required_grad : True\n",
      "epoch 1 loss is 26.547101974487305\n",
      "epoch 1 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 1 : params.grad right after loss.backward(): tensor([-2.1279, -9.5764])\n",
      "epoch 1 after optimizer.step() : tensor([1.0427, 0.1935], requires_grad=True), required_grad : True\n",
      "epoch 2 loss is 25.594009399414062\n",
      "epoch 2 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 2 : params.grad right after loss.backward(): tensor([-2.1091, -9.3873])\n",
      "epoch 2 after optimizer.step() : tensor([1.0638, 0.2873], requires_grad=True), required_grad : True\n",
      "epoch 3 loss is 24.677221298217773\n",
      "epoch 3 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 3 : params.grad right after loss.backward(): tensor([-2.0904, -9.2019])\n",
      "epoch 3 after optimizer.step() : tensor([1.0847, 0.3793], requires_grad=True), required_grad : True\n",
      "epoch 4 loss is 23.795320510864258\n",
      "epoch 4 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 4 : params.grad right after loss.backward(): tensor([-2.0718, -9.0203])\n",
      "epoch 4 after optimizer.step() : tensor([1.1055, 0.4696], requires_grad=True), required_grad : True\n",
      "epoch 5 loss is 22.946975708007812\n",
      "epoch 5 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 5 : params.grad right after loss.backward(): tensor([-2.0531, -8.8422])\n",
      "epoch 5 after optimizer.step() : tensor([1.1260, 0.5580], requires_grad=True), required_grad : True\n",
      "epoch 6 loss is 22.130878448486328\n",
      "epoch 6 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 6 : params.grad right after loss.backward(): tensor([-2.0346, -8.6677])\n",
      "epoch 6 after optimizer.step() : tensor([1.1463, 0.6447], requires_grad=True), required_grad : True\n",
      "epoch 7 loss is 21.34579086303711\n",
      "epoch 7 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 7 : params.grad right after loss.backward(): tensor([-2.0161, -8.4967])\n",
      "epoch 7 after optimizer.step() : tensor([1.1665, 0.7296], requires_grad=True), required_grad : True\n",
      "epoch 8 loss is 20.59052085876465\n",
      "epoch 8 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 8 : params.grad right after loss.backward(): tensor([-1.9977, -8.3290])\n",
      "epoch 8 after optimizer.step() : tensor([1.1865, 0.8129], requires_grad=True), required_grad : True\n",
      "epoch 9 loss is 19.86391258239746\n",
      "epoch 9 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 9 : params.grad right after loss.backward(): tensor([-1.9793, -8.1647])\n",
      "epoch 9 after optimizer.step() : tensor([1.2063, 0.8946], requires_grad=True), required_grad : True\n",
      "epoch 10 loss is 19.16486930847168\n",
      "epoch 10 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 10 : params.grad right after loss.backward(): tensor([-1.9610, -8.0037])\n",
      "epoch 10 after optimizer.step() : tensor([1.2259, 0.9746], requires_grad=True), required_grad : True\n",
      "epoch 11 loss is 18.492319107055664\n",
      "epoch 11 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 11 : params.grad right after loss.backward(): tensor([-1.9428, -7.8458])\n",
      "epoch 11 after optimizer.step() : tensor([1.2453, 1.0530], requires_grad=True), required_grad : True\n",
      "epoch 12 loss is 17.84524917602539\n",
      "epoch 12 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 12 : params.grad right after loss.backward(): tensor([-1.9247, -7.6911])\n",
      "epoch 12 after optimizer.step() : tensor([1.2646, 1.1300], requires_grad=True), required_grad : True\n",
      "epoch 13 loss is 17.222675323486328\n",
      "epoch 13 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 13 : params.grad right after loss.backward(): tensor([-1.9066, -7.5395])\n",
      "epoch 13 after optimizer.step() : tensor([1.2836, 1.2054], requires_grad=True), required_grad : True\n",
      "epoch 14 loss is 16.623659133911133\n",
      "epoch 14 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 14 : params.grad right after loss.backward(): tensor([-1.8886, -7.3909])\n",
      "epoch 14 after optimizer.step() : tensor([1.3025, 1.2793], requires_grad=True), required_grad : True\n",
      "epoch 15 loss is 16.047292709350586\n",
      "epoch 15 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 15 : params.grad right after loss.backward(): tensor([-1.8707, -7.2452])\n",
      "epoch 15 after optimizer.step() : tensor([1.3212, 1.3517], requires_grad=True), required_grad : True\n",
      "epoch 16 loss is 15.492707252502441\n",
      "epoch 16 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 16 : params.grad right after loss.backward(): tensor([-1.8529, -7.1024])\n",
      "epoch 16 after optimizer.step() : tensor([1.3397, 1.4227], requires_grad=True), required_grad : True\n",
      "epoch 17 loss is 14.959064483642578\n",
      "epoch 17 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 17 : params.grad right after loss.backward(): tensor([-1.8352, -6.9625])\n",
      "epoch 17 after optimizer.step() : tensor([1.3581, 1.4924], requires_grad=True), required_grad : True\n",
      "epoch 18 loss is 14.445561408996582\n",
      "epoch 18 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 18 : params.grad right after loss.backward(): tensor([-1.8175, -6.8253])\n",
      "epoch 18 after optimizer.step() : tensor([1.3763, 1.5606], requires_grad=True), required_grad : True\n",
      "epoch 19 loss is 13.951424598693848\n",
      "epoch 19 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 19 : params.grad right after loss.backward(): tensor([-1.8000, -6.6909])\n",
      "epoch 19 after optimizer.step() : tensor([1.3943, 1.6275], requires_grad=True), required_grad : True\n",
      "epoch 20 loss is 13.475913047790527\n",
      "epoch 20 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 20 : params.grad right after loss.backward(): tensor([-1.7825, -6.5591])\n",
      "epoch 20 after optimizer.step() : tensor([1.4121, 1.6931], requires_grad=True), required_grad : True\n",
      "epoch 21 loss is 13.018311500549316\n",
      "epoch 21 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 21 : params.grad right after loss.backward(): tensor([-1.7651, -6.4300])\n",
      "epoch 21 after optimizer.step() : tensor([1.4297, 1.7574], requires_grad=True), required_grad : True\n",
      "epoch 22 loss is 12.577934265136719\n",
      "epoch 22 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 22 : params.grad right after loss.backward(): tensor([-1.7479, -6.3034])\n",
      "epoch 22 after optimizer.step() : tensor([1.4472, 1.8205], requires_grad=True), required_grad : True\n",
      "epoch 23 loss is 12.154121398925781\n",
      "epoch 23 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 23 : params.grad right after loss.backward(): tensor([-1.7307, -6.1793])\n",
      "epoch 23 after optimizer.step() : tensor([1.4645, 1.8822], requires_grad=True), required_grad : True\n",
      "epoch 24 loss is 11.746238708496094\n",
      "epoch 24 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 24 : params.grad right after loss.backward(): tensor([-1.7136, -6.0577])\n",
      "epoch 24 after optimizer.step() : tensor([1.4817, 1.9428], requires_grad=True), required_grad : True\n",
      "epoch 25 loss is 11.353676795959473\n",
      "epoch 25 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 25 : params.grad right after loss.backward(): tensor([-1.6966, -5.9385])\n",
      "epoch 25 after optimizer.step() : tensor([1.4986, 2.0022], requires_grad=True), required_grad : True\n",
      "epoch 26 loss is 10.975851058959961\n",
      "epoch 26 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 26 : params.grad right after loss.backward(): tensor([-1.6797, -5.8216])\n",
      "epoch 26 after optimizer.step() : tensor([1.5154, 2.0604], requires_grad=True), required_grad : True\n",
      "epoch 27 loss is 10.61219596862793\n",
      "epoch 27 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 27 : params.grad right after loss.backward(): tensor([-1.6630, -5.7071])\n",
      "epoch 27 after optimizer.step() : tensor([1.5321, 2.1175], requires_grad=True), required_grad : True\n",
      "epoch 28 loss is 10.262175559997559\n",
      "epoch 28 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 28 : params.grad right after loss.backward(): tensor([-1.6463, -5.5949])\n",
      "epoch 28 after optimizer.step() : tensor([1.5485, 2.1734], requires_grad=True), required_grad : True\n",
      "epoch 29 loss is 9.925263404846191\n",
      "epoch 29 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 29 : params.grad right after loss.backward(): tensor([-1.6297, -5.4848])\n",
      "epoch 29 after optimizer.step() : tensor([1.5648, 2.2283], requires_grad=True), required_grad : True\n",
      "epoch 30 loss is 9.600961685180664\n",
      "epoch 30 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 30 : params.grad right after loss.backward(): tensor([-1.6132, -5.3770])\n",
      "epoch 30 after optimizer.step() : tensor([1.5810, 2.2821], requires_grad=True), required_grad : True\n",
      "epoch 31 loss is 9.288790702819824\n",
      "epoch 31 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 31 : params.grad right after loss.backward(): tensor([-1.5969, -5.2713])\n",
      "epoch 31 after optimizer.step() : tensor([1.5969, 2.3348], requires_grad=True), required_grad : True\n",
      "epoch 32 loss is 8.988286972045898\n",
      "epoch 32 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 32 : params.grad right after loss.backward(): tensor([-1.5806, -5.1677])\n",
      "epoch 32 after optimizer.step() : tensor([1.6127, 2.3864], requires_grad=True), required_grad : True\n",
      "epoch 33 loss is 8.699007987976074\n",
      "epoch 33 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 33 : params.grad right after loss.backward(): tensor([-1.5645, -5.0661])\n",
      "epoch 33 after optimizer.step() : tensor([1.6284, 2.4371], requires_grad=True), required_grad : True\n",
      "epoch 34 loss is 8.420522689819336\n",
      "epoch 34 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 34 : params.grad right after loss.backward(): tensor([-1.5485, -4.9666])\n",
      "epoch 34 after optimizer.step() : tensor([1.6439, 2.4868], requires_grad=True), required_grad : True\n",
      "epoch 35 loss is 8.152423858642578\n",
      "epoch 35 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 35 : params.grad right after loss.backward(): tensor([-1.5325, -4.8690])\n",
      "epoch 35 after optimizer.step() : tensor([1.6592, 2.5355], requires_grad=True), required_grad : True\n",
      "epoch 36 loss is 7.894314765930176\n",
      "epoch 36 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 36 : params.grad right after loss.backward(): tensor([-1.5167, -4.7734])\n",
      "epoch 36 after optimizer.step() : tensor([1.6743, 2.5832], requires_grad=True), required_grad : True\n",
      "epoch 37 loss is 7.645817279815674\n",
      "epoch 37 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 37 : params.grad right after loss.backward(): tensor([-1.5010, -4.6796])\n",
      "epoch 37 after optimizer.step() : tensor([1.6894, 2.6300], requires_grad=True), required_grad : True\n",
      "epoch 38 loss is 7.406564235687256\n",
      "epoch 38 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 38 : params.grad right after loss.backward(): tensor([-1.4854, -4.5877])\n",
      "epoch 38 after optimizer.step() : tensor([1.7042, 2.6759], requires_grad=True), required_grad : True\n",
      "epoch 39 loss is 7.176206588745117\n",
      "epoch 39 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 39 : params.grad right after loss.backward(): tensor([-1.4700, -4.4977])\n",
      "epoch 39 after optimizer.step() : tensor([1.7189, 2.7208], requires_grad=True), required_grad : True\n",
      "epoch 40 loss is 6.954406261444092\n",
      "epoch 40 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 40 : params.grad right after loss.backward(): tensor([-1.4546, -4.4094])\n",
      "epoch 40 after optimizer.step() : tensor([1.7335, 2.7649], requires_grad=True), required_grad : True\n",
      "epoch 41 loss is 6.740839958190918\n",
      "epoch 41 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 41 : params.grad right after loss.backward(): tensor([-1.4393, -4.3229])\n",
      "epoch 41 after optimizer.step() : tensor([1.7479, 2.8082], requires_grad=True), required_grad : True\n",
      "epoch 42 loss is 6.53519344329834\n",
      "epoch 42 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 42 : params.grad right after loss.backward(): tensor([-1.4242, -4.2380])\n",
      "epoch 42 after optimizer.step() : tensor([1.7621, 2.8506], requires_grad=True), required_grad : True\n",
      "epoch 43 loss is 6.337167739868164\n",
      "epoch 43 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 43 : params.grad right after loss.backward(): tensor([-1.4092, -4.1549])\n",
      "epoch 43 after optimizer.step() : tensor([1.7762, 2.8921], requires_grad=True), required_grad : True\n",
      "epoch 44 loss is 6.146477222442627\n",
      "epoch 44 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 44 : params.grad right after loss.backward(): tensor([-1.3943, -4.0734])\n",
      "epoch 44 after optimizer.step() : tensor([1.7901, 2.9328], requires_grad=True), required_grad : True\n",
      "epoch 45 loss is 5.962840557098389\n",
      "epoch 45 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 45 : params.grad right after loss.backward(): tensor([-1.3795, -3.9935])\n",
      "epoch 45 after optimizer.step() : tensor([1.8039, 2.9728], requires_grad=True), required_grad : True\n",
      "epoch 46 loss is 5.785994052886963\n",
      "epoch 46 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 46 : params.grad right after loss.backward(): tensor([-1.3648, -3.9152])\n",
      "epoch 46 after optimizer.step() : tensor([1.8176, 3.0119], requires_grad=True), required_grad : True\n",
      "epoch 47 loss is 5.6156792640686035\n",
      "epoch 47 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 47 : params.grad right after loss.backward(): tensor([-1.3503, -3.8385])\n",
      "epoch 47 after optimizer.step() : tensor([1.8311, 3.0503], requires_grad=True), required_grad : True\n",
      "epoch 48 loss is 5.451650619506836\n",
      "epoch 48 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 48 : params.grad right after loss.backward(): tensor([-1.3358, -3.7632])\n",
      "epoch 48 after optimizer.step() : tensor([1.8444, 3.0879], requires_grad=True), required_grad : True\n",
      "epoch 49 loss is 5.293670654296875\n",
      "epoch 49 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 49 : params.grad right after loss.backward(): tensor([-1.3215, -3.6895])\n",
      "epoch 49 after optimizer.step() : tensor([1.8576, 3.1248], requires_grad=True), required_grad : True\n",
      "epoch 50 loss is 5.141511917114258\n",
      "epoch 50 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 50 : params.grad right after loss.backward(): tensor([-1.3073, -3.6172])\n",
      "epoch 50 after optimizer.step() : tensor([1.8707, 3.1610], requires_grad=True), required_grad : True\n",
      "epoch 51 loss is 4.994955539703369\n",
      "epoch 51 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 51 : params.grad right after loss.backward(): tensor([-1.2932, -3.5463])\n",
      "epoch 51 after optimizer.step() : tensor([1.8837, 3.1965], requires_grad=True), required_grad : True\n",
      "epoch 52 loss is 4.85378885269165\n",
      "epoch 52 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 52 : params.grad right after loss.backward(): tensor([-1.2792, -3.4769])\n",
      "epoch 52 after optimizer.step() : tensor([1.8964, 3.2312], requires_grad=True), required_grad : True\n",
      "epoch 53 loss is 4.71781063079834\n",
      "epoch 53 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 53 : params.grad right after loss.backward(): tensor([-1.2653, -3.4088])\n",
      "epoch 53 after optimizer.step() : tensor([1.9091, 3.2653], requires_grad=True), required_grad : True\n",
      "epoch 54 loss is 4.586824417114258\n",
      "epoch 54 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 54 : params.grad right after loss.backward(): tensor([-1.2516, -3.3421])\n",
      "epoch 54 after optimizer.step() : tensor([1.9216, 3.2987], requires_grad=True), required_grad : True\n",
      "epoch 55 loss is 4.460644721984863\n",
      "epoch 55 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 55 : params.grad right after loss.backward(): tensor([-1.2379, -3.2767])\n",
      "epoch 55 after optimizer.step() : tensor([1.9340, 3.3315], requires_grad=True), required_grad : True\n",
      "epoch 56 loss is 4.339089393615723\n",
      "epoch 56 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 56 : params.grad right after loss.backward(): tensor([-1.2244, -3.2125])\n",
      "epoch 56 after optimizer.step() : tensor([1.9462, 3.3636], requires_grad=True), required_grad : True\n",
      "epoch 57 loss is 4.221985340118408\n",
      "epoch 57 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 57 : params.grad right after loss.backward(): tensor([-1.2110, -3.1497])\n",
      "epoch 57 after optimizer.step() : tensor([1.9583, 3.3951], requires_grad=True), required_grad : True\n",
      "epoch 58 loss is 4.109166622161865\n",
      "epoch 58 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 58 : params.grad right after loss.backward(): tensor([-1.1977, -3.0881])\n",
      "epoch 58 after optimizer.step() : tensor([1.9703, 3.4260], requires_grad=True), required_grad : True\n",
      "epoch 59 loss is 4.000471591949463\n",
      "epoch 59 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 59 : params.grad right after loss.backward(): tensor([-1.1846, -3.0277])\n",
      "epoch 59 after optimizer.step() : tensor([1.9822, 3.4563], requires_grad=True), required_grad : True\n",
      "epoch 60 loss is 3.895747184753418\n",
      "epoch 60 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 60 : params.grad right after loss.backward(): tensor([-1.1715, -2.9684])\n",
      "epoch 60 after optimizer.step() : tensor([1.9939, 3.4860], requires_grad=True), required_grad : True\n",
      "epoch 61 loss is 3.7948427200317383\n",
      "epoch 61 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 61 : params.grad right after loss.backward(): tensor([-1.1586, -2.9104])\n",
      "epoch 61 after optimizer.step() : tensor([2.0055, 3.5151], requires_grad=True), required_grad : True\n",
      "epoch 62 loss is 3.697617292404175\n",
      "epoch 62 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 62 : params.grad right after loss.backward(): tensor([-1.1457, -2.8535])\n",
      "epoch 62 after optimizer.step() : tensor([2.0169, 3.5436], requires_grad=True), required_grad : True\n",
      "epoch 63 loss is 3.6039328575134277\n",
      "epoch 63 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 63 : params.grad right after loss.backward(): tensor([-1.1330, -2.7978])\n",
      "epoch 63 after optimizer.step() : tensor([2.0283, 3.5716], requires_grad=True), required_grad : True\n",
      "epoch 64 loss is 3.513658046722412\n",
      "epoch 64 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 64 : params.grad right after loss.backward(): tensor([-1.1204, -2.7431])\n",
      "epoch 64 after optimizer.step() : tensor([2.0395, 3.5990], requires_grad=True), required_grad : True\n",
      "epoch 65 loss is 3.426664113998413\n",
      "epoch 65 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 65 : params.grad right after loss.backward(): tensor([-1.1079, -2.6895])\n",
      "epoch 65 after optimizer.step() : tensor([2.0505, 3.6259], requires_grad=True), required_grad : True\n",
      "epoch 66 loss is 3.3428308963775635\n",
      "epoch 66 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 66 : params.grad right after loss.backward(): tensor([-1.0955, -2.6370])\n",
      "epoch 66 after optimizer.step() : tensor([2.0615, 3.6523], requires_grad=True), required_grad : True\n",
      "epoch 67 loss is 3.262038230895996\n",
      "epoch 67 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 67 : params.grad right after loss.backward(): tensor([-1.0833, -2.5855])\n",
      "epoch 67 after optimizer.step() : tensor([2.0723, 3.6781], requires_grad=True), required_grad : True\n",
      "epoch 68 loss is 3.1841747760772705\n",
      "epoch 68 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 68 : params.grad right after loss.backward(): tensor([-1.0711, -2.5350])\n",
      "epoch 68 after optimizer.step() : tensor([2.0830, 3.7035], requires_grad=True), required_grad : True\n",
      "epoch 69 loss is 3.109130620956421\n",
      "epoch 69 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 69 : params.grad right after loss.backward(): tensor([-1.0591, -2.4855])\n",
      "epoch 69 after optimizer.step() : tensor([2.0936, 3.7283], requires_grad=True), required_grad : True\n",
      "epoch 70 loss is 3.036802053451538\n",
      "epoch 70 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 70 : params.grad right after loss.backward(): tensor([-1.0472, -2.4370])\n",
      "epoch 70 after optimizer.step() : tensor([2.1041, 3.7527], requires_grad=True), required_grad : True\n",
      "epoch 71 loss is 2.967087745666504\n",
      "epoch 71 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 71 : params.grad right after loss.backward(): tensor([-1.0353, -2.3895])\n",
      "epoch 71 after optimizer.step() : tensor([2.1145, 3.7766], requires_grad=True), required_grad : True\n",
      "epoch 72 loss is 2.899890661239624\n",
      "epoch 72 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 72 : params.grad right after loss.backward(): tensor([-1.0236, -2.3429])\n",
      "epoch 72 after optimizer.step() : tensor([2.1247, 3.8000], requires_grad=True), required_grad : True\n",
      "epoch 73 loss is 2.835117816925049\n",
      "epoch 73 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 73 : params.grad right after loss.backward(): tensor([-1.0120, -2.2972])\n",
      "epoch 73 after optimizer.step() : tensor([2.1348, 3.8230], requires_grad=True), required_grad : True\n",
      "epoch 74 loss is 2.7726778984069824\n",
      "epoch 74 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 74 : params.grad right after loss.backward(): tensor([-1.0006, -2.2524])\n",
      "epoch 74 after optimizer.step() : tensor([2.1448, 3.8455], requires_grad=True), required_grad : True\n",
      "epoch 75 loss is 2.71248722076416\n",
      "epoch 75 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 75 : params.grad right after loss.backward(): tensor([-0.9892, -2.2085])\n",
      "epoch 75 after optimizer.step() : tensor([2.1547, 3.8676], requires_grad=True), required_grad : True\n",
      "epoch 76 loss is 2.6544604301452637\n",
      "epoch 76 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 76 : params.grad right after loss.backward(): tensor([-0.9779, -2.1654])\n",
      "epoch 76 after optimizer.step() : tensor([2.1645, 3.8893], requires_grad=True), required_grad : True\n",
      "epoch 77 loss is 2.5985190868377686\n",
      "epoch 77 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 77 : params.grad right after loss.backward(): tensor([-0.9667, -2.1232])\n",
      "epoch 77 after optimizer.step() : tensor([2.1742, 3.9105], requires_grad=True), required_grad : True\n",
      "epoch 78 loss is 2.5445847511291504\n",
      "epoch 78 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 78 : params.grad right after loss.backward(): tensor([-0.9557, -2.0819])\n",
      "epoch 78 after optimizer.step() : tensor([2.1837, 3.9313], requires_grad=True), required_grad : True\n",
      "epoch 79 loss is 2.492584466934204\n",
      "epoch 79 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 79 : params.grad right after loss.backward(): tensor([-0.9447, -2.0413])\n",
      "epoch 79 after optimizer.step() : tensor([2.1932, 3.9517], requires_grad=True), required_grad : True\n",
      "epoch 80 loss is 2.44244647026062\n",
      "epoch 80 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 80 : params.grad right after loss.backward(): tensor([-0.9339, -2.0016])\n",
      "epoch 80 after optimizer.step() : tensor([2.2025, 3.9718], requires_grad=True), required_grad : True\n",
      "epoch 81 loss is 2.3941025733947754\n",
      "epoch 81 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 81 : params.grad right after loss.backward(): tensor([-0.9232, -1.9626])\n",
      "epoch 81 after optimizer.step() : tensor([2.2117, 3.9914], requires_grad=True), required_grad : True\n",
      "epoch 82 loss is 2.3474864959716797\n",
      "epoch 82 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 82 : params.grad right after loss.backward(): tensor([-0.9125, -1.9244])\n",
      "epoch 82 after optimizer.step() : tensor([2.2209, 4.0106], requires_grad=True), required_grad : True\n",
      "epoch 83 loss is 2.302534818649292\n",
      "epoch 83 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 83 : params.grad right after loss.backward(): tensor([-0.9020, -1.8869])\n",
      "epoch 83 after optimizer.step() : tensor([2.2299, 4.0295], requires_grad=True), required_grad : True\n",
      "epoch 84 loss is 2.259186029434204\n",
      "epoch 84 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 84 : params.grad right after loss.backward(): tensor([-0.8916, -1.8502])\n",
      "epoch 84 after optimizer.step() : tensor([2.2388, 4.0480], requires_grad=True), required_grad : True\n",
      "epoch 85 loss is 2.2173824310302734\n",
      "epoch 85 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 85 : params.grad right after loss.backward(): tensor([-0.8813, -1.8142])\n",
      "epoch 85 after optimizer.step() : tensor([2.2476, 4.0661], requires_grad=True), required_grad : True\n",
      "epoch 86 loss is 2.1770665645599365\n",
      "epoch 86 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 86 : params.grad right after loss.backward(): tensor([-0.8711, -1.7789])\n",
      "epoch 86 after optimizer.step() : tensor([2.2563, 4.0839], requires_grad=True), required_grad : True\n",
      "epoch 87 loss is 2.1381845474243164\n",
      "epoch 87 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 87 : params.grad right after loss.backward(): tensor([-0.8610, -1.7444])\n",
      "epoch 87 after optimizer.step() : tensor([2.2649, 4.1014], requires_grad=True), required_grad : True\n",
      "epoch 88 loss is 2.1006829738616943\n",
      "epoch 88 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 88 : params.grad right after loss.backward(): tensor([-0.8509, -1.7105])\n",
      "epoch 88 after optimizer.step() : tensor([2.2734, 4.1185], requires_grad=True), required_grad : True\n",
      "epoch 89 loss is 2.06451153755188\n",
      "epoch 89 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 89 : params.grad right after loss.backward(): tensor([-0.8410, -1.6772])\n",
      "epoch 89 after optimizer.step() : tensor([2.2818, 4.1352], requires_grad=True), required_grad : True\n",
      "epoch 90 loss is 2.0296220779418945\n",
      "epoch 90 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 90 : params.grad right after loss.backward(): tensor([-0.8312, -1.6446])\n",
      "epoch 90 after optimizer.step() : tensor([2.2902, 4.1517], requires_grad=True), required_grad : True\n",
      "epoch 91 loss is 1.9959677457809448\n",
      "epoch 91 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 91 : params.grad right after loss.backward(): tensor([-0.8215, -1.6127])\n",
      "epoch 91 after optimizer.step() : tensor([2.2984, 4.1678], requires_grad=True), required_grad : True\n",
      "epoch 92 loss is 1.9635040760040283\n",
      "epoch 92 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 92 : params.grad right after loss.backward(): tensor([-0.8119, -1.5814])\n",
      "epoch 92 after optimizer.step() : tensor([2.3065, 4.1836], requires_grad=True), required_grad : True\n",
      "epoch 93 loss is 1.9321867227554321\n",
      "epoch 93 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 93 : params.grad right after loss.backward(): tensor([-0.8024, -1.5507])\n",
      "epoch 93 after optimizer.step() : tensor([2.3145, 4.1991], requires_grad=True), required_grad : True\n",
      "epoch 94 loss is 1.9019742012023926\n",
      "epoch 94 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 94 : params.grad right after loss.backward(): tensor([-0.7930, -1.5206])\n",
      "epoch 94 after optimizer.step() : tensor([2.3224, 4.2143], requires_grad=True), required_grad : True\n",
      "epoch 95 loss is 1.872826337814331\n",
      "epoch 95 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 95 : params.grad right after loss.backward(): tensor([-0.7837, -1.4910])\n",
      "epoch 95 after optimizer.step() : tensor([2.3303, 4.2293], requires_grad=True), required_grad : True\n",
      "epoch 96 loss is 1.84470534324646\n",
      "epoch 96 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 96 : params.grad right after loss.backward(): tensor([-0.7744, -1.4621])\n",
      "epoch 96 after optimizer.step() : tensor([2.3380, 4.2439], requires_grad=True), required_grad : True\n",
      "epoch 97 loss is 1.8175723552703857\n",
      "epoch 97 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 97 : params.grad right after loss.backward(): tensor([-0.7653, -1.4338])\n",
      "epoch 97 after optimizer.step() : tensor([2.3457, 4.2582], requires_grad=True), required_grad : True\n",
      "epoch 98 loss is 1.7913925647735596\n",
      "epoch 98 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 98 : params.grad right after loss.backward(): tensor([-0.7563, -1.4060])\n",
      "epoch 98 after optimizer.step() : tensor([2.3532, 4.2723], requires_grad=True), required_grad : True\n",
      "epoch 99 loss is 1.7661311626434326\n",
      "epoch 99 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 99 : params.grad right after loss.backward(): tensor([-0.7473, -1.3787])\n",
      "epoch 99 after optimizer.step() : tensor([2.3607, 4.2861], requires_grad=True), required_grad : True\n",
      "epoch 100 loss is 1.741755485534668\n",
      "epoch 100 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 100 : params.grad right after loss.backward(): tensor([-0.7385, -1.3520])\n",
      "epoch 100 after optimizer.step() : tensor([2.3681, 4.2996], requires_grad=True), required_grad : True\n",
      "epoch 101 loss is 1.7182326316833496\n",
      "epoch 101 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 101 : params.grad right after loss.backward(): tensor([-0.7298, -1.3258])\n",
      "epoch 101 after optimizer.step() : tensor([2.3754, 4.3128], requires_grad=True), required_grad : True\n",
      "epoch 102 loss is 1.695533037185669\n",
      "epoch 102 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 102 : params.grad right after loss.backward(): tensor([-0.7211, -1.3001])\n",
      "epoch 102 after optimizer.step() : tensor([2.3826, 4.3258], requires_grad=True), required_grad : True\n",
      "epoch 103 loss is 1.6736253499984741\n",
      "epoch 103 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 103 : params.grad right after loss.backward(): tensor([-0.7125, -1.2749])\n",
      "epoch 103 after optimizer.step() : tensor([2.3897, 4.3386], requires_grad=True), required_grad : True\n",
      "epoch 104 loss is 1.6524816751480103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 104 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 104 : params.grad right after loss.backward(): tensor([-0.7041, -1.2502])\n",
      "epoch 104 after optimizer.step() : tensor([2.3968, 4.3511], requires_grad=True), required_grad : True\n",
      "epoch 105 loss is 1.632075548171997\n",
      "epoch 105 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 105 : params.grad right after loss.backward(): tensor([-0.6957, -1.2260])\n",
      "epoch 105 after optimizer.step() : tensor([2.4037, 4.3634], requires_grad=True), required_grad : True\n",
      "epoch 106 loss is 1.6123794317245483\n",
      "epoch 106 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 106 : params.grad right after loss.backward(): tensor([-0.6874, -1.2023])\n",
      "epoch 106 after optimizer.step() : tensor([2.4106, 4.3754], requires_grad=True), required_grad : True\n",
      "epoch 107 loss is 1.593367576599121\n",
      "epoch 107 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 107 : params.grad right after loss.backward(): tensor([-0.6792, -1.1790])\n",
      "epoch 107 after optimizer.step() : tensor([2.4174, 4.3872], requires_grad=True), required_grad : True\n",
      "epoch 108 loss is 1.5750161409378052\n",
      "epoch 108 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 108 : params.grad right after loss.backward(): tensor([-0.6710, -1.1562])\n",
      "epoch 108 after optimizer.step() : tensor([2.4241, 4.3987], requires_grad=True), required_grad : True\n",
      "epoch 109 loss is 1.5573015213012695\n",
      "epoch 109 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 109 : params.grad right after loss.backward(): tensor([-0.6630, -1.1338])\n",
      "epoch 109 after optimizer.step() : tensor([2.4307, 4.4101], requires_grad=True), required_grad : True\n",
      "epoch 110 loss is 1.540199875831604\n",
      "epoch 110 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 110 : params.grad right after loss.backward(): tensor([-0.6551, -1.1119])\n",
      "epoch 110 after optimizer.step() : tensor([2.4373, 4.4212], requires_grad=True), required_grad : True\n",
      "epoch 111 loss is 1.5236903429031372\n",
      "epoch 111 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 111 : params.grad right after loss.backward(): tensor([-0.6472, -1.0904])\n",
      "epoch 111 after optimizer.step() : tensor([2.4438, 4.4321], requires_grad=True), required_grad : True\n",
      "epoch 112 loss is 1.5077513456344604\n",
      "epoch 112 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 112 : params.grad right after loss.backward(): tensor([-0.6394, -1.0694])\n",
      "epoch 112 after optimizer.step() : tensor([2.4502, 4.4428], requires_grad=True), required_grad : True\n",
      "epoch 113 loss is 1.4923624992370605\n",
      "epoch 113 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 113 : params.grad right after loss.backward(): tensor([-0.6317, -1.0487])\n",
      "epoch 113 after optimizer.step() : tensor([2.4565, 4.4533], requires_grad=True), required_grad : True\n",
      "epoch 114 loss is 1.4775042533874512\n",
      "epoch 114 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 114 : params.grad right after loss.backward(): tensor([-0.6241, -1.0284])\n",
      "epoch 114 after optimizer.step() : tensor([2.4627, 4.4636], requires_grad=True), required_grad : True\n",
      "epoch 115 loss is 1.4631575345993042\n",
      "epoch 115 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 115 : params.grad right after loss.backward(): tensor([-0.6166, -1.0086])\n",
      "epoch 115 after optimizer.step() : tensor([2.4689, 4.4736], requires_grad=True), required_grad : True\n",
      "epoch 116 loss is 1.4493041038513184\n",
      "epoch 116 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 116 : params.grad right after loss.backward(): tensor([-0.6092, -0.9891])\n",
      "epoch 116 after optimizer.step() : tensor([2.4750, 4.4835], requires_grad=True), required_grad : True\n",
      "epoch 117 loss is 1.4359267950057983\n",
      "epoch 117 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 117 : params.grad right after loss.backward(): tensor([-0.6018, -0.9700])\n",
      "epoch 117 after optimizer.step() : tensor([2.4810, 4.4932], requires_grad=True), required_grad : True\n",
      "epoch 118 loss is 1.4230083227157593\n",
      "epoch 118 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 118 : params.grad right after loss.backward(): tensor([-0.5945, -0.9513])\n",
      "epoch 118 after optimizer.step() : tensor([2.4869, 4.5027], requires_grad=True), required_grad : True\n",
      "epoch 119 loss is 1.4105327129364014\n",
      "epoch 119 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 119 : params.grad right after loss.backward(): tensor([-0.5873, -0.9330])\n",
      "epoch 119 after optimizer.step() : tensor([2.4928, 4.5121], requires_grad=True), required_grad : True\n",
      "epoch 120 loss is 1.3984838724136353\n",
      "epoch 120 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 120 : params.grad right after loss.backward(): tensor([-0.5802, -0.9150])\n",
      "epoch 120 after optimizer.step() : tensor([2.4986, 4.5212], requires_grad=True), required_grad : True\n",
      "epoch 121 loss is 1.3868470191955566\n",
      "epoch 121 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 121 : params.grad right after loss.backward(): tensor([-0.5731, -0.8973])\n",
      "epoch 121 after optimizer.step() : tensor([2.5043, 4.5302], requires_grad=True), required_grad : True\n",
      "epoch 122 loss is 1.375607967376709\n",
      "epoch 122 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 122 : params.grad right after loss.backward(): tensor([-0.5662, -0.8800])\n",
      "epoch 122 after optimizer.step() : tensor([2.5100, 4.5390], requires_grad=True), required_grad : True\n",
      "epoch 123 loss is 1.3647515773773193\n",
      "epoch 123 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 123 : params.grad right after loss.backward(): tensor([-0.5593, -0.8631])\n",
      "epoch 123 after optimizer.step() : tensor([2.5156, 4.5476], requires_grad=True), required_grad : True\n",
      "epoch 124 loss is 1.3542650938034058\n",
      "epoch 124 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 124 : params.grad right after loss.backward(): tensor([-0.5525, -0.8465])\n",
      "epoch 124 after optimizer.step() : tensor([2.5211, 4.5561], requires_grad=True), required_grad : True\n",
      "epoch 125 loss is 1.3441357612609863\n",
      "epoch 125 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 125 : params.grad right after loss.backward(): tensor([-0.5458, -0.8302])\n",
      "epoch 125 after optimizer.step() : tensor([2.5266, 4.5644], requires_grad=True), required_grad : True\n",
      "epoch 126 loss is 1.3343499898910522\n",
      "epoch 126 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 126 : params.grad right after loss.backward(): tensor([-0.5391, -0.8142])\n",
      "epoch 126 after optimizer.step() : tensor([2.5320, 4.5725], requires_grad=True), required_grad : True\n",
      "epoch 127 loss is 1.3248966932296753\n",
      "epoch 127 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 127 : params.grad right after loss.backward(): tensor([-0.5325, -0.7985])\n",
      "epoch 127 after optimizer.step() : tensor([2.5373, 4.5805], requires_grad=True), required_grad : True\n",
      "epoch 128 loss is 1.3157635927200317\n",
      "epoch 128 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 128 : params.grad right after loss.backward(): tensor([-0.5260, -0.7831])\n",
      "epoch 128 after optimizer.step() : tensor([2.5426, 4.5884], requires_grad=True), required_grad : True\n",
      "epoch 129 loss is 1.3069396018981934\n",
      "epoch 129 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 129 : params.grad right after loss.backward(): tensor([-0.5196, -0.7681])\n",
      "epoch 129 after optimizer.step() : tensor([2.5478, 4.5960], requires_grad=True), required_grad : True\n",
      "epoch 130 loss is 1.2984139919281006\n",
      "epoch 130 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 130 : params.grad right after loss.backward(): tensor([-0.5132, -0.7533])\n",
      "epoch 130 after optimizer.step() : tensor([2.5529, 4.6036], requires_grad=True), required_grad : True\n",
      "epoch 131 loss is 1.290176272392273\n",
      "epoch 131 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 131 : params.grad right after loss.backward(): tensor([-0.5069, -0.7388])\n",
      "epoch 131 after optimizer.step() : tensor([2.5580, 4.6110], requires_grad=True), required_grad : True\n",
      "epoch 132 loss is 1.2822166681289673\n",
      "epoch 132 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 132 : params.grad right after loss.backward(): tensor([-0.5007, -0.7246])\n",
      "epoch 132 after optimizer.step() : tensor([2.5630, 4.6182], requires_grad=True), required_grad : True\n",
      "epoch 133 loss is 1.2745249271392822\n",
      "epoch 133 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 133 : params.grad right after loss.backward(): tensor([-0.4945, -0.7107])\n",
      "epoch 133 after optimizer.step() : tensor([2.5679, 4.6253], requires_grad=True), required_grad : True\n",
      "epoch 134 loss is 1.2670921087265015\n",
      "epoch 134 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 134 : params.grad right after loss.backward(): tensor([-0.4885, -0.6970])\n",
      "epoch 134 after optimizer.step() : tensor([2.5728, 4.6323], requires_grad=True), required_grad : True\n",
      "epoch 135 loss is 1.2599090337753296\n",
      "epoch 135 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 135 : params.grad right after loss.backward(): tensor([-0.4824, -0.6837])\n",
      "epoch 135 after optimizer.step() : tensor([2.5776, 4.6391], requires_grad=True), required_grad : True\n",
      "epoch 136 loss is 1.2529668807983398\n",
      "epoch 136 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 136 : params.grad right after loss.backward(): tensor([-0.4765, -0.6705])\n",
      "epoch 136 after optimizer.step() : tensor([2.5824, 4.6458], requires_grad=True), required_grad : True\n",
      "epoch 137 loss is 1.2462573051452637\n",
      "epoch 137 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 137 : params.grad right after loss.backward(): tensor([-0.4706, -0.6577])\n",
      "epoch 137 after optimizer.step() : tensor([2.5871, 4.6524], requires_grad=True), required_grad : True\n",
      "epoch 138 loss is 1.2397725582122803\n",
      "epoch 138 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 138 : params.grad right after loss.backward(): tensor([-0.4648, -0.6450])\n",
      "epoch 138 after optimizer.step() : tensor([2.5917, 4.6588], requires_grad=True), required_grad : True\n",
      "epoch 139 loss is 1.233504295349121\n",
      "epoch 139 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 139 : params.grad right after loss.backward(): tensor([-0.4591, -0.6327])\n",
      "epoch 139 after optimizer.step() : tensor([2.5963, 4.6652], requires_grad=True), required_grad : True\n",
      "epoch 140 loss is 1.2274454832077026\n",
      "epoch 140 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 140 : params.grad right after loss.backward(): tensor([-0.4534, -0.6205])\n",
      "epoch 140 after optimizer.step() : tensor([2.6009, 4.6714], requires_grad=True), required_grad : True\n",
      "epoch 141 loss is 1.2215886116027832\n",
      "epoch 141 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 141 : params.grad right after loss.backward(): tensor([-0.4478, -0.6087])\n",
      "epoch 141 after optimizer.step() : tensor([2.6053, 4.6775], requires_grad=True), required_grad : True\n",
      "epoch 142 loss is 1.2159268856048584\n",
      "epoch 142 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 142 : params.grad right after loss.backward(): tensor([-0.4422, -0.5970])\n",
      "epoch 142 after optimizer.step() : tensor([2.6098, 4.6834], requires_grad=True), required_grad : True\n",
      "epoch 143 loss is 1.2104535102844238\n",
      "epoch 143 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 143 : params.grad right after loss.backward(): tensor([-0.4368, -0.5855])\n",
      "epoch 143 after optimizer.step() : tensor([2.6141, 4.6893], requires_grad=True), required_grad : True\n",
      "epoch 144 loss is 1.2051618099212646\n",
      "epoch 144 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 144 : params.grad right after loss.backward(): tensor([-0.4313, -0.5743])\n",
      "epoch 144 after optimizer.step() : tensor([2.6184, 4.6950], requires_grad=True), required_grad : True\n",
      "epoch 145 loss is 1.2000457048416138\n",
      "epoch 145 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 145 : params.grad right after loss.backward(): tensor([-0.4260, -0.5633])\n",
      "epoch 145 after optimizer.step() : tensor([2.6227, 4.7007], requires_grad=True), required_grad : True\n",
      "epoch 146 loss is 1.1950993537902832\n",
      "epoch 146 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 146 : params.grad right after loss.backward(): tensor([-0.4207, -0.5526])\n",
      "epoch 146 after optimizer.step() : tensor([2.6269, 4.7062], requires_grad=True), required_grad : True\n",
      "epoch 147 loss is 1.1903164386749268\n",
      "epoch 147 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 147 : params.grad right after loss.backward(): tensor([-0.4155, -0.5420])\n",
      "epoch 147 after optimizer.step() : tensor([2.6311, 4.7116], requires_grad=True), required_grad : True\n",
      "epoch 148 loss is 1.1856917142868042\n",
      "epoch 148 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 148 : params.grad right after loss.backward(): tensor([-0.4103, -0.5316])\n",
      "epoch 148 after optimizer.step() : tensor([2.6352, 4.7169], requires_grad=True), required_grad : True\n",
      "epoch 149 loss is 1.1812196969985962\n",
      "epoch 149 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 149 : params.grad right after loss.backward(): tensor([-0.4052, -0.5215])\n",
      "epoch 149 after optimizer.step() : tensor([2.6392, 4.7221], requires_grad=True), required_grad : True\n",
      "epoch 150 loss is 1.176895260810852\n",
      "epoch 150 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 150 : params.grad right after loss.backward(): tensor([-0.4001, -0.5115])\n",
      "epoch 150 after optimizer.step() : tensor([2.6432, 4.7273], requires_grad=True), required_grad : True\n",
      "epoch 151 loss is 1.172713041305542\n",
      "epoch 151 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 151 : params.grad right after loss.backward(): tensor([-0.3951, -0.5017])\n",
      "epoch 151 after optimizer.step() : tensor([2.6472, 4.7323], requires_grad=True), required_grad : True\n",
      "epoch 152 loss is 1.168668270111084\n",
      "epoch 152 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 152 : params.grad right after loss.backward(): tensor([-0.3902, -0.4921])\n",
      "epoch 152 after optimizer.step() : tensor([2.6511, 4.7372], requires_grad=True), required_grad : True\n",
      "epoch 153 loss is 1.164756417274475\n",
      "epoch 153 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 153 : params.grad right after loss.backward(): tensor([-0.3853, -0.4827])\n",
      "epoch 153 after optimizer.step() : tensor([2.6549, 4.7420], requires_grad=True), required_grad : True\n",
      "epoch 154 loss is 1.160973310470581\n",
      "epoch 154 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 154 : params.grad right after loss.backward(): tensor([-0.3805, -0.4735])\n",
      "epoch 154 after optimizer.step() : tensor([2.6587, 4.7468], requires_grad=True), required_grad : True\n",
      "epoch 155 loss is 1.1573138236999512\n",
      "epoch 155 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 155 : params.grad right after loss.backward(): tensor([-0.3757, -0.4645])\n",
      "epoch 155 after optimizer.step() : tensor([2.6625, 4.7514], requires_grad=True), required_grad : True\n",
      "epoch 156 loss is 1.1537739038467407\n",
      "epoch 156 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 156 : params.grad right after loss.backward(): tensor([-0.3710, -0.4556])\n",
      "epoch 156 after optimizer.step() : tensor([2.6662, 4.7560], requires_grad=True), required_grad : True\n",
      "epoch 157 loss is 1.1503500938415527\n",
      "epoch 157 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 157 : params.grad right after loss.backward(): tensor([-0.3664, -0.4469])\n",
      "epoch 157 after optimizer.step() : tensor([2.6699, 4.7604], requires_grad=True), required_grad : True\n",
      "epoch 158 loss is 1.1470377445220947\n",
      "epoch 158 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 158 : params.grad right after loss.backward(): tensor([-0.3618, -0.4384])\n",
      "epoch 158 after optimizer.step() : tensor([2.6735, 4.7648], requires_grad=True), required_grad : True\n",
      "epoch 159 loss is 1.1438333988189697\n",
      "epoch 159 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 159 : params.grad right after loss.backward(): tensor([-0.3572, -0.4300])\n",
      "epoch 159 after optimizer.step() : tensor([2.6770, 4.7691], requires_grad=True), required_grad : True\n",
      "epoch 160 loss is 1.1407333612442017\n",
      "epoch 160 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 160 : params.grad right after loss.backward(): tensor([-0.3528, -0.4218])\n",
      "epoch 160 after optimizer.step() : tensor([2.6806, 4.7733], requires_grad=True), required_grad : True\n",
      "epoch 161 loss is 1.1377341747283936\n",
      "epoch 161 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 161 : params.grad right after loss.backward(): tensor([-0.3483, -0.4138])\n",
      "epoch 161 after optimizer.step() : tensor([2.6841, 4.7775], requires_grad=True), required_grad : True\n",
      "epoch 162 loss is 1.134832739830017\n",
      "epoch 162 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 162 : params.grad right after loss.backward(): tensor([-0.3439, -0.4059])\n",
      "epoch 162 after optimizer.step() : tensor([2.6875, 4.7815], requires_grad=True), required_grad : True\n",
      "epoch 163 loss is 1.132024884223938\n",
      "epoch 163 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 163 : params.grad right after loss.backward(): tensor([-0.3396, -0.3982])\n",
      "epoch 163 after optimizer.step() : tensor([2.6909, 4.7855], requires_grad=True), required_grad : True\n",
      "epoch 164 loss is 1.1293083429336548\n",
      "epoch 164 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 164 : params.grad right after loss.backward(): tensor([-0.3353, -0.3906])\n",
      "epoch 164 after optimizer.step() : tensor([2.6942, 4.7894], requires_grad=True), required_grad : True\n",
      "epoch 165 loss is 1.126679539680481\n",
      "epoch 165 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 165 : params.grad right after loss.backward(): tensor([-0.3311, -0.3832])\n",
      "epoch 165 after optimizer.step() : tensor([2.6976, 4.7933], requires_grad=True), required_grad : True\n",
      "epoch 166 loss is 1.1241358518600464\n",
      "epoch 166 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 166 : params.grad right after loss.backward(): tensor([-0.3269, -0.3759])\n",
      "epoch 166 after optimizer.step() : tensor([2.7008, 4.7970], requires_grad=True), required_grad : True\n",
      "epoch 167 loss is 1.1216741800308228\n",
      "epoch 167 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 167 : params.grad right after loss.backward(): tensor([-0.3228, -0.3688])\n",
      "epoch 167 after optimizer.step() : tensor([2.7041, 4.8007], requires_grad=True), required_grad : True\n",
      "epoch 168 loss is 1.11929190158844\n",
      "epoch 168 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 168 : params.grad right after loss.backward(): tensor([-0.3187, -0.3618])\n",
      "epoch 168 after optimizer.step() : tensor([2.7072, 4.8043], requires_grad=True), required_grad : True\n",
      "epoch 169 loss is 1.1169863939285278\n",
      "epoch 169 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 169 : params.grad right after loss.backward(): tensor([-0.3147, -0.3549])\n",
      "epoch 169 after optimizer.step() : tensor([2.7104, 4.8079], requires_grad=True), required_grad : True\n",
      "epoch 170 loss is 1.1147550344467163\n",
      "epoch 170 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 170 : params.grad right after loss.backward(): tensor([-0.3107, -0.3481])\n",
      "epoch 170 after optimizer.step() : tensor([2.7135, 4.8113], requires_grad=True), required_grad : True\n",
      "epoch 171 loss is 1.1125953197479248\n",
      "epoch 171 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 171 : params.grad right after loss.backward(): tensor([-0.3068, -0.3415])\n",
      "epoch 171 after optimizer.step() : tensor([2.7166, 4.8148], requires_grad=True), required_grad : True\n",
      "epoch 172 loss is 1.1105046272277832\n",
      "epoch 172 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 172 : params.grad right after loss.backward(): tensor([-0.3029, -0.3351])\n",
      "epoch 172 after optimizer.step() : tensor([2.7196, 4.8181], requires_grad=True), required_grad : True\n",
      "epoch 173 loss is 1.1084809303283691\n",
      "epoch 173 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 173 : params.grad right after loss.backward(): tensor([-0.2991, -0.3287])\n",
      "epoch 173 after optimizer.step() : tensor([2.7226, 4.8214], requires_grad=True), required_grad : True\n",
      "epoch 174 loss is 1.1065224409103394\n",
      "epoch 174 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 174 : params.grad right after loss.backward(): tensor([-0.2953, -0.3225])\n",
      "epoch 174 after optimizer.step() : tensor([2.7255, 4.8246], requires_grad=True), required_grad : True\n",
      "epoch 175 loss is 1.1046264171600342\n",
      "epoch 175 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 175 : params.grad right after loss.backward(): tensor([-0.2915, -0.3163])\n",
      "epoch 175 after optimizer.step() : tensor([2.7285, 4.8278], requires_grad=True), required_grad : True\n",
      "epoch 176 loss is 1.1027904748916626\n",
      "epoch 176 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 176 : params.grad right after loss.backward(): tensor([-0.2878, -0.3104])\n",
      "epoch 176 after optimizer.step() : tensor([2.7313, 4.8309], requires_grad=True), required_grad : True\n",
      "epoch 177 loss is 1.101013422012329\n",
      "epoch 177 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 177 : params.grad right after loss.backward(): tensor([-0.2842, -0.3045])\n",
      "epoch 177 after optimizer.step() : tensor([2.7342, 4.8339], requires_grad=True), required_grad : True\n",
      "epoch 178 loss is 1.0992927551269531\n",
      "epoch 178 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 178 : params.grad right after loss.backward(): tensor([-0.2805, -0.2987])\n",
      "epoch 178 after optimizer.step() : tensor([2.7370, 4.8369], requires_grad=True), required_grad : True\n",
      "epoch 179 loss is 1.0976269245147705\n",
      "epoch 179 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 179 : params.grad right after loss.backward(): tensor([-0.2770, -0.2931])\n",
      "epoch 179 after optimizer.step() : tensor([2.7397, 4.8399], requires_grad=True), required_grad : True\n",
      "epoch 180 loss is 1.096014142036438\n",
      "epoch 180 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 180 : params.grad right after loss.backward(): tensor([-0.2735, -0.2875])\n",
      "epoch 180 after optimizer.step() : tensor([2.7425, 4.8427], requires_grad=True), required_grad : True\n",
      "epoch 181 loss is 1.0944522619247437\n",
      "epoch 181 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 181 : params.grad right after loss.backward(): tensor([-0.2700, -0.2821])\n",
      "epoch 181 after optimizer.step() : tensor([2.7452, 4.8455], requires_grad=True), required_grad : True\n",
      "epoch 182 loss is 1.092940092086792\n",
      "epoch 182 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 182 : params.grad right after loss.backward(): tensor([-0.2665, -0.2767])\n",
      "epoch 182 after optimizer.step() : tensor([2.7478, 4.8483], requires_grad=True), required_grad : True\n",
      "epoch 183 loss is 1.091475486755371\n",
      "epoch 183 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 183 : params.grad right after loss.backward(): tensor([-0.2631, -0.2715])\n",
      "epoch 183 after optimizer.step() : tensor([2.7505, 4.8510], requires_grad=True), required_grad : True\n",
      "epoch 184 loss is 1.090057373046875\n",
      "epoch 184 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 184 : params.grad right after loss.backward(): tensor([-0.2598, -0.2664])\n",
      "epoch 184 after optimizer.step() : tensor([2.7531, 4.8537], requires_grad=True), required_grad : True\n",
      "epoch 185 loss is 1.0886842012405396\n",
      "epoch 185 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 185 : params.grad right after loss.backward(): tensor([-0.2565, -0.2613])\n",
      "epoch 185 after optimizer.step() : tensor([2.7556, 4.8563], requires_grad=True), required_grad : True\n",
      "epoch 186 loss is 1.0873541831970215\n",
      "epoch 186 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 186 : params.grad right after loss.backward(): tensor([-0.2532, -0.2564])\n",
      "epoch 186 after optimizer.step() : tensor([2.7582, 4.8589], requires_grad=True), required_grad : True\n",
      "epoch 187 loss is 1.0860657691955566\n",
      "epoch 187 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 187 : params.grad right after loss.backward(): tensor([-0.2499, -0.2516])\n",
      "epoch 187 after optimizer.step() : tensor([2.7607, 4.8614], requires_grad=True), required_grad : True\n",
      "epoch 188 loss is 1.0848182439804077\n",
      "epoch 188 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 188 : params.grad right after loss.backward(): tensor([-0.2468, -0.2468])\n",
      "epoch 188 after optimizer.step() : tensor([2.7631, 4.8639], requires_grad=True), required_grad : True\n",
      "epoch 189 loss is 1.0836098194122314\n",
      "epoch 189 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 189 : params.grad right after loss.backward(): tensor([-0.2436, -0.2422])\n",
      "epoch 189 after optimizer.step() : tensor([2.7656, 4.8663], requires_grad=True), required_grad : True\n",
      "epoch 190 loss is 1.0824395418167114\n",
      "epoch 190 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 190 : params.grad right after loss.backward(): tensor([-0.2405, -0.2376])\n",
      "epoch 190 after optimizer.step() : tensor([2.7680, 4.8687], requires_grad=True), required_grad : True\n",
      "epoch 191 loss is 1.0813055038452148\n",
      "epoch 191 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 191 : params.grad right after loss.backward(): tensor([-0.2374, -0.2331])\n",
      "epoch 191 after optimizer.step() : tensor([2.7704, 4.8710], requires_grad=True), required_grad : True\n",
      "epoch 192 loss is 1.080207347869873\n",
      "epoch 192 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 192 : params.grad right after loss.backward(): tensor([-0.2344, -0.2287])\n",
      "epoch 192 after optimizer.step() : tensor([2.7727, 4.8733], requires_grad=True), required_grad : True\n",
      "epoch 193 loss is 1.0791435241699219\n",
      "epoch 193 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 193 : params.grad right after loss.backward(): tensor([-0.2313, -0.2244])\n",
      "epoch 193 after optimizer.step() : tensor([2.7750, 4.8755], requires_grad=True), required_grad : True\n",
      "epoch 194 loss is 1.0781128406524658\n",
      "epoch 194 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 194 : params.grad right after loss.backward(): tensor([-0.2284, -0.2202])\n",
      "epoch 194 after optimizer.step() : tensor([2.7773, 4.8777], requires_grad=True), required_grad : True\n",
      "epoch 195 loss is 1.077114224433899\n",
      "epoch 195 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 195 : params.grad right after loss.backward(): tensor([-0.2254, -0.2160])\n",
      "epoch 195 after optimizer.step() : tensor([2.7795, 4.8799], requires_grad=True), required_grad : True\n",
      "epoch 196 loss is 1.0761468410491943\n",
      "epoch 196 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 196 : params.grad right after loss.backward(): tensor([-0.2226, -0.2120])\n",
      "epoch 196 after optimizer.step() : tensor([2.7818, 4.8820], requires_grad=True), required_grad : True\n",
      "epoch 197 loss is 1.075209617614746\n",
      "epoch 197 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 197 : params.grad right after loss.backward(): tensor([-0.2197, -0.2080])\n",
      "epoch 197 after optimizer.step() : tensor([2.7840, 4.8841], requires_grad=True), required_grad : True\n",
      "epoch 198 loss is 1.0743014812469482\n",
      "epoch 198 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 198 : params.grad right after loss.backward(): tensor([-0.2169, -0.2041])\n",
      "epoch 198 after optimizer.step() : tensor([2.7861, 4.8861], requires_grad=True), required_grad : True\n",
      "epoch 199 loss is 1.073421597480774\n",
      "epoch 199 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 199 : params.grad right after loss.backward(): tensor([-0.2141, -0.2002])\n",
      "epoch 199 after optimizer.step() : tensor([2.7883, 4.8881], requires_grad=True), required_grad : True\n",
      "epoch 200 loss is 1.0725690126419067\n",
      "epoch 200 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 200 : params.grad right after loss.backward(): tensor([-0.2113, -0.1965])\n",
      "epoch 200 after optimizer.step() : tensor([2.7904, 4.8901], requires_grad=True), required_grad : True\n",
      "epoch 201 loss is 1.0717426538467407\n",
      "epoch 201 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 201 : params.grad right after loss.backward(): tensor([-0.2086, -0.1928])\n",
      "epoch 201 after optimizer.step() : tensor([2.7925, 4.8920], requires_grad=True), required_grad : True\n",
      "epoch 202 loss is 1.0709421634674072\n",
      "epoch 202 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 202 : params.grad right after loss.backward(): tensor([-0.2059, -0.1892])\n",
      "epoch 202 after optimizer.step() : tensor([2.7945, 4.8939], requires_grad=True), required_grad : True\n",
      "epoch 203 loss is 1.0701664686203003\n",
      "epoch 203 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 203 : params.grad right after loss.backward(): tensor([-0.2033, -0.1856])\n",
      "epoch 203 after optimizer.step() : tensor([2.7966, 4.8958], requires_grad=True), required_grad : True\n",
      "epoch 204 loss is 1.0694143772125244\n",
      "epoch 204 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 204 : params.grad right after loss.backward(): tensor([-0.2006, -0.1821])\n",
      "epoch 204 after optimizer.step() : tensor([2.7986, 4.8976], requires_grad=True), required_grad : True\n",
      "epoch 205 loss is 1.0686858892440796\n",
      "epoch 205 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 205 : params.grad right after loss.backward(): tensor([-0.1981, -0.1787])\n",
      "epoch 205 after optimizer.step() : tensor([2.8006, 4.8994], requires_grad=True), required_grad : True\n",
      "epoch 206 loss is 1.0679796934127808\n",
      "epoch 206 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 206 : params.grad right after loss.backward(): tensor([-0.1955, -0.1754])\n",
      "epoch 206 after optimizer.step() : tensor([2.8025, 4.9011], requires_grad=True), required_grad : True\n",
      "epoch 207 loss is 1.0672951936721802\n",
      "epoch 207 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 207 : params.grad right after loss.backward(): tensor([-0.1930, -0.1721])\n",
      "epoch 207 after optimizer.step() : tensor([2.8044, 4.9028], requires_grad=True), required_grad : True\n",
      "epoch 208 loss is 1.0666316747665405\n",
      "epoch 208 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 208 : params.grad right after loss.backward(): tensor([-0.1905, -0.1689])\n",
      "epoch 208 after optimizer.step() : tensor([2.8063, 4.9045], requires_grad=True), required_grad : True\n",
      "epoch 209 loss is 1.0659887790679932\n",
      "epoch 209 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 209 : params.grad right after loss.backward(): tensor([-0.1880, -0.1657])\n",
      "epoch 209 after optimizer.step() : tensor([2.8082, 4.9062], requires_grad=True), required_grad : True\n",
      "epoch 210 loss is 1.0653655529022217\n",
      "epoch 210 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 210 : params.grad right after loss.backward(): tensor([-0.1856, -0.1626])\n",
      "epoch 210 after optimizer.step() : tensor([2.8101, 4.9078], requires_grad=True), required_grad : True\n",
      "epoch 211 loss is 1.0647614002227783\n",
      "epoch 211 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 211 : params.grad right after loss.backward(): tensor([-0.1832, -0.1596])\n",
      "epoch 211 after optimizer.step() : tensor([2.8119, 4.9094], requires_grad=True), required_grad : True\n",
      "epoch 212 loss is 1.0641756057739258\n",
      "epoch 212 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 212 : params.grad right after loss.backward(): tensor([-0.1808, -0.1566])\n",
      "epoch 212 after optimizer.step() : tensor([2.8137, 4.9110], requires_grad=True), required_grad : True\n",
      "epoch 213 loss is 1.0636078119277954\n",
      "epoch 213 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 213 : params.grad right after loss.backward(): tensor([-0.1785, -0.1537])\n",
      "epoch 213 after optimizer.step() : tensor([2.8155, 4.9125], requires_grad=True), required_grad : True\n",
      "epoch 214 loss is 1.0630574226379395\n",
      "epoch 214 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 214 : params.grad right after loss.backward(): tensor([-0.1762, -0.1508])\n",
      "epoch 214 after optimizer.step() : tensor([2.8173, 4.9140], requires_grad=True), required_grad : True\n",
      "epoch 215 loss is 1.0625238418579102\n",
      "epoch 215 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 215 : params.grad right after loss.backward(): tensor([-0.1739, -0.1480])\n",
      "epoch 215 after optimizer.step() : tensor([2.8190, 4.9155], requires_grad=True), required_grad : True\n",
      "epoch 216 loss is 1.0620064735412598\n",
      "epoch 216 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 216 : params.grad right after loss.backward(): tensor([-0.1716, -0.1452])\n",
      "epoch 216 after optimizer.step() : tensor([2.8207, 4.9170], requires_grad=True), required_grad : True\n",
      "epoch 217 loss is 1.0615049600601196\n",
      "epoch 217 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 217 : params.grad right after loss.backward(): tensor([-0.1694, -0.1425])\n",
      "epoch 217 after optimizer.step() : tensor([2.8224, 4.9184], requires_grad=True), required_grad : True\n",
      "epoch 218 loss is 1.061018705368042\n",
      "epoch 218 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 218 : params.grad right after loss.backward(): tensor([-0.1672, -0.1399])\n",
      "epoch 218 after optimizer.step() : tensor([2.8241, 4.9198], requires_grad=True), required_grad : True\n",
      "epoch 219 loss is 1.0605472326278687\n",
      "epoch 219 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 219 : params.grad right after loss.backward(): tensor([-0.1650, -0.1372])\n",
      "epoch 219 after optimizer.step() : tensor([2.8257, 4.9212], requires_grad=True), required_grad : True\n",
      "epoch 220 loss is 1.0600899457931519\n",
      "epoch 220 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 220 : params.grad right after loss.backward(): tensor([-0.1629, -0.1347])\n",
      "epoch 220 after optimizer.step() : tensor([2.8274, 4.9225], requires_grad=True), required_grad : True\n",
      "epoch 221 loss is 1.059646725654602\n",
      "epoch 221 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 221 : params.grad right after loss.backward(): tensor([-0.1608, -0.1322])\n",
      "epoch 221 after optimizer.step() : tensor([2.8290, 4.9238], requires_grad=True), required_grad : True\n",
      "epoch 222 loss is 1.0592164993286133\n",
      "epoch 222 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 222 : params.grad right after loss.backward(): tensor([-0.1587, -0.1297])\n",
      "epoch 222 after optimizer.step() : tensor([2.8306, 4.9251], requires_grad=True), required_grad : True\n",
      "epoch 223 loss is 1.0587997436523438\n",
      "epoch 223 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 223 : params.grad right after loss.backward(): tensor([-0.1566, -0.1273])\n",
      "epoch 223 after optimizer.step() : tensor([2.8321, 4.9264], requires_grad=True), required_grad : True\n",
      "epoch 224 loss is 1.0583956241607666\n",
      "epoch 224 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 224 : params.grad right after loss.backward(): tensor([-0.1546, -0.1249])\n",
      "epoch 224 after optimizer.step() : tensor([2.8337, 4.9276], requires_grad=True), required_grad : True\n",
      "epoch 225 loss is 1.0580034255981445\n",
      "epoch 225 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 225 : params.grad right after loss.backward(): tensor([-0.1526, -0.1226])\n",
      "epoch 225 after optimizer.step() : tensor([2.8352, 4.9289], requires_grad=True), required_grad : True\n",
      "epoch 226 loss is 1.057623267173767\n",
      "epoch 226 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 226 : params.grad right after loss.backward(): tensor([-0.1506, -0.1203])\n",
      "epoch 226 after optimizer.step() : tensor([2.8367, 4.9301], requires_grad=True), required_grad : True\n",
      "epoch 227 loss is 1.057254433631897\n",
      "epoch 227 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 227 : params.grad right after loss.backward(): tensor([-0.1486, -0.1181])\n",
      "epoch 227 after optimizer.step() : tensor([2.8382, 4.9313], requires_grad=True), required_grad : True\n",
      "epoch 228 loss is 1.0568968057632446\n",
      "epoch 228 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 228 : params.grad right after loss.backward(): tensor([-0.1467, -0.1159])\n",
      "epoch 228 after optimizer.step() : tensor([2.8397, 4.9324], requires_grad=True), required_grad : True\n",
      "epoch 229 loss is 1.0565500259399414\n",
      "epoch 229 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 229 : params.grad right after loss.backward(): tensor([-0.1448, -0.1138])\n",
      "epoch 229 after optimizer.step() : tensor([2.8411, 4.9335], requires_grad=True), required_grad : True\n",
      "epoch 230 loss is 1.05621337890625\n",
      "epoch 230 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 230 : params.grad right after loss.backward(): tensor([-0.1429, -0.1116])\n",
      "epoch 230 after optimizer.step() : tensor([2.8425, 4.9347], requires_grad=True), required_grad : True\n",
      "epoch 231 loss is 1.05588698387146\n",
      "epoch 231 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 231 : params.grad right after loss.backward(): tensor([-0.1410, -0.1096])\n",
      "epoch 231 after optimizer.step() : tensor([2.8440, 4.9358], requires_grad=True), required_grad : True\n",
      "epoch 232 loss is 1.0555706024169922\n",
      "epoch 232 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 232 : params.grad right after loss.backward(): tensor([-0.1392, -0.1075])\n",
      "epoch 232 after optimizer.step() : tensor([2.8453, 4.9368], requires_grad=True), required_grad : True\n",
      "epoch 233 loss is 1.055263638496399\n",
      "epoch 233 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 233 : params.grad right after loss.backward(): tensor([-0.1374, -0.1056])\n",
      "epoch 233 after optimizer.step() : tensor([2.8467, 4.9379], requires_grad=True), required_grad : True\n",
      "epoch 234 loss is 1.054965615272522\n",
      "epoch 234 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 234 : params.grad right after loss.backward(): tensor([-0.1356, -0.1036])\n",
      "epoch 234 after optimizer.step() : tensor([2.8481, 4.9389], requires_grad=True), required_grad : True\n",
      "epoch 235 loss is 1.0546765327453613\n",
      "epoch 235 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 235 : params.grad right after loss.backward(): tensor([-0.1338, -0.1017])\n",
      "epoch 235 after optimizer.step() : tensor([2.8494, 4.9399], requires_grad=True), required_grad : True\n",
      "epoch 236 loss is 1.0543965101242065\n",
      "epoch 236 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 236 : params.grad right after loss.backward(): tensor([-0.1321, -0.0998])\n",
      "epoch 236 after optimizer.step() : tensor([2.8507, 4.9409], requires_grad=True), required_grad : True\n",
      "epoch 237 loss is 1.0541244745254517\n",
      "epoch 237 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 237 : params.grad right after loss.backward(): tensor([-0.1303, -0.0980])\n",
      "epoch 237 after optimizer.step() : tensor([2.8520, 4.9419], requires_grad=True), required_grad : True\n",
      "epoch 238 loss is 1.0538605451583862\n",
      "epoch 238 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 238 : params.grad right after loss.backward(): tensor([-0.1286, -0.0961])\n",
      "epoch 238 after optimizer.step() : tensor([2.8533, 4.9429], requires_grad=True), required_grad : True\n",
      "epoch 239 loss is 1.0536046028137207\n",
      "epoch 239 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 239 : params.grad right after loss.backward(): tensor([-0.1269, -0.0944])\n",
      "epoch 239 after optimizer.step() : tensor([2.8546, 4.9438], requires_grad=True), required_grad : True\n",
      "epoch 240 loss is 1.0533562898635864\n",
      "epoch 240 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 240 : params.grad right after loss.backward(): tensor([-0.1253, -0.0926])\n",
      "epoch 240 after optimizer.step() : tensor([2.8558, 4.9448], requires_grad=True), required_grad : True\n",
      "epoch 241 loss is 1.0531154870986938\n",
      "epoch 241 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 241 : params.grad right after loss.backward(): tensor([-0.1236, -0.0909])\n",
      "epoch 241 after optimizer.step() : tensor([2.8571, 4.9457], requires_grad=True), required_grad : True\n",
      "epoch 242 loss is 1.0528817176818848\n",
      "epoch 242 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 242 : params.grad right after loss.backward(): tensor([-0.1220, -0.0892])\n",
      "epoch 242 after optimizer.step() : tensor([2.8583, 4.9466], requires_grad=True), required_grad : True\n",
      "epoch 243 loss is 1.0526548624038696\n",
      "epoch 243 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 243 : params.grad right after loss.backward(): tensor([-0.1204, -0.0876])\n",
      "epoch 243 after optimizer.step() : tensor([2.8595, 4.9474], requires_grad=True), required_grad : True\n",
      "epoch 244 loss is 1.0524346828460693\n",
      "epoch 244 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 244 : params.grad right after loss.backward(): tensor([-0.1188, -0.0860])\n",
      "epoch 244 after optimizer.step() : tensor([2.8607, 4.9483], requires_grad=True), required_grad : True\n",
      "epoch 245 loss is 1.0522211790084839\n",
      "epoch 245 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 245 : params.grad right after loss.backward(): tensor([-0.1173, -0.0844])\n",
      "epoch 245 after optimizer.step() : tensor([2.8619, 4.9491], requires_grad=True), required_grad : True\n",
      "epoch 246 loss is 1.0520139932632446\n",
      "epoch 246 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 246 : params.grad right after loss.backward(): tensor([-0.1158, -0.0828])\n",
      "epoch 246 after optimizer.step() : tensor([2.8630, 4.9500], requires_grad=True), required_grad : True\n",
      "epoch 247 loss is 1.0518128871917725\n",
      "epoch 247 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 247 : params.grad right after loss.backward(): tensor([-0.1142, -0.0813])\n",
      "epoch 247 after optimizer.step() : tensor([2.8642, 4.9508], requires_grad=True), required_grad : True\n",
      "epoch 248 loss is 1.0516178607940674\n",
      "epoch 248 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 248 : params.grad right after loss.backward(): tensor([-0.1127, -0.0798])\n",
      "epoch 248 after optimizer.step() : tensor([2.8653, 4.9516], requires_grad=True), required_grad : True\n",
      "epoch 249 loss is 1.0514283180236816\n",
      "epoch 249 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 249 : params.grad right after loss.backward(): tensor([-0.1113, -0.0783])\n",
      "epoch 249 after optimizer.step() : tensor([2.8664, 4.9524], requires_grad=True), required_grad : True\n",
      "epoch 250 loss is 1.0512446165084839\n",
      "epoch 250 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 250 : params.grad right after loss.backward(): tensor([-0.1098, -0.0769])\n",
      "epoch 250 after optimizer.step() : tensor([2.8675, 4.9531], requires_grad=True), required_grad : True\n",
      "epoch 251 loss is 1.0510663986206055\n",
      "epoch 251 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 251 : params.grad right after loss.backward(): tensor([-0.1084, -0.0755])\n",
      "epoch 251 after optimizer.step() : tensor([2.8686, 4.9539], requires_grad=True), required_grad : True\n",
      "epoch 252 loss is 1.0508931875228882\n",
      "epoch 252 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 252 : params.grad right after loss.backward(): tensor([-0.1069, -0.0741])\n",
      "epoch 252 after optimizer.step() : tensor([2.8697, 4.9546], requires_grad=True), required_grad : True\n",
      "epoch 253 loss is 1.0507252216339111\n",
      "epoch 253 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 253 : params.grad right after loss.backward(): tensor([-0.1055, -0.0727])\n",
      "epoch 253 after optimizer.step() : tensor([2.8707, 4.9553], requires_grad=True), required_grad : True\n",
      "epoch 254 loss is 1.0505621433258057\n",
      "epoch 254 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 254 : params.grad right after loss.backward(): tensor([-0.1041, -0.0714])\n",
      "epoch 254 after optimizer.step() : tensor([2.8718, 4.9561], requires_grad=True), required_grad : True\n",
      "epoch 255 loss is 1.0504038333892822\n",
      "epoch 255 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 255 : params.grad right after loss.backward(): tensor([-0.1028, -0.0701])\n",
      "epoch 255 after optimizer.step() : tensor([2.8728, 4.9568], requires_grad=True), required_grad : True\n",
      "epoch 256 loss is 1.0502502918243408\n",
      "epoch 256 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 256 : params.grad right after loss.backward(): tensor([-0.1014, -0.0688])\n",
      "epoch 256 after optimizer.step() : tensor([2.8738, 4.9575], requires_grad=True), required_grad : True\n",
      "epoch 257 loss is 1.0501011610031128\n",
      "epoch 257 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 257 : params.grad right after loss.backward(): tensor([-0.1001, -0.0676])\n",
      "epoch 257 after optimizer.step() : tensor([2.8748, 4.9581], requires_grad=True), required_grad : True\n",
      "epoch 258 loss is 1.0499564409255981\n",
      "epoch 258 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 258 : params.grad right after loss.backward(): tensor([-0.0988, -0.0663])\n",
      "epoch 258 after optimizer.step() : tensor([2.8758, 4.9588], requires_grad=True), required_grad : True\n",
      "epoch 259 loss is 1.0498158931732178\n",
      "epoch 259 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 259 : params.grad right after loss.backward(): tensor([-0.0975, -0.0651])\n",
      "epoch 259 after optimizer.step() : tensor([2.8768, 4.9594], requires_grad=True), required_grad : True\n",
      "epoch 260 loss is 1.0496795177459717\n",
      "epoch 260 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 260 : params.grad right after loss.backward(): tensor([-0.0962, -0.0639])\n",
      "epoch 260 after optimizer.step() : tensor([2.8777, 4.9601], requires_grad=True), required_grad : True\n",
      "epoch 261 loss is 1.0495471954345703\n",
      "epoch 261 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 261 : params.grad right after loss.backward(): tensor([-0.0949, -0.0627])\n",
      "epoch 261 after optimizer.step() : tensor([2.8787, 4.9607], requires_grad=True), required_grad : True\n",
      "epoch 262 loss is 1.0494186878204346\n",
      "epoch 262 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 262 : params.grad right after loss.backward(): tensor([-0.0937, -0.0616])\n",
      "epoch 262 after optimizer.step() : tensor([2.8796, 4.9613], requires_grad=True), required_grad : True\n",
      "epoch 263 loss is 1.0492939949035645\n",
      "epoch 263 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 263 : params.grad right after loss.backward(): tensor([-0.0924, -0.0605])\n",
      "epoch 263 after optimizer.step() : tensor([2.8805, 4.9619], requires_grad=True), required_grad : True\n",
      "epoch 264 loss is 1.0491729974746704\n",
      "epoch 264 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 264 : params.grad right after loss.backward(): tensor([-0.0912, -0.0594])\n",
      "epoch 264 after optimizer.step() : tensor([2.8814, 4.9625], requires_grad=True), required_grad : True\n",
      "epoch 265 loss is 1.0490554571151733\n",
      "epoch 265 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 265 : params.grad right after loss.backward(): tensor([-0.0900, -0.0583])\n",
      "epoch 265 after optimizer.step() : tensor([2.8823, 4.9631], requires_grad=True), required_grad : True\n",
      "epoch 266 loss is 1.0489412546157837\n",
      "epoch 266 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 266 : params.grad right after loss.backward(): tensor([-0.0888, -0.0572])\n",
      "epoch 266 after optimizer.step() : tensor([2.8832, 4.9637], requires_grad=True), required_grad : True\n",
      "epoch 267 loss is 1.0488303899765015\n",
      "epoch 267 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 267 : params.grad right after loss.backward(): tensor([-0.0876, -0.0562])\n",
      "epoch 267 after optimizer.step() : tensor([2.8841, 4.9642], requires_grad=True), required_grad : True\n",
      "epoch 268 loss is 1.0487228631973267\n",
      "epoch 268 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 268 : params.grad right after loss.backward(): tensor([-0.0865, -0.0552])\n",
      "epoch 268 after optimizer.step() : tensor([2.8850, 4.9648], requires_grad=True), required_grad : True\n",
      "epoch 269 loss is 1.0486183166503906\n",
      "epoch 269 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 269 : params.grad right after loss.backward(): tensor([-0.0853, -0.0541])\n",
      "epoch 269 after optimizer.step() : tensor([2.8858, 4.9653], requires_grad=True), required_grad : True\n",
      "epoch 270 loss is 1.048516869544983\n",
      "epoch 270 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 270 : params.grad right after loss.backward(): tensor([-0.0842, -0.0532])\n",
      "epoch 270 after optimizer.step() : tensor([2.8867, 4.9659], requires_grad=True), required_grad : True\n",
      "epoch 271 loss is 1.048418641090393\n",
      "epoch 271 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 271 : params.grad right after loss.backward(): tensor([-0.0831, -0.0522])\n",
      "epoch 271 after optimizer.step() : tensor([2.8875, 4.9664], requires_grad=True), required_grad : True\n",
      "epoch 272 loss is 1.0483227968215942\n",
      "epoch 272 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 272 : params.grad right after loss.backward(): tensor([-0.0820, -0.0512])\n",
      "epoch 272 after optimizer.step() : tensor([2.8883, 4.9669], requires_grad=True), required_grad : True\n",
      "epoch 273 loss is 1.0482299327850342\n",
      "epoch 273 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 273 : params.grad right after loss.backward(): tensor([-0.0809, -0.0503])\n",
      "epoch 273 after optimizer.step() : tensor([2.8891, 4.9674], requires_grad=True), required_grad : True\n",
      "epoch 274 loss is 1.0481399297714233\n",
      "epoch 274 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 274 : params.grad right after loss.backward(): tensor([-0.0799, -0.0494])\n",
      "epoch 274 after optimizer.step() : tensor([2.8899, 4.9679], requires_grad=True), required_grad : True\n",
      "epoch 275 loss is 1.0480525493621826\n",
      "epoch 275 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 275 : params.grad right after loss.backward(): tensor([-0.0788, -0.0485])\n",
      "epoch 275 after optimizer.step() : tensor([2.8907, 4.9684], requires_grad=True), required_grad : True\n",
      "epoch 276 loss is 1.0479674339294434\n",
      "epoch 276 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 276 : params.grad right after loss.backward(): tensor([-0.0778, -0.0476])\n",
      "epoch 276 after optimizer.step() : tensor([2.8915, 4.9689], requires_grad=True), required_grad : True\n",
      "epoch 277 loss is 1.0478848218917847\n",
      "epoch 277 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 277 : params.grad right after loss.backward(): tensor([-0.0767, -0.0468])\n",
      "epoch 277 after optimizer.step() : tensor([2.8923, 4.9693], requires_grad=True), required_grad : True\n",
      "epoch 278 loss is 1.0478047132492065\n",
      "epoch 278 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 278 : params.grad right after loss.backward(): tensor([-0.0757, -0.0459])\n",
      "epoch 278 after optimizer.step() : tensor([2.8930, 4.9698], requires_grad=True), required_grad : True\n",
      "epoch 279 loss is 1.0477267503738403\n",
      "epoch 279 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 279 : params.grad right after loss.backward(): tensor([-0.0747, -0.0451])\n",
      "epoch 279 after optimizer.step() : tensor([2.8938, 4.9702], requires_grad=True), required_grad : True\n",
      "epoch 280 loss is 1.0476514101028442\n",
      "epoch 280 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 280 : params.grad right after loss.backward(): tensor([-0.0737, -0.0443])\n",
      "epoch 280 after optimizer.step() : tensor([2.8945, 4.9707], requires_grad=True), required_grad : True\n",
      "epoch 281 loss is 1.047577977180481\n",
      "epoch 281 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 281 : params.grad right after loss.backward(): tensor([-0.0727, -0.0435])\n",
      "epoch 281 after optimizer.step() : tensor([2.8952, 4.9711], requires_grad=True), required_grad : True\n",
      "epoch 282 loss is 1.0475066900253296\n",
      "epoch 282 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 282 : params.grad right after loss.backward(): tensor([-0.0718, -0.0427])\n",
      "epoch 282 after optimizer.step() : tensor([2.8959, 4.9715], requires_grad=True), required_grad : True\n",
      "epoch 283 loss is 1.0474375486373901\n",
      "epoch 283 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 283 : params.grad right after loss.backward(): tensor([-0.0708, -0.0419])\n",
      "epoch 283 after optimizer.step() : tensor([2.8967, 4.9720], requires_grad=True), required_grad : True\n",
      "epoch 284 loss is 1.047370195388794\n",
      "epoch 284 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 284 : params.grad right after loss.backward(): tensor([-0.0699, -0.0411])\n",
      "epoch 284 after optimizer.step() : tensor([2.8974, 4.9724], requires_grad=True), required_grad : True\n",
      "epoch 285 loss is 1.0473049879074097\n",
      "epoch 285 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 285 : params.grad right after loss.backward(): tensor([-0.0690, -0.0404])\n",
      "epoch 285 after optimizer.step() : tensor([2.8980, 4.9728], requires_grad=True), required_grad : True\n",
      "epoch 286 loss is 1.0472416877746582\n",
      "epoch 286 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 286 : params.grad right after loss.backward(): tensor([-0.0680, -0.0397])\n",
      "epoch 286 after optimizer.step() : tensor([2.8987, 4.9732], requires_grad=True), required_grad : True\n",
      "epoch 287 loss is 1.0471798181533813\n",
      "epoch 287 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 287 : params.grad right after loss.backward(): tensor([-0.0671, -0.0390])\n",
      "epoch 287 after optimizer.step() : tensor([2.8994, 4.9736], requires_grad=True), required_grad : True\n",
      "epoch 288 loss is 1.047120213508606\n",
      "epoch 288 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 288 : params.grad right after loss.backward(): tensor([-0.0662, -0.0382])\n",
      "epoch 288 after optimizer.step() : tensor([2.9001, 4.9739], requires_grad=True), required_grad : True\n",
      "epoch 289 loss is 1.0470620393753052\n",
      "epoch 289 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 289 : params.grad right after loss.backward(): tensor([-0.0654, -0.0376])\n",
      "epoch 289 after optimizer.step() : tensor([2.9007, 4.9743], requires_grad=True), required_grad : True\n",
      "epoch 290 loss is 1.0470056533813477\n",
      "epoch 290 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 290 : params.grad right after loss.backward(): tensor([-0.0645, -0.0369])\n",
      "epoch 290 after optimizer.step() : tensor([2.9014, 4.9747], requires_grad=True), required_grad : True\n",
      "epoch 291 loss is 1.0469509363174438\n",
      "epoch 291 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 291 : params.grad right after loss.backward(): tensor([-0.0636, -0.0362])\n",
      "epoch 291 after optimizer.step() : tensor([2.9020, 4.9750], requires_grad=True), required_grad : True\n",
      "epoch 292 loss is 1.046897530555725\n",
      "epoch 292 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 292 : params.grad right after loss.backward(): tensor([-0.0628, -0.0356])\n",
      "epoch 292 after optimizer.step() : tensor([2.9026, 4.9754], requires_grad=True), required_grad : True\n",
      "epoch 293 loss is 1.0468459129333496\n",
      "epoch 293 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 293 : params.grad right after loss.backward(): tensor([-0.0620, -0.0349])\n",
      "epoch 293 after optimizer.step() : tensor([2.9032, 4.9758], requires_grad=True), required_grad : True\n",
      "epoch 294 loss is 1.0467957258224487\n",
      "epoch 294 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 294 : params.grad right after loss.backward(): tensor([-0.0611, -0.0343])\n",
      "epoch 294 after optimizer.step() : tensor([2.9038, 4.9761], requires_grad=True), required_grad : True\n",
      "epoch 295 loss is 1.046746850013733\n",
      "epoch 295 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 295 : params.grad right after loss.backward(): tensor([-0.0603, -0.0337])\n",
      "epoch 295 after optimizer.step() : tensor([2.9045, 4.9764], requires_grad=True), required_grad : True\n",
      "epoch 296 loss is 1.0466994047164917\n",
      "epoch 296 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 296 : params.grad right after loss.backward(): tensor([-0.0595, -0.0331])\n",
      "epoch 296 after optimizer.step() : tensor([2.9050, 4.9768], requires_grad=True), required_grad : True\n",
      "epoch 297 loss is 1.046653389930725\n",
      "epoch 297 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 297 : params.grad right after loss.backward(): tensor([-0.0587, -0.0325])\n",
      "epoch 297 after optimizer.step() : tensor([2.9056, 4.9771], requires_grad=True), required_grad : True\n",
      "epoch 298 loss is 1.046608805656433\n",
      "epoch 298 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 298 : params.grad right after loss.backward(): tensor([-0.0580, -0.0319])\n",
      "epoch 298 after optimizer.step() : tensor([2.9062, 4.9774], requires_grad=True), required_grad : True\n",
      "epoch 299 loss is 1.046565294265747\n",
      "epoch 299 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 299 : params.grad right after loss.backward(): tensor([-0.0572, -0.0313])\n",
      "epoch 299 after optimizer.step() : tensor([2.9068, 4.9777], requires_grad=True), required_grad : True\n",
      "epoch 300 loss is 1.0465229749679565\n",
      "epoch 300 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 300 : params.grad right after loss.backward(): tensor([-0.0564, -0.0308])\n",
      "epoch 300 after optimizer.step() : tensor([2.9074, 4.9780], requires_grad=True), required_grad : True\n",
      "epoch 301 loss is 1.046481966972351\n",
      "epoch 301 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 301 : params.grad right after loss.backward(): tensor([-0.0557, -0.0302])\n",
      "epoch 301 after optimizer.step() : tensor([2.9079, 4.9783], requires_grad=True), required_grad : True\n",
      "epoch 302 loss is 1.0464422702789307\n",
      "epoch 302 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 302 : params.grad right after loss.backward(): tensor([-0.0549, -0.0297])\n",
      "epoch 302 after optimizer.step() : tensor([2.9085, 4.9786], requires_grad=True), required_grad : True\n",
      "epoch 303 loss is 1.046403408050537\n",
      "epoch 303 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 303 : params.grad right after loss.backward(): tensor([-0.0542, -0.0291])\n",
      "epoch 303 after optimizer.step() : tensor([2.9090, 4.9789], requires_grad=True), required_grad : True\n",
      "epoch 304 loss is 1.0463658571243286\n",
      "epoch 304 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 304 : params.grad right after loss.backward(): tensor([-0.0535, -0.0286])\n",
      "epoch 304 after optimizer.step() : tensor([2.9095, 4.9792], requires_grad=True), required_grad : True\n",
      "epoch 305 loss is 1.046329379081726\n",
      "epoch 305 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 305 : params.grad right after loss.backward(): tensor([-0.0528, -0.0281])\n",
      "epoch 305 after optimizer.step() : tensor([2.9101, 4.9795], requires_grad=True), required_grad : True\n",
      "epoch 306 loss is 1.0462939739227295\n",
      "epoch 306 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 306 : params.grad right after loss.backward(): tensor([-0.0521, -0.0276])\n",
      "epoch 306 after optimizer.step() : tensor([2.9106, 4.9798], requires_grad=True), required_grad : True\n",
      "epoch 307 loss is 1.0462592840194702\n",
      "epoch 307 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 307 : params.grad right after loss.backward(): tensor([-0.0514, -0.0271])\n",
      "epoch 307 after optimizer.step() : tensor([2.9111, 4.9800], requires_grad=True), required_grad : True\n",
      "epoch 308 loss is 1.0462260246276855\n",
      "epoch 308 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 308 : params.grad right after loss.backward(): tensor([-0.0507, -0.0266])\n",
      "epoch 308 after optimizer.step() : tensor([2.9116, 4.9803], requires_grad=True), required_grad : True\n",
      "epoch 309 loss is 1.046193242073059\n",
      "epoch 309 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 309 : params.grad right after loss.backward(): tensor([-0.0500, -0.0262])\n",
      "epoch 309 after optimizer.step() : tensor([2.9121, 4.9806], requires_grad=True), required_grad : True\n",
      "epoch 310 loss is 1.0461616516113281\n",
      "epoch 310 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 310 : params.grad right after loss.backward(): tensor([-0.0493, -0.0257])\n",
      "epoch 310 after optimizer.step() : tensor([2.9126, 4.9808], requires_grad=True), required_grad : True\n",
      "epoch 311 loss is 1.0461310148239136\n",
      "epoch 311 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 311 : params.grad right after loss.backward(): tensor([-0.0487, -0.0252])\n",
      "epoch 311 after optimizer.step() : tensor([2.9131, 4.9811], requires_grad=True), required_grad : True\n",
      "epoch 312 loss is 1.0461010932922363\n",
      "epoch 312 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 312 : params.grad right after loss.backward(): tensor([-0.0480, -0.0248])\n",
      "epoch 312 after optimizer.step() : tensor([2.9136, 4.9813], requires_grad=True), required_grad : True\n",
      "epoch 313 loss is 1.046072244644165\n",
      "epoch 313 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 313 : params.grad right after loss.backward(): tensor([-0.0474, -0.0243])\n",
      "epoch 313 after optimizer.step() : tensor([2.9140, 4.9816], requires_grad=True), required_grad : True\n",
      "epoch 314 loss is 1.046043872833252\n",
      "epoch 314 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 314 : params.grad right after loss.backward(): tensor([-0.0468, -0.0239])\n",
      "epoch 314 after optimizer.step() : tensor([2.9145, 4.9818], requires_grad=True), required_grad : True\n",
      "epoch 315 loss is 1.0460164546966553\n",
      "epoch 315 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 315 : params.grad right after loss.backward(): tensor([-0.0461, -0.0235])\n",
      "epoch 315 after optimizer.step() : tensor([2.9150, 4.9820], requires_grad=True), required_grad : True\n",
      "epoch 316 loss is 1.0459898710250854\n",
      "epoch 316 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 316 : params.grad right after loss.backward(): tensor([-0.0455, -0.0231])\n",
      "epoch 316 after optimizer.step() : tensor([2.9154, 4.9823], requires_grad=True), required_grad : True\n",
      "epoch 317 loss is 1.045964241027832\n",
      "epoch 317 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 317 : params.grad right after loss.backward(): tensor([-0.0449, -0.0227])\n",
      "epoch 317 after optimizer.step() : tensor([2.9159, 4.9825], requires_grad=True), required_grad : True\n",
      "epoch 318 loss is 1.0459389686584473\n",
      "epoch 318 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 318 : params.grad right after loss.backward(): tensor([-0.0443, -0.0223])\n",
      "epoch 318 after optimizer.step() : tensor([2.9163, 4.9827], requires_grad=True), required_grad : True\n",
      "epoch 319 loss is 1.0459145307540894\n",
      "epoch 319 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 319 : params.grad right after loss.backward(): tensor([-0.0437, -0.0219])\n",
      "epoch 319 after optimizer.step() : tensor([2.9167, 4.9829], requires_grad=True), required_grad : True\n",
      "epoch 320 loss is 1.0458909273147583\n",
      "epoch 320 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 320 : params.grad right after loss.backward(): tensor([-0.0431, -0.0215])\n",
      "epoch 320 after optimizer.step() : tensor([2.9172, 4.9831], requires_grad=True), required_grad : True\n",
      "epoch 321 loss is 1.0458678007125854\n",
      "epoch 321 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 321 : params.grad right after loss.backward(): tensor([-0.0426, -0.0211])\n",
      "epoch 321 after optimizer.step() : tensor([2.9176, 4.9834], requires_grad=True), required_grad : True\n",
      "epoch 322 loss is 1.04584538936615\n",
      "epoch 322 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 322 : params.grad right after loss.backward(): tensor([-0.0420, -0.0207])\n",
      "epoch 322 after optimizer.step() : tensor([2.9180, 4.9836], requires_grad=True), required_grad : True\n",
      "epoch 323 loss is 1.045823574066162\n",
      "epoch 323 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 323 : params.grad right after loss.backward(): tensor([-0.0414, -0.0204])\n",
      "epoch 323 after optimizer.step() : tensor([2.9184, 4.9838], requires_grad=True), required_grad : True\n",
      "epoch 324 loss is 1.045802354812622\n",
      "epoch 324 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 324 : params.grad right after loss.backward(): tensor([-0.0409, -0.0200])\n",
      "epoch 324 after optimizer.step() : tensor([2.9188, 4.9840], requires_grad=True), required_grad : True\n",
      "epoch 325 loss is 1.0457819700241089\n",
      "epoch 325 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 325 : params.grad right after loss.backward(): tensor([-0.0403, -0.0196])\n",
      "epoch 325 after optimizer.step() : tensor([2.9193, 4.9842], requires_grad=True), required_grad : True\n",
      "epoch 326 loss is 1.0457618236541748\n",
      "epoch 326 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 326 : params.grad right after loss.backward(): tensor([-0.0398, -0.0193])\n",
      "epoch 326 after optimizer.step() : tensor([2.9197, 4.9844], requires_grad=True), required_grad : True\n",
      "epoch 327 loss is 1.0457425117492676\n",
      "epoch 327 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 327 : params.grad right after loss.backward(): tensor([-0.0393, -0.0190])\n",
      "epoch 327 after optimizer.step() : tensor([2.9200, 4.9845], requires_grad=True), required_grad : True\n",
      "epoch 328 loss is 1.045723557472229\n",
      "epoch 328 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 328 : params.grad right after loss.backward(): tensor([-0.0387, -0.0186])\n",
      "epoch 328 after optimizer.step() : tensor([2.9204, 4.9847], requires_grad=True), required_grad : True\n",
      "epoch 329 loss is 1.0457053184509277\n",
      "epoch 329 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 329 : params.grad right after loss.backward(): tensor([-0.0382, -0.0183])\n",
      "epoch 329 after optimizer.step() : tensor([2.9208, 4.9849], requires_grad=True), required_grad : True\n",
      "epoch 330 loss is 1.0456874370574951\n",
      "epoch 330 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 330 : params.grad right after loss.backward(): tensor([-0.0377, -0.0180])\n",
      "epoch 330 after optimizer.step() : tensor([2.9212, 4.9851], requires_grad=True), required_grad : True\n",
      "epoch 331 loss is 1.0456702709197998\n",
      "epoch 331 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 331 : params.grad right after loss.backward(): tensor([-0.0372, -0.0177])\n",
      "epoch 331 after optimizer.step() : tensor([2.9216, 4.9853], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 332 loss is 1.0456533432006836\n",
      "epoch 332 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 332 : params.grad right after loss.backward(): tensor([-0.0367, -0.0173])\n",
      "epoch 332 after optimizer.step() : tensor([2.9219, 4.9854], requires_grad=True), required_grad : True\n",
      "epoch 333 loss is 1.0456370115280151\n",
      "epoch 333 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 333 : params.grad right after loss.backward(): tensor([-0.0362, -0.0170])\n",
      "epoch 333 after optimizer.step() : tensor([2.9223, 4.9856], requires_grad=True), required_grad : True\n",
      "epoch 334 loss is 1.0456211566925049\n",
      "epoch 334 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 334 : params.grad right after loss.backward(): tensor([-0.0357, -0.0167])\n",
      "epoch 334 after optimizer.step() : tensor([2.9226, 4.9858], requires_grad=True), required_grad : True\n",
      "epoch 335 loss is 1.0456056594848633\n",
      "epoch 335 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 335 : params.grad right after loss.backward(): tensor([-0.0352, -0.0164])\n",
      "epoch 335 after optimizer.step() : tensor([2.9230, 4.9860], requires_grad=True), required_grad : True\n",
      "epoch 336 loss is 1.0455906391143799\n",
      "epoch 336 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 336 : params.grad right after loss.backward(): tensor([-0.0348, -0.0162])\n",
      "epoch 336 after optimizer.step() : tensor([2.9233, 4.9861], requires_grad=True), required_grad : True\n",
      "epoch 337 loss is 1.0455759763717651\n",
      "epoch 337 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 337 : params.grad right after loss.backward(): tensor([-0.0343, -0.0159])\n",
      "epoch 337 after optimizer.step() : tensor([2.9237, 4.9863], requires_grad=True), required_grad : True\n",
      "epoch 338 loss is 1.0455617904663086\n",
      "epoch 338 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 338 : params.grad right after loss.backward(): tensor([-0.0338, -0.0156])\n",
      "epoch 338 after optimizer.step() : tensor([2.9240, 4.9864], requires_grad=True), required_grad : True\n",
      "epoch 339 loss is 1.0455480813980103\n",
      "epoch 339 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 339 : params.grad right after loss.backward(): tensor([-0.0334, -0.0153])\n",
      "epoch 339 after optimizer.step() : tensor([2.9244, 4.9866], requires_grad=True), required_grad : True\n",
      "epoch 340 loss is 1.0455347299575806\n",
      "epoch 340 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 340 : params.grad right after loss.backward(): tensor([-0.0329, -0.0150])\n",
      "epoch 340 after optimizer.step() : tensor([2.9247, 4.9867], requires_grad=True), required_grad : True\n",
      "epoch 341 loss is 1.04552161693573\n",
      "epoch 341 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 341 : params.grad right after loss.backward(): tensor([-0.0325, -0.0148])\n",
      "epoch 341 after optimizer.step() : tensor([2.9250, 4.9869], requires_grad=True), required_grad : True\n",
      "epoch 342 loss is 1.0455089807510376\n",
      "epoch 342 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 342 : params.grad right after loss.backward(): tensor([-0.0321, -0.0145])\n",
      "epoch 342 after optimizer.step() : tensor([2.9253, 4.9870], requires_grad=True), required_grad : True\n",
      "epoch 343 loss is 1.0454967021942139\n",
      "epoch 343 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 343 : params.grad right after loss.backward(): tensor([-0.0316, -0.0143])\n",
      "epoch 343 after optimizer.step() : tensor([2.9257, 4.9872], requires_grad=True), required_grad : True\n",
      "epoch 344 loss is 1.0454847812652588\n",
      "epoch 344 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 344 : params.grad right after loss.backward(): tensor([-0.0312, -0.0140])\n",
      "epoch 344 after optimizer.step() : tensor([2.9260, 4.9873], requires_grad=True), required_grad : True\n",
      "epoch 345 loss is 1.0454729795455933\n",
      "epoch 345 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 345 : params.grad right after loss.backward(): tensor([-0.0308, -0.0138])\n",
      "epoch 345 after optimizer.step() : tensor([2.9263, 4.9874], requires_grad=True), required_grad : True\n",
      "epoch 346 loss is 1.0454617738723755\n",
      "epoch 346 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 346 : params.grad right after loss.backward(): tensor([-0.0304, -0.0135])\n",
      "epoch 346 after optimizer.step() : tensor([2.9266, 4.9876], requires_grad=True), required_grad : True\n",
      "epoch 347 loss is 1.0454509258270264\n",
      "epoch 347 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 347 : params.grad right after loss.backward(): tensor([-0.0300, -0.0133])\n",
      "epoch 347 after optimizer.step() : tensor([2.9269, 4.9877], requires_grad=True), required_grad : True\n",
      "epoch 348 loss is 1.0454401969909668\n",
      "epoch 348 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 348 : params.grad right after loss.backward(): tensor([-0.0296, -0.0131])\n",
      "epoch 348 after optimizer.step() : tensor([2.9272, 4.9878], requires_grad=True), required_grad : True\n",
      "epoch 349 loss is 1.0454298257827759\n",
      "epoch 349 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 349 : params.grad right after loss.backward(): tensor([-0.0292, -0.0128])\n",
      "epoch 349 after optimizer.step() : tensor([2.9275, 4.9880], requires_grad=True), required_grad : True\n",
      "epoch 350 loss is 1.0454195737838745\n",
      "epoch 350 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 350 : params.grad right after loss.backward(): tensor([-0.0288, -0.0126])\n",
      "epoch 350 after optimizer.step() : tensor([2.9278, 4.9881], requires_grad=True), required_grad : True\n",
      "epoch 351 loss is 1.0454100370407104\n",
      "epoch 351 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 351 : params.grad right after loss.backward(): tensor([-0.0284, -0.0124])\n",
      "epoch 351 after optimizer.step() : tensor([2.9280, 4.9882], requires_grad=True), required_grad : True\n",
      "epoch 352 loss is 1.0454003810882568\n",
      "epoch 352 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 352 : params.grad right after loss.backward(): tensor([-0.0280, -0.0122])\n",
      "epoch 352 after optimizer.step() : tensor([2.9283, 4.9883], requires_grad=True), required_grad : True\n",
      "epoch 353 loss is 1.0453910827636719\n",
      "epoch 353 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 353 : params.grad right after loss.backward(): tensor([-0.0276, -0.0120])\n",
      "epoch 353 after optimizer.step() : tensor([2.9286, 4.9885], requires_grad=True), required_grad : True\n",
      "epoch 354 loss is 1.045382022857666\n",
      "epoch 354 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 354 : params.grad right after loss.backward(): tensor([-0.0273, -0.0118])\n",
      "epoch 354 after optimizer.step() : tensor([2.9289, 4.9886], requires_grad=True), required_grad : True\n",
      "epoch 355 loss is 1.0453733205795288\n",
      "epoch 355 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 355 : params.grad right after loss.backward(): tensor([-0.0269, -0.0116])\n",
      "epoch 355 after optimizer.step() : tensor([2.9291, 4.9887], requires_grad=True), required_grad : True\n",
      "epoch 356 loss is 1.0453648567199707\n",
      "epoch 356 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 356 : params.grad right after loss.backward(): tensor([-0.0265, -0.0114])\n",
      "epoch 356 after optimizer.step() : tensor([2.9294, 4.9888], requires_grad=True), required_grad : True\n",
      "epoch 357 loss is 1.0453566312789917\n",
      "epoch 357 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 357 : params.grad right after loss.backward(): tensor([-0.0262, -0.0112])\n",
      "epoch 357 after optimizer.step() : tensor([2.9297, 4.9889], requires_grad=True), required_grad : True\n",
      "epoch 358 loss is 1.0453486442565918\n",
      "epoch 358 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 358 : params.grad right after loss.backward(): tensor([-0.0258, -0.0110])\n",
      "epoch 358 after optimizer.step() : tensor([2.9299, 4.9890], requires_grad=True), required_grad : True\n",
      "epoch 359 loss is 1.0453407764434814\n",
      "epoch 359 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 359 : params.grad right after loss.backward(): tensor([-0.0255, -0.0108])\n",
      "epoch 359 after optimizer.step() : tensor([2.9302, 4.9891], requires_grad=True), required_grad : True\n",
      "epoch 360 loss is 1.0453331470489502\n",
      "epoch 360 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 360 : params.grad right after loss.backward(): tensor([-0.0251, -0.0106])\n",
      "epoch 360 after optimizer.step() : tensor([2.9304, 4.9892], requires_grad=True), required_grad : True\n",
      "epoch 361 loss is 1.0453256368637085\n",
      "epoch 361 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 361 : params.grad right after loss.backward(): tensor([-0.0248, -0.0104])\n",
      "epoch 361 after optimizer.step() : tensor([2.9307, 4.9893], requires_grad=True), required_grad : True\n",
      "epoch 362 loss is 1.0453184843063354\n",
      "epoch 362 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 362 : params.grad right after loss.backward(): tensor([-0.0245, -0.0102])\n",
      "epoch 362 after optimizer.step() : tensor([2.9309, 4.9895], requires_grad=True), required_grad : True\n",
      "epoch 363 loss is 1.0453115701675415\n",
      "epoch 363 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 363 : params.grad right after loss.backward(): tensor([-0.0241, -0.0101])\n",
      "epoch 363 after optimizer.step() : tensor([2.9312, 4.9896], requires_grad=True), required_grad : True\n",
      "epoch 364 loss is 1.045304775238037\n",
      "epoch 364 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 364 : params.grad right after loss.backward(): tensor([-0.0238, -0.0099])\n",
      "epoch 364 after optimizer.step() : tensor([2.9314, 4.9897], requires_grad=True), required_grad : True\n",
      "epoch 365 loss is 1.0452980995178223\n",
      "epoch 365 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 365 : params.grad right after loss.backward(): tensor([-0.0235, -0.0097])\n",
      "epoch 365 after optimizer.step() : tensor([2.9316, 4.9897], requires_grad=True), required_grad : True\n",
      "epoch 366 loss is 1.0452916622161865\n",
      "epoch 366 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 366 : params.grad right after loss.backward(): tensor([-0.0232, -0.0095])\n",
      "epoch 366 after optimizer.step() : tensor([2.9319, 4.9898], requires_grad=True), required_grad : True\n",
      "epoch 367 loss is 1.0452854633331299\n",
      "epoch 367 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 367 : params.grad right after loss.backward(): tensor([-0.0229, -0.0094])\n",
      "epoch 367 after optimizer.step() : tensor([2.9321, 4.9899], requires_grad=True), required_grad : True\n",
      "epoch 368 loss is 1.0452795028686523\n",
      "epoch 368 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 368 : params.grad right after loss.backward(): tensor([-0.0226, -0.0092])\n",
      "epoch 368 after optimizer.step() : tensor([2.9323, 4.9900], requires_grad=True), required_grad : True\n",
      "epoch 369 loss is 1.0452735424041748\n",
      "epoch 369 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 369 : params.grad right after loss.backward(): tensor([-0.0223, -0.0091])\n",
      "epoch 369 after optimizer.step() : tensor([2.9325, 4.9901], requires_grad=True), required_grad : True\n",
      "epoch 370 loss is 1.0452677011489868\n",
      "epoch 370 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 370 : params.grad right after loss.backward(): tensor([-0.0220, -0.0089])\n",
      "epoch 370 after optimizer.step() : tensor([2.9328, 4.9902], requires_grad=True), required_grad : True\n",
      "epoch 371 loss is 1.045262336730957\n",
      "epoch 371 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 371 : params.grad right after loss.backward(): tensor([-0.0217, -0.0087])\n",
      "epoch 371 after optimizer.step() : tensor([2.9330, 4.9903], requires_grad=True), required_grad : True\n",
      "epoch 372 loss is 1.0452568531036377\n",
      "epoch 372 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 372 : params.grad right after loss.backward(): tensor([-0.0214, -0.0086])\n",
      "epoch 372 after optimizer.step() : tensor([2.9332, 4.9904], requires_grad=True), required_grad : True\n",
      "epoch 373 loss is 1.0452516078948975\n",
      "epoch 373 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 373 : params.grad right after loss.backward(): tensor([-0.0211, -0.0084])\n",
      "epoch 373 after optimizer.step() : tensor([2.9334, 4.9905], requires_grad=True), required_grad : True\n",
      "epoch 374 loss is 1.0452464818954468\n",
      "epoch 374 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 374 : params.grad right after loss.backward(): tensor([-0.0208, -0.0083])\n",
      "epoch 374 after optimizer.step() : tensor([2.9336, 4.9906], requires_grad=True), required_grad : True\n",
      "epoch 375 loss is 1.0452414751052856\n",
      "epoch 375 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 375 : params.grad right after loss.backward(): tensor([-0.0205, -0.0082])\n",
      "epoch 375 after optimizer.step() : tensor([2.9338, 4.9906], requires_grad=True), required_grad : True\n",
      "epoch 376 loss is 1.0452367067337036\n",
      "epoch 376 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 376 : params.grad right after loss.backward(): tensor([-0.0202, -0.0080])\n",
      "epoch 376 after optimizer.step() : tensor([2.9340, 4.9907], requires_grad=True), required_grad : True\n",
      "epoch 377 loss is 1.045231819152832\n",
      "epoch 377 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 377 : params.grad right after loss.backward(): tensor([-0.0200, -0.0079])\n",
      "epoch 377 after optimizer.step() : tensor([2.9342, 4.9908], requires_grad=True), required_grad : True\n",
      "epoch 378 loss is 1.045227289199829\n",
      "epoch 378 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 378 : params.grad right after loss.backward(): tensor([-0.0197, -0.0077])\n",
      "epoch 378 after optimizer.step() : tensor([2.9344, 4.9909], requires_grad=True), required_grad : True\n",
      "epoch 379 loss is 1.0452227592468262\n",
      "epoch 379 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 379 : params.grad right after loss.backward(): tensor([-0.0194, -0.0076])\n",
      "epoch 379 after optimizer.step() : tensor([2.9346, 4.9909], requires_grad=True), required_grad : True\n",
      "epoch 380 loss is 1.0452184677124023\n",
      "epoch 380 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 380 : params.grad right after loss.backward(): tensor([-0.0192, -0.0075])\n",
      "epoch 380 after optimizer.step() : tensor([2.9348, 4.9910], requires_grad=True), required_grad : True\n",
      "epoch 381 loss is 1.0452144145965576\n",
      "epoch 381 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 381 : params.grad right after loss.backward(): tensor([-0.0189, -0.0074])\n",
      "epoch 381 after optimizer.step() : tensor([2.9350, 4.9911], requires_grad=True), required_grad : True\n",
      "epoch 382 loss is 1.0452102422714233\n",
      "epoch 382 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 382 : params.grad right after loss.backward(): tensor([-0.0187, -0.0072])\n",
      "epoch 382 after optimizer.step() : tensor([2.9352, 4.9912], requires_grad=True), required_grad : True\n",
      "epoch 383 loss is 1.0452063083648682\n",
      "epoch 383 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 383 : params.grad right after loss.backward(): tensor([-0.0184, -0.0071])\n",
      "epoch 383 after optimizer.step() : tensor([2.9354, 4.9912], requires_grad=True), required_grad : True\n",
      "epoch 384 loss is 1.0452024936676025\n",
      "epoch 384 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 384 : params.grad right after loss.backward(): tensor([-0.0182, -0.0070])\n",
      "epoch 384 after optimizer.step() : tensor([2.9355, 4.9913], requires_grad=True), required_grad : True\n",
      "epoch 385 loss is 1.0451985597610474\n",
      "epoch 385 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 385 : params.grad right after loss.backward(): tensor([-0.0179, -0.0069])\n",
      "epoch 385 after optimizer.step() : tensor([2.9357, 4.9914], requires_grad=True), required_grad : True\n",
      "epoch 386 loss is 1.0451951026916504\n",
      "epoch 386 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 386 : params.grad right after loss.backward(): tensor([-0.0177, -0.0068])\n",
      "epoch 386 after optimizer.step() : tensor([2.9359, 4.9914], requires_grad=True), required_grad : True\n",
      "epoch 387 loss is 1.0451914072036743\n",
      "epoch 387 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 387 : params.grad right after loss.backward(): tensor([-0.0174, -0.0066])\n",
      "epoch 387 after optimizer.step() : tensor([2.9361, 4.9915], requires_grad=True), required_grad : True\n",
      "epoch 388 loss is 1.0451879501342773\n",
      "epoch 388 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 388 : params.grad right after loss.backward(): tensor([-0.0172, -0.0065])\n",
      "epoch 388 after optimizer.step() : tensor([2.9362, 4.9916], requires_grad=True), required_grad : True\n",
      "epoch 389 loss is 1.0451847314834595\n",
      "epoch 389 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 389 : params.grad right after loss.backward(): tensor([-0.0170, -0.0064])\n",
      "epoch 389 after optimizer.step() : tensor([2.9364, 4.9916], requires_grad=True), required_grad : True\n",
      "epoch 390 loss is 1.045181393623352\n",
      "epoch 390 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 390 : params.grad right after loss.backward(): tensor([-0.0167, -0.0063])\n",
      "epoch 390 after optimizer.step() : tensor([2.9366, 4.9917], requires_grad=True), required_grad : True\n",
      "epoch 391 loss is 1.0451781749725342\n",
      "epoch 391 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 391 : params.grad right after loss.backward(): tensor([-0.0165, -0.0062])\n",
      "epoch 391 after optimizer.step() : tensor([2.9367, 4.9918], requires_grad=True), required_grad : True\n",
      "epoch 392 loss is 1.0451751947402954\n",
      "epoch 392 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 392 : params.grad right after loss.backward(): tensor([-0.0163, -0.0061])\n",
      "epoch 392 after optimizer.step() : tensor([2.9369, 4.9918], requires_grad=True), required_grad : True\n",
      "epoch 393 loss is 1.045172095298767\n",
      "epoch 393 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 393 : params.grad right after loss.backward(): tensor([-0.0161, -0.0060])\n",
      "epoch 393 after optimizer.step() : tensor([2.9371, 4.9919], requires_grad=True), required_grad : True\n",
      "epoch 394 loss is 1.0451693534851074\n",
      "epoch 394 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 394 : params.grad right after loss.backward(): tensor([-0.0158, -0.0059])\n",
      "epoch 394 after optimizer.step() : tensor([2.9372, 4.9919], requires_grad=True), required_grad : True\n",
      "epoch 395 loss is 1.0451664924621582\n",
      "epoch 395 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 395 : params.grad right after loss.backward(): tensor([-0.0156, -0.0058])\n",
      "epoch 395 after optimizer.step() : tensor([2.9374, 4.9920], requires_grad=True), required_grad : True\n",
      "epoch 396 loss is 1.0451637506484985\n",
      "epoch 396 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 396 : params.grad right after loss.backward(): tensor([-0.0154, -0.0057])\n",
      "epoch 396 after optimizer.step() : tensor([2.9375, 4.9921], requires_grad=True), required_grad : True\n",
      "epoch 397 loss is 1.0451607704162598\n",
      "epoch 397 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 397 : params.grad right after loss.backward(): tensor([-0.0152, -0.0056])\n",
      "epoch 397 after optimizer.step() : tensor([2.9377, 4.9921], requires_grad=True), required_grad : True\n",
      "epoch 398 loss is 1.0451585054397583\n",
      "epoch 398 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 398 : params.grad right after loss.backward(): tensor([-0.0150, -0.0055])\n",
      "epoch 398 after optimizer.step() : tensor([2.9378, 4.9922], requires_grad=True), required_grad : True\n",
      "epoch 399 loss is 1.0451557636260986\n",
      "epoch 399 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 399 : params.grad right after loss.backward(): tensor([-0.0148, -0.0054])\n",
      "epoch 399 after optimizer.step() : tensor([2.9380, 4.9922], requires_grad=True), required_grad : True\n",
      "epoch 400 loss is 1.0451533794403076\n",
      "epoch 400 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 400 : params.grad right after loss.backward(): tensor([-0.0146, -0.0053])\n",
      "epoch 400 after optimizer.step() : tensor([2.9381, 4.9923], requires_grad=True), required_grad : True\n",
      "epoch 401 loss is 1.045150876045227\n",
      "epoch 401 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 401 : params.grad right after loss.backward(): tensor([-0.0144, -0.0052])\n",
      "epoch 401 after optimizer.step() : tensor([2.9383, 4.9923], requires_grad=True), required_grad : True\n",
      "epoch 402 loss is 1.0451486110687256\n",
      "epoch 402 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 402 : params.grad right after loss.backward(): tensor([-0.0142, -0.0051])\n",
      "epoch 402 after optimizer.step() : tensor([2.9384, 4.9924], requires_grad=True), required_grad : True\n",
      "epoch 403 loss is 1.0451464653015137\n",
      "epoch 403 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 403 : params.grad right after loss.backward(): tensor([-0.0140, -0.0051])\n",
      "epoch 403 after optimizer.step() : tensor([2.9386, 4.9924], requires_grad=True), required_grad : True\n",
      "epoch 404 loss is 1.0451440811157227\n",
      "epoch 404 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 404 : params.grad right after loss.backward(): tensor([-0.0138, -0.0050])\n",
      "epoch 404 after optimizer.step() : tensor([2.9387, 4.9925], requires_grad=True), required_grad : True\n",
      "epoch 405 loss is 1.0451419353485107\n",
      "epoch 405 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 405 : params.grad right after loss.backward(): tensor([-0.0136, -0.0049])\n",
      "epoch 405 after optimizer.step() : tensor([2.9388, 4.9925], requires_grad=True), required_grad : True\n",
      "epoch 406 loss is 1.0451397895812988\n",
      "epoch 406 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 406 : params.grad right after loss.backward(): tensor([-0.0135, -0.0048])\n",
      "epoch 406 after optimizer.step() : tensor([2.9390, 4.9926], requires_grad=True), required_grad : True\n",
      "epoch 407 loss is 1.045137882232666\n",
      "epoch 407 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 407 : params.grad right after loss.backward(): tensor([-0.0133, -0.0047])\n",
      "epoch 407 after optimizer.step() : tensor([2.9391, 4.9926], requires_grad=True), required_grad : True\n",
      "epoch 408 loss is 1.0451358556747437\n",
      "epoch 408 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 408 : params.grad right after loss.backward(): tensor([-0.0131, -0.0046])\n",
      "epoch 408 after optimizer.step() : tensor([2.9392, 4.9927], requires_grad=True), required_grad : True\n",
      "epoch 409 loss is 1.0451340675354004\n",
      "epoch 409 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 409 : params.grad right after loss.backward(): tensor([-0.0129, -0.0046])\n",
      "epoch 409 after optimizer.step() : tensor([2.9394, 4.9927], requires_grad=True), required_grad : True\n",
      "epoch 410 loss is 1.0451321601867676\n",
      "epoch 410 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 410 : params.grad right after loss.backward(): tensor([-0.0127, -0.0045])\n",
      "epoch 410 after optimizer.step() : tensor([2.9395, 4.9928], requires_grad=True), required_grad : True\n",
      "epoch 411 loss is 1.0451303720474243\n",
      "epoch 411 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 411 : params.grad right after loss.backward(): tensor([-0.0126, -0.0044])\n",
      "epoch 411 after optimizer.step() : tensor([2.9396, 4.9928], requires_grad=True), required_grad : True\n",
      "epoch 412 loss is 1.0451284646987915\n",
      "epoch 412 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 412 : params.grad right after loss.backward(): tensor([-0.0124, -0.0043])\n",
      "epoch 412 after optimizer.step() : tensor([2.9397, 4.9928], requires_grad=True), required_grad : True\n",
      "epoch 413 loss is 1.0451267957687378\n",
      "epoch 413 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 413 : params.grad right after loss.backward(): tensor([-0.0122, -0.0043])\n",
      "epoch 413 after optimizer.step() : tensor([2.9399, 4.9929], requires_grad=True), required_grad : True\n",
      "epoch 414 loss is 1.0451250076293945\n",
      "epoch 414 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 414 : params.grad right after loss.backward(): tensor([-0.0121, -0.0042])\n",
      "epoch 414 after optimizer.step() : tensor([2.9400, 4.9929], requires_grad=True), required_grad : True\n",
      "epoch 415 loss is 1.0451236963272095\n",
      "epoch 415 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 415 : params.grad right after loss.backward(): tensor([-0.0119, -0.0041])\n",
      "epoch 415 after optimizer.step() : tensor([2.9401, 4.9930], requires_grad=True), required_grad : True\n",
      "epoch 416 loss is 1.0451220273971558\n",
      "epoch 416 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 416 : params.grad right after loss.backward(): tensor([-0.0117, -0.0041])\n",
      "epoch 416 after optimizer.step() : tensor([2.9402, 4.9930], requires_grad=True), required_grad : True\n",
      "epoch 417 loss is 1.0451205968856812\n",
      "epoch 417 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 417 : params.grad right after loss.backward(): tensor([-0.0116, -0.0040])\n",
      "epoch 417 after optimizer.step() : tensor([2.9403, 4.9931], requires_grad=True), required_grad : True\n",
      "epoch 418 loss is 1.045119047164917\n",
      "epoch 418 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 418 : params.grad right after loss.backward(): tensor([-0.0114, -0.0039])\n",
      "epoch 418 after optimizer.step() : tensor([2.9404, 4.9931], requires_grad=True), required_grad : True\n",
      "epoch 419 loss is 1.0451176166534424\n",
      "epoch 419 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 419 : params.grad right after loss.backward(): tensor([-0.0113, -0.0039])\n",
      "epoch 419 after optimizer.step() : tensor([2.9406, 4.9931], requires_grad=True), required_grad : True\n",
      "epoch 420 loss is 1.0451160669326782\n",
      "epoch 420 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 420 : params.grad right after loss.backward(): tensor([-0.0111, -0.0038])\n",
      "epoch 420 after optimizer.step() : tensor([2.9407, 4.9932], requires_grad=True), required_grad : True\n",
      "epoch 421 loss is 1.0451146364212036\n",
      "epoch 421 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 421 : params.grad right after loss.backward(): tensor([-0.0110, -0.0037])\n",
      "epoch 421 after optimizer.step() : tensor([2.9408, 4.9932], requires_grad=True), required_grad : True\n",
      "epoch 422 loss is 1.045113444328308\n",
      "epoch 422 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 422 : params.grad right after loss.backward(): tensor([-0.0108, -0.0037])\n",
      "epoch 422 after optimizer.step() : tensor([2.9409, 4.9932], requires_grad=True), required_grad : True\n",
      "epoch 423 loss is 1.0451122522354126\n",
      "epoch 423 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 423 : params.grad right after loss.backward(): tensor([-0.0107, -0.0036])\n",
      "epoch 423 after optimizer.step() : tensor([2.9410, 4.9933], requires_grad=True), required_grad : True\n",
      "epoch 424 loss is 1.0451107025146484\n",
      "epoch 424 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 424 : params.grad right after loss.backward(): tensor([-0.0105, -0.0035])\n",
      "epoch 424 after optimizer.step() : tensor([2.9411, 4.9933], requires_grad=True), required_grad : True\n",
      "epoch 425 loss is 1.0451096296310425\n",
      "epoch 425 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 425 : params.grad right after loss.backward(): tensor([-0.0104, -0.0035])\n",
      "epoch 425 after optimizer.step() : tensor([2.9412, 4.9933], requires_grad=True), required_grad : True\n",
      "epoch 426 loss is 1.045108437538147\n",
      "epoch 426 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 426 : params.grad right after loss.backward(): tensor([-0.0102, -0.0034])\n",
      "epoch 426 after optimizer.step() : tensor([2.9413, 4.9934], requires_grad=True), required_grad : True\n",
      "epoch 427 loss is 1.0451072454452515\n",
      "epoch 427 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 427 : params.grad right after loss.backward(): tensor([-0.0101, -0.0034])\n",
      "epoch 427 after optimizer.step() : tensor([2.9414, 4.9934], requires_grad=True), required_grad : True\n",
      "epoch 428 loss is 1.045106053352356\n",
      "epoch 428 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 428 : params.grad right after loss.backward(): tensor([-0.0100, -0.0033])\n",
      "epoch 428 after optimizer.step() : tensor([2.9415, 4.9935], requires_grad=True), required_grad : True\n",
      "epoch 429 loss is 1.0451050996780396\n",
      "epoch 429 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 429 : params.grad right after loss.backward(): tensor([-0.0098, -0.0033])\n",
      "epoch 429 after optimizer.step() : tensor([2.9416, 4.9935], requires_grad=True), required_grad : True\n",
      "epoch 430 loss is 1.0451040267944336\n",
      "epoch 430 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 430 : params.grad right after loss.backward(): tensor([-0.0097, -0.0032])\n",
      "epoch 430 after optimizer.step() : tensor([2.9417, 4.9935], requires_grad=True), required_grad : True\n",
      "epoch 431 loss is 1.0451029539108276\n",
      "epoch 431 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 431 : params.grad right after loss.backward(): tensor([-0.0096, -0.0032])\n",
      "epoch 431 after optimizer.step() : tensor([2.9418, 4.9935], requires_grad=True), required_grad : True\n",
      "epoch 432 loss is 1.0451020002365112\n",
      "epoch 432 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 432 : params.grad right after loss.backward(): tensor([-0.0094, -0.0031])\n",
      "epoch 432 after optimizer.step() : tensor([2.9419, 4.9936], requires_grad=True), required_grad : True\n",
      "epoch 433 loss is 1.0451008081436157\n",
      "epoch 433 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 433 : params.grad right after loss.backward(): tensor([-0.0093, -0.0030])\n",
      "epoch 433 after optimizer.step() : tensor([2.9420, 4.9936], requires_grad=True), required_grad : True\n",
      "epoch 434 loss is 1.0450999736785889\n",
      "epoch 434 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 434 : params.grad right after loss.backward(): tensor([-0.0092, -0.0030])\n",
      "epoch 434 after optimizer.step() : tensor([2.9421, 4.9936], requires_grad=True), required_grad : True\n",
      "epoch 435 loss is 1.045098900794983\n",
      "epoch 435 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 435 : params.grad right after loss.backward(): tensor([-0.0091, -0.0029])\n",
      "epoch 435 after optimizer.step() : tensor([2.9422, 4.9937], requires_grad=True), required_grad : True\n",
      "epoch 436 loss is 1.0450981855392456\n",
      "epoch 436 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 436 : params.grad right after loss.backward(): tensor([-0.0089, -0.0029])\n",
      "epoch 436 after optimizer.step() : tensor([2.9423, 4.9937], requires_grad=True), required_grad : True\n",
      "epoch 437 loss is 1.0450972318649292\n",
      "epoch 437 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 437 : params.grad right after loss.backward(): tensor([-0.0088, -0.0029])\n",
      "epoch 437 after optimizer.step() : tensor([2.9423, 4.9937], requires_grad=True), required_grad : True\n",
      "epoch 438 loss is 1.045096516609192\n",
      "epoch 438 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 438 : params.grad right after loss.backward(): tensor([-0.0087, -0.0028])\n",
      "epoch 438 after optimizer.step() : tensor([2.9424, 4.9938], requires_grad=True), required_grad : True\n",
      "epoch 439 loss is 1.0450955629348755\n",
      "epoch 439 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 439 : params.grad right after loss.backward(): tensor([-0.0086, -0.0028])\n",
      "epoch 439 after optimizer.step() : tensor([2.9425, 4.9938], requires_grad=True), required_grad : True\n",
      "epoch 440 loss is 1.0450948476791382\n",
      "epoch 440 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 440 : params.grad right after loss.backward(): tensor([-0.0085, -0.0027])\n",
      "epoch 440 after optimizer.step() : tensor([2.9426, 4.9938], requires_grad=True), required_grad : True\n",
      "epoch 441 loss is 1.0450938940048218\n",
      "epoch 441 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 441 : params.grad right after loss.backward(): tensor([-0.0083, -0.0027])\n",
      "epoch 441 after optimizer.step() : tensor([2.9427, 4.9938], requires_grad=True), required_grad : True\n",
      "epoch 442 loss is 1.0450931787490845\n",
      "epoch 442 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 442 : params.grad right after loss.backward(): tensor([-0.0082, -0.0026])\n",
      "epoch 442 after optimizer.step() : tensor([2.9428, 4.9939], requires_grad=True), required_grad : True\n",
      "epoch 443 loss is 1.0450925827026367\n",
      "epoch 443 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 443 : params.grad right after loss.backward(): tensor([-0.0081, -0.0026])\n",
      "epoch 443 after optimizer.step() : tensor([2.9429, 4.9939], requires_grad=True), required_grad : True\n",
      "epoch 444 loss is 1.0450917482376099\n",
      "epoch 444 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 444 : params.grad right after loss.backward(): tensor([-0.0080, -0.0025])\n",
      "epoch 444 after optimizer.step() : tensor([2.9429, 4.9939], requires_grad=True), required_grad : True\n",
      "epoch 445 loss is 1.045091152191162\n",
      "epoch 445 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 445 : params.grad right after loss.backward(): tensor([-0.0079, -0.0025])\n",
      "epoch 445 after optimizer.step() : tensor([2.9430, 4.9939], requires_grad=True), required_grad : True\n",
      "epoch 446 loss is 1.0450903177261353\n",
      "epoch 446 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 446 : params.grad right after loss.backward(): tensor([-0.0078, -0.0025])\n",
      "epoch 446 after optimizer.step() : tensor([2.9431, 4.9940], requires_grad=True), required_grad : True\n",
      "epoch 447 loss is 1.045089840888977\n",
      "epoch 447 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 447 : params.grad right after loss.backward(): tensor([-0.0077, -0.0024])\n",
      "epoch 447 after optimizer.step() : tensor([2.9432, 4.9940], requires_grad=True), required_grad : True\n",
      "epoch 448 loss is 1.0450891256332397\n",
      "epoch 448 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 448 : params.grad right after loss.backward(): tensor([-0.0076, -0.0024])\n",
      "epoch 448 after optimizer.step() : tensor([2.9432, 4.9940], requires_grad=True), required_grad : True\n",
      "epoch 449 loss is 1.0450884103775024\n",
      "epoch 449 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 449 : params.grad right after loss.backward(): tensor([-0.0075, -0.0023])\n",
      "epoch 449 after optimizer.step() : tensor([2.9433, 4.9940], requires_grad=True), required_grad : True\n",
      "epoch 450 loss is 1.0450879335403442\n",
      "epoch 450 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 450 : params.grad right after loss.backward(): tensor([-0.0074, -0.0023])\n",
      "epoch 450 after optimizer.step() : tensor([2.9434, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 451 loss is 1.0450873374938965\n",
      "epoch 451 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 451 : params.grad right after loss.backward(): tensor([-0.0073, -0.0023])\n",
      "epoch 451 after optimizer.step() : tensor([2.9435, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 452 loss is 1.0450866222381592\n",
      "epoch 452 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 452 : params.grad right after loss.backward(): tensor([-0.0072, -0.0022])\n",
      "epoch 452 after optimizer.step() : tensor([2.9435, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 453 loss is 1.045086145401001\n",
      "epoch 453 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 453 : params.grad right after loss.backward(): tensor([-0.0071, -0.0022])\n",
      "epoch 453 after optimizer.step() : tensor([2.9436, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 454 loss is 1.0450855493545532\n",
      "epoch 454 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 454 : params.grad right after loss.backward(): tensor([-0.0070, -0.0022])\n",
      "epoch 454 after optimizer.step() : tensor([2.9437, 4.9941], requires_grad=True), required_grad : True\n",
      "epoch 455 loss is 1.0450851917266846\n",
      "epoch 455 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 455 : params.grad right after loss.backward(): tensor([-0.0069, -0.0021])\n",
      "epoch 455 after optimizer.step() : tensor([2.9437, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 456 loss is 1.0450844764709473\n",
      "epoch 456 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 456 : params.grad right after loss.backward(): tensor([-0.0068, -0.0021])\n",
      "epoch 456 after optimizer.step() : tensor([2.9438, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 457 loss is 1.0450838804244995\n",
      "epoch 457 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 457 : params.grad right after loss.backward(): tensor([-0.0067, -0.0020])\n",
      "epoch 457 after optimizer.step() : tensor([2.9439, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 458 loss is 1.0450836420059204\n",
      "epoch 458 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 458 : params.grad right after loss.backward(): tensor([-0.0066, -0.0020])\n",
      "epoch 458 after optimizer.step() : tensor([2.9439, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 459 loss is 1.0450830459594727\n",
      "epoch 459 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 459 : params.grad right after loss.backward(): tensor([-0.0065, -0.0020])\n",
      "epoch 459 after optimizer.step() : tensor([2.9440, 4.9942], requires_grad=True), required_grad : True\n",
      "epoch 460 loss is 1.0450825691223145\n",
      "epoch 460 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 460 : params.grad right after loss.backward(): tensor([-0.0064, -0.0020])\n",
      "epoch 460 after optimizer.step() : tensor([2.9441, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 461 loss is 1.0450819730758667\n",
      "epoch 461 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 461 : params.grad right after loss.backward(): tensor([-0.0064, -0.0019])\n",
      "epoch 461 after optimizer.step() : tensor([2.9441, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 462 loss is 1.0450817346572876\n",
      "epoch 462 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 462 : params.grad right after loss.backward(): tensor([-0.0063, -0.0019])\n",
      "epoch 462 after optimizer.step() : tensor([2.9442, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 463 loss is 1.045081377029419\n",
      "epoch 463 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 463 : params.grad right after loss.backward(): tensor([-0.0062, -0.0019])\n",
      "epoch 463 after optimizer.step() : tensor([2.9443, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 464 loss is 1.0450809001922607\n",
      "epoch 464 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 464 : params.grad right after loss.backward(): tensor([-0.0061, -0.0018])\n",
      "epoch 464 after optimizer.step() : tensor([2.9443, 4.9943], requires_grad=True), required_grad : True\n",
      "epoch 465 loss is 1.045080542564392\n",
      "epoch 465 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 465 : params.grad right after loss.backward(): tensor([-0.0060, -0.0018])\n",
      "epoch 465 after optimizer.step() : tensor([2.9444, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 466 loss is 1.0450800657272339\n",
      "epoch 466 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 466 : params.grad right after loss.backward(): tensor([-0.0059, -0.0018])\n",
      "epoch 466 after optimizer.step() : tensor([2.9444, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 467 loss is 1.0450797080993652\n",
      "epoch 467 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 467 : params.grad right after loss.backward(): tensor([-0.0059, -0.0017])\n",
      "epoch 467 after optimizer.step() : tensor([2.9445, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 468 loss is 1.045079231262207\n",
      "epoch 468 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 468 : params.grad right after loss.backward(): tensor([-0.0058, -0.0017])\n",
      "epoch 468 after optimizer.step() : tensor([2.9446, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 469 loss is 1.0450788736343384\n",
      "epoch 469 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 469 : params.grad right after loss.backward(): tensor([-0.0057, -0.0017])\n",
      "epoch 469 after optimizer.step() : tensor([2.9446, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 470 loss is 1.0450787544250488\n",
      "epoch 470 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 470 : params.grad right after loss.backward(): tensor([-0.0056, -0.0017])\n",
      "epoch 470 after optimizer.step() : tensor([2.9447, 4.9944], requires_grad=True), required_grad : True\n",
      "epoch 471 loss is 1.0450783967971802\n",
      "epoch 471 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 471 : params.grad right after loss.backward(): tensor([-0.0055, -0.0016])\n",
      "epoch 471 after optimizer.step() : tensor([2.9447, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 472 loss is 1.045077919960022\n",
      "epoch 472 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 472 : params.grad right after loss.backward(): tensor([-0.0055, -0.0016])\n",
      "epoch 472 after optimizer.step() : tensor([2.9448, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 473 loss is 1.0450776815414429\n",
      "epoch 473 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 473 : params.grad right after loss.backward(): tensor([-0.0054, -0.0016])\n",
      "epoch 473 after optimizer.step() : tensor([2.9448, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 474 loss is 1.0450773239135742\n",
      "epoch 474 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 474 : params.grad right after loss.backward(): tensor([-0.0053, -0.0016])\n",
      "epoch 474 after optimizer.step() : tensor([2.9449, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 475 loss is 1.0450769662857056\n",
      "epoch 475 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 475 : params.grad right after loss.backward(): tensor([-0.0052, -0.0015])\n",
      "epoch 475 after optimizer.step() : tensor([2.9449, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 476 loss is 1.0450767278671265\n",
      "epoch 476 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 476 : params.grad right after loss.backward(): tensor([-0.0052, -0.0015])\n",
      "epoch 476 after optimizer.step() : tensor([2.9450, 4.9945], requires_grad=True), required_grad : True\n",
      "epoch 477 loss is 1.0450762510299683\n",
      "epoch 477 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 477 : params.grad right after loss.backward(): tensor([-0.0051, -0.0015])\n",
      "epoch 477 after optimizer.step() : tensor([2.9450, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 478 loss is 1.0450761318206787\n",
      "epoch 478 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 478 : params.grad right after loss.backward(): tensor([-0.0050, -0.0015])\n",
      "epoch 478 after optimizer.step() : tensor([2.9451, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 479 loss is 1.04507577419281\n",
      "epoch 479 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 479 : params.grad right after loss.backward(): tensor([-0.0050, -0.0014])\n",
      "epoch 479 after optimizer.step() : tensor([2.9451, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 480 loss is 1.0450756549835205\n",
      "epoch 480 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 480 : params.grad right after loss.backward(): tensor([-0.0049, -0.0014])\n",
      "epoch 480 after optimizer.step() : tensor([2.9452, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 481 loss is 1.0450751781463623\n",
      "epoch 481 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 481 : params.grad right after loss.backward(): tensor([-0.0048, -0.0014])\n",
      "epoch 481 after optimizer.step() : tensor([2.9452, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 482 loss is 1.0450751781463623\n",
      "epoch 482 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 482 : params.grad right after loss.backward(): tensor([-0.0048, -0.0014])\n",
      "epoch 482 after optimizer.step() : tensor([2.9453, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 483 loss is 1.0450748205184937\n",
      "epoch 483 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 483 : params.grad right after loss.backward(): tensor([-0.0047, -0.0013])\n",
      "epoch 483 after optimizer.step() : tensor([2.9453, 4.9946], requires_grad=True), required_grad : True\n",
      "epoch 484 loss is 1.045074462890625\n",
      "epoch 484 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 484 : params.grad right after loss.backward(): tensor([-0.0046, -0.0013])\n",
      "epoch 484 after optimizer.step() : tensor([2.9454, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 485 loss is 1.0450743436813354\n",
      "epoch 485 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 485 : params.grad right after loss.backward(): tensor([-0.0046, -0.0013])\n",
      "epoch 485 after optimizer.step() : tensor([2.9454, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 486 loss is 1.045074224472046\n",
      "epoch 486 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 486 : params.grad right after loss.backward(): tensor([-0.0045, -0.0013])\n",
      "epoch 486 after optimizer.step() : tensor([2.9455, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 487 loss is 1.0450739860534668\n",
      "epoch 487 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 487 : params.grad right after loss.backward(): tensor([-0.0045, -0.0013])\n",
      "epoch 487 after optimizer.step() : tensor([2.9455, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 488 loss is 1.0450737476348877\n",
      "epoch 488 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 488 : params.grad right after loss.backward(): tensor([-0.0044, -0.0012])\n",
      "epoch 488 after optimizer.step() : tensor([2.9456, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 489 loss is 1.0450732707977295\n",
      "epoch 489 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 489 : params.grad right after loss.backward(): tensor([-0.0043, -0.0012])\n",
      "epoch 489 after optimizer.step() : tensor([2.9456, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 490 loss is 1.045073390007019\n",
      "epoch 490 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 490 : params.grad right after loss.backward(): tensor([-0.0043, -0.0012])\n",
      "epoch 490 after optimizer.step() : tensor([2.9457, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 491 loss is 1.04507315158844\n",
      "epoch 491 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 491 : params.grad right after loss.backward(): tensor([-0.0042, -0.0012])\n",
      "epoch 491 after optimizer.step() : tensor([2.9457, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 492 loss is 1.0450730323791504\n",
      "epoch 492 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 492 : params.grad right after loss.backward(): tensor([-0.0042, -0.0012])\n",
      "epoch 492 after optimizer.step() : tensor([2.9457, 4.9947], requires_grad=True), required_grad : True\n",
      "epoch 493 loss is 1.0450727939605713\n",
      "epoch 493 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 493 : params.grad right after loss.backward(): tensor([-0.0041, -0.0011])\n",
      "epoch 493 after optimizer.step() : tensor([2.9458, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 494 loss is 1.0450724363327026\n",
      "epoch 494 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 494 : params.grad right after loss.backward(): tensor([-0.0040, -0.0011])\n",
      "epoch 494 after optimizer.step() : tensor([2.9458, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 495 loss is 1.045072317123413\n",
      "epoch 495 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 495 : params.grad right after loss.backward(): tensor([-0.0040, -0.0011])\n",
      "epoch 495 after optimizer.step() : tensor([2.9459, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 496 loss is 1.045072317123413\n",
      "epoch 496 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 496 : params.grad right after loss.backward(): tensor([-0.0039, -0.0011])\n",
      "epoch 496 after optimizer.step() : tensor([2.9459, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 497 loss is 1.045072078704834\n",
      "epoch 497 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 497 : params.grad right after loss.backward(): tensor([-0.0039, -0.0011])\n",
      "epoch 497 after optimizer.step() : tensor([2.9459, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 498 loss is 1.0450718402862549\n",
      "epoch 498 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 498 : params.grad right after loss.backward(): tensor([-0.0038, -0.0011])\n",
      "epoch 498 after optimizer.step() : tensor([2.9460, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 499 loss is 1.0450718402862549\n",
      "epoch 499 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 499 : params.grad right after loss.backward(): tensor([-0.0038, -0.0010])\n",
      "epoch 499 after optimizer.step() : tensor([2.9460, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 500 loss is 1.0450716018676758\n",
      "epoch 500 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 500 : params.grad right after loss.backward(): tensor([-0.0037, -0.0010])\n",
      "epoch 500 after optimizer.step() : tensor([2.9460, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 501 loss is 1.0450713634490967\n",
      "epoch 501 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 501 : params.grad right after loss.backward(): tensor([-0.0037, -0.0010])\n",
      "epoch 501 after optimizer.step() : tensor([2.9461, 4.9948], requires_grad=True), required_grad : True\n",
      "epoch 502 loss is 1.0450712442398071\n",
      "epoch 502 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 502 : params.grad right after loss.backward(): tensor([-0.0036, -0.0010])\n",
      "epoch 502 after optimizer.step() : tensor([2.9461, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 503 loss is 1.0450711250305176\n",
      "epoch 503 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 503 : params.grad right after loss.backward(): tensor([-0.0036, -0.0010])\n",
      "epoch 503 after optimizer.step() : tensor([2.9462, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 504 loss is 1.045071005821228\n",
      "epoch 504 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 504 : params.grad right after loss.backward(): tensor([-0.0035, -0.0010])\n",
      "epoch 504 after optimizer.step() : tensor([2.9462, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 505 loss is 1.045071005821228\n",
      "epoch 505 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 505 : params.grad right after loss.backward(): tensor([-0.0035, -0.0009])\n",
      "epoch 505 after optimizer.step() : tensor([2.9462, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 506 loss is 1.045070767402649\n",
      "epoch 506 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 506 : params.grad right after loss.backward(): tensor([-0.0034, -0.0009])\n",
      "epoch 506 after optimizer.step() : tensor([2.9463, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 507 loss is 1.0450705289840698\n",
      "epoch 507 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 507 : params.grad right after loss.backward(): tensor([-0.0034, -0.0009])\n",
      "epoch 507 after optimizer.step() : tensor([2.9463, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 508 loss is 1.0450705289840698\n",
      "epoch 508 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 508 : params.grad right after loss.backward(): tensor([-0.0033, -0.0009])\n",
      "epoch 508 after optimizer.step() : tensor([2.9463, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 509 loss is 1.0450702905654907\n",
      "epoch 509 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 509 : params.grad right after loss.backward(): tensor([-0.0033, -0.0009])\n",
      "epoch 509 after optimizer.step() : tensor([2.9464, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 510 loss is 1.0450702905654907\n",
      "epoch 510 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 510 : params.grad right after loss.backward(): tensor([-0.0032, -0.0009])\n",
      "epoch 510 after optimizer.step() : tensor([2.9464, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 511 loss is 1.0450701713562012\n",
      "epoch 511 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 511 : params.grad right after loss.backward(): tensor([-0.0032, -0.0009])\n",
      "epoch 511 after optimizer.step() : tensor([2.9464, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 512 loss is 1.045069932937622\n",
      "epoch 512 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 512 : params.grad right after loss.backward(): tensor([-0.0032, -0.0008])\n",
      "epoch 512 after optimizer.step() : tensor([2.9465, 4.9949], requires_grad=True), required_grad : True\n",
      "epoch 513 loss is 1.045069932937622\n",
      "epoch 513 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 513 : params.grad right after loss.backward(): tensor([-0.0031, -0.0008])\n",
      "epoch 513 after optimizer.step() : tensor([2.9465, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 514 loss is 1.045069932937622\n",
      "epoch 514 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 514 : params.grad right after loss.backward(): tensor([-0.0031, -0.0008])\n",
      "epoch 514 after optimizer.step() : tensor([2.9465, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 515 loss is 1.045069694519043\n",
      "epoch 515 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 515 : params.grad right after loss.backward(): tensor([-0.0030, -0.0008])\n",
      "epoch 515 after optimizer.step() : tensor([2.9465, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 516 loss is 1.045069694519043\n",
      "epoch 516 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 516 : params.grad right after loss.backward(): tensor([-0.0030, -0.0008])\n",
      "epoch 516 after optimizer.step() : tensor([2.9466, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 517 loss is 1.045069694519043\n",
      "epoch 517 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 517 : params.grad right after loss.backward(): tensor([-0.0029, -0.0008])\n",
      "epoch 517 after optimizer.step() : tensor([2.9466, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 518 loss is 1.0450694561004639\n",
      "epoch 518 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 518 : params.grad right after loss.backward(): tensor([-0.0029, -0.0008])\n",
      "epoch 518 after optimizer.step() : tensor([2.9466, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 519 loss is 1.0450694561004639\n",
      "epoch 519 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 519 : params.grad right after loss.backward(): tensor([-0.0029, -0.0008])\n",
      "epoch 519 after optimizer.step() : tensor([2.9467, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 520 loss is 1.0450693368911743\n",
      "epoch 520 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 520 : params.grad right after loss.backward(): tensor([-0.0028, -0.0007])\n",
      "epoch 520 after optimizer.step() : tensor([2.9467, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 521 loss is 1.0450690984725952\n",
      "epoch 521 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 521 : params.grad right after loss.backward(): tensor([-0.0028, -0.0007])\n",
      "epoch 521 after optimizer.step() : tensor([2.9467, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 522 loss is 1.0450690984725952\n",
      "epoch 522 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 522 : params.grad right after loss.backward(): tensor([-0.0028, -0.0007])\n",
      "epoch 522 after optimizer.step() : tensor([2.9467, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 523 loss is 1.0450690984725952\n",
      "epoch 523 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 523 : params.grad right after loss.backward(): tensor([-0.0027, -0.0007])\n",
      "epoch 523 after optimizer.step() : tensor([2.9468, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 524 loss is 1.0450689792633057\n",
      "epoch 524 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 524 : params.grad right after loss.backward(): tensor([-0.0027, -0.0007])\n",
      "epoch 524 after optimizer.step() : tensor([2.9468, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 525 loss is 1.0450688600540161\n",
      "epoch 525 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 525 : params.grad right after loss.backward(): tensor([-0.0026, -0.0007])\n",
      "epoch 525 after optimizer.step() : tensor([2.9468, 4.9950], requires_grad=True), required_grad : True\n",
      "epoch 526 loss is 1.0450688600540161\n",
      "epoch 526 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 526 : params.grad right after loss.backward(): tensor([-0.0026, -0.0007])\n",
      "epoch 526 after optimizer.step() : tensor([2.9469, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 527 loss is 1.0450687408447266\n",
      "epoch 527 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 527 : params.grad right after loss.backward(): tensor([-0.0026, -0.0007])\n",
      "epoch 527 after optimizer.step() : tensor([2.9469, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 528 loss is 1.045068621635437\n",
      "epoch 528 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 528 : params.grad right after loss.backward(): tensor([-0.0025, -0.0007])\n",
      "epoch 528 after optimizer.step() : tensor([2.9469, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 529 loss is 1.045068621635437\n",
      "epoch 529 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 529 : params.grad right after loss.backward(): tensor([-0.0025, -0.0006])\n",
      "epoch 529 after optimizer.step() : tensor([2.9469, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 530 loss is 1.045068621635437\n",
      "epoch 530 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 530 : params.grad right after loss.backward(): tensor([-0.0025, -0.0006])\n",
      "epoch 530 after optimizer.step() : tensor([2.9470, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 531 loss is 1.045068383216858\n",
      "epoch 531 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 531 : params.grad right after loss.backward(): tensor([-0.0024, -0.0006])\n",
      "epoch 531 after optimizer.step() : tensor([2.9470, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 532 loss is 1.045068383216858\n",
      "epoch 532 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 532 : params.grad right after loss.backward(): tensor([-0.0024, -0.0006])\n",
      "epoch 532 after optimizer.step() : tensor([2.9470, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 533 loss is 1.0450682640075684\n",
      "epoch 533 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 533 : params.grad right after loss.backward(): tensor([-0.0024, -0.0006])\n",
      "epoch 533 after optimizer.step() : tensor([2.9470, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 534 loss is 1.045068383216858\n",
      "epoch 534 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 534 : params.grad right after loss.backward(): tensor([-0.0023, -0.0006])\n",
      "epoch 534 after optimizer.step() : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 535 loss is 1.0450682640075684\n",
      "epoch 535 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 535 : params.grad right after loss.backward(): tensor([-0.0023, -0.0006])\n",
      "epoch 535 after optimizer.step() : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 536 loss is 1.0450682640075684\n",
      "epoch 536 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 536 : params.grad right after loss.backward(): tensor([-0.0023, -0.0006])\n",
      "epoch 536 after optimizer.step() : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 537 loss is 1.0450680255889893\n",
      "epoch 537 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 537 : params.grad right after loss.backward(): tensor([-0.0022, -0.0006])\n",
      "epoch 537 after optimizer.step() : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 538 loss is 1.0450681447982788\n",
      "epoch 538 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 538 : params.grad right after loss.backward(): tensor([-0.0022, -0.0006])\n",
      "epoch 538 after optimizer.step() : tensor([2.9471, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 539 loss is 1.0450680255889893\n",
      "epoch 539 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 539 : params.grad right after loss.backward(): tensor([-0.0022, -0.0006])\n",
      "epoch 539 after optimizer.step() : tensor([2.9472, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 540 loss is 1.0450679063796997\n",
      "epoch 540 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 540 : params.grad right after loss.backward(): tensor([-0.0022, -0.0005])\n",
      "epoch 540 after optimizer.step() : tensor([2.9472, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 541 loss is 1.0450679063796997\n",
      "epoch 541 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 541 : params.grad right after loss.backward(): tensor([-0.0021, -0.0005])\n",
      "epoch 541 after optimizer.step() : tensor([2.9472, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 542 loss is 1.0450677871704102\n",
      "epoch 542 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 542 : params.grad right after loss.backward(): tensor([-0.0021, -0.0005])\n",
      "epoch 542 after optimizer.step() : tensor([2.9472, 4.9951], requires_grad=True), required_grad : True\n",
      "epoch 543 loss is 1.0450679063796997\n",
      "epoch 543 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 543 : params.grad right after loss.backward(): tensor([-0.0021, -0.0005])\n",
      "epoch 543 after optimizer.step() : tensor([2.9472, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 544 loss is 1.0450677871704102\n",
      "epoch 544 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 544 : params.grad right after loss.backward(): tensor([-0.0020, -0.0005])\n",
      "epoch 544 after optimizer.step() : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 545 loss is 1.0450677871704102\n",
      "epoch 545 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 545 : params.grad right after loss.backward(): tensor([-0.0020, -0.0005])\n",
      "epoch 545 after optimizer.step() : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 546 loss is 1.045067548751831\n",
      "epoch 546 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 546 : params.grad right after loss.backward(): tensor([-0.0020, -0.0005])\n",
      "epoch 546 after optimizer.step() : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 547 loss is 1.0450676679611206\n",
      "epoch 547 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 547 : params.grad right after loss.backward(): tensor([-0.0020, -0.0005])\n",
      "epoch 547 after optimizer.step() : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 548 loss is 1.0450676679611206\n",
      "epoch 548 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 548 : params.grad right after loss.backward(): tensor([-0.0019, -0.0005])\n",
      "epoch 548 after optimizer.step() : tensor([2.9473, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 549 loss is 1.0450674295425415\n",
      "epoch 549 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 549 : params.grad right after loss.backward(): tensor([-0.0019, -0.0005])\n",
      "epoch 549 after optimizer.step() : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 550 loss is 1.0450674295425415\n",
      "epoch 550 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 550 : params.grad right after loss.backward(): tensor([-0.0019, -0.0005])\n",
      "epoch 550 after optimizer.step() : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 551 loss is 1.045067548751831\n",
      "epoch 551 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 551 : params.grad right after loss.backward(): tensor([-0.0018, -0.0005])\n",
      "epoch 551 after optimizer.step() : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 552 loss is 1.0450674295425415\n",
      "epoch 552 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 552 : params.grad right after loss.backward(): tensor([-0.0018, -0.0004])\n",
      "epoch 552 after optimizer.step() : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 553 loss is 1.045067310333252\n",
      "epoch 553 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 553 : params.grad right after loss.backward(): tensor([-0.0018, -0.0004])\n",
      "epoch 553 after optimizer.step() : tensor([2.9474, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 554 loss is 1.0450671911239624\n",
      "epoch 554 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 554 : params.grad right after loss.backward(): tensor([-0.0018, -0.0004])\n",
      "epoch 554 after optimizer.step() : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 555 loss is 1.0450674295425415\n",
      "epoch 555 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 555 : params.grad right after loss.backward(): tensor([-0.0018, -0.0004])\n",
      "epoch 555 after optimizer.step() : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 556 loss is 1.0450674295425415\n",
      "epoch 556 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 556 : params.grad right after loss.backward(): tensor([-0.0017, -0.0004])\n",
      "epoch 556 after optimizer.step() : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 557 loss is 1.0450671911239624\n",
      "epoch 557 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 557 : params.grad right after loss.backward(): tensor([-0.0017, -0.0004])\n",
      "epoch 557 after optimizer.step() : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 558 loss is 1.0450671911239624\n",
      "epoch 558 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 558 : params.grad right after loss.backward(): tensor([-0.0017, -0.0004])\n",
      "epoch 558 after optimizer.step() : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 559 loss is 1.045067310333252\n",
      "epoch 559 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 559 : params.grad right after loss.backward(): tensor([-0.0017, -0.0004])\n",
      "epoch 559 after optimizer.step() : tensor([2.9475, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 560 loss is 1.0450671911239624\n",
      "epoch 560 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 560 : params.grad right after loss.backward(): tensor([-0.0016, -0.0004])\n",
      "epoch 560 after optimizer.step() : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 561 loss is 1.0450671911239624\n",
      "epoch 561 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 561 : params.grad right after loss.backward(): tensor([-0.0016, -0.0004])\n",
      "epoch 561 after optimizer.step() : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 562 loss is 1.0450671911239624\n",
      "epoch 562 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 562 : params.grad right after loss.backward(): tensor([-0.0016, -0.0004])\n",
      "epoch 562 after optimizer.step() : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 563 loss is 1.0450671911239624\n",
      "epoch 563 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 563 : params.grad right after loss.backward(): tensor([-0.0016, -0.0004])\n",
      "epoch 563 after optimizer.step() : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 564 loss is 1.0450671911239624\n",
      "epoch 564 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 564 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 564 after optimizer.step() : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 565 loss is 1.0450670719146729\n",
      "epoch 565 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 565 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 565 after optimizer.step() : tensor([2.9476, 4.9952], requires_grad=True), required_grad : True\n",
      "epoch 566 loss is 1.0450670719146729\n",
      "epoch 566 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 566 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 566 after optimizer.step() : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 567 loss is 1.0450669527053833\n",
      "epoch 567 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 567 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 567 after optimizer.step() : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 568 loss is 1.0450668334960938\n",
      "epoch 568 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 568 : params.grad right after loss.backward(): tensor([-0.0015, -0.0004])\n",
      "epoch 568 after optimizer.step() : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 569 loss is 1.0450669527053833\n",
      "epoch 569 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 569 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 569 after optimizer.step() : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 570 loss is 1.0450669527053833\n",
      "epoch 570 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 570 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 570 after optimizer.step() : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 571 loss is 1.0450669527053833\n",
      "epoch 571 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 571 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 571 after optimizer.step() : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 572 loss is 1.0450668334960938\n",
      "epoch 572 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 572 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 572 after optimizer.step() : tensor([2.9477, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 573 loss is 1.0450669527053833\n",
      "epoch 573 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 573 : params.grad right after loss.backward(): tensor([-0.0014, -0.0003])\n",
      "epoch 573 after optimizer.step() : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 574 loss is 1.0450668334960938\n",
      "epoch 574 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 574 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 574 after optimizer.step() : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 575 loss is 1.0450669527053833\n",
      "epoch 575 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 575 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 575 after optimizer.step() : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 576 loss is 1.0450668334960938\n",
      "epoch 576 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 576 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 576 after optimizer.step() : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 577 loss is 1.0450668334960938\n",
      "epoch 577 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 577 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 577 after optimizer.step() : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 578 loss is 1.0450667142868042\n",
      "epoch 578 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 578 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 578 after optimizer.step() : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 579 loss is 1.0450667142868042\n",
      "epoch 579 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 579 : params.grad right after loss.backward(): tensor([-0.0013, -0.0003])\n",
      "epoch 579 after optimizer.step() : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 580 loss is 1.0450668334960938\n",
      "epoch 580 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 580 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 580 after optimizer.step() : tensor([2.9478, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 581 loss is 1.0450667142868042\n",
      "epoch 581 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 581 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 581 after optimizer.step() : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 582 loss is 1.0450667142868042\n",
      "epoch 582 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 582 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 582 after optimizer.step() : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 583 loss is 1.0450667142868042\n",
      "epoch 583 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 583 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 583 after optimizer.step() : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 584 loss is 1.0450667142868042\n",
      "epoch 584 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 584 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 584 after optimizer.step() : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 585 loss is 1.0450667142868042\n",
      "epoch 585 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 585 : params.grad right after loss.backward(): tensor([-0.0012, -0.0003])\n",
      "epoch 585 after optimizer.step() : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 586 loss is 1.0450665950775146\n",
      "epoch 586 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 586 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 586 after optimizer.step() : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 587 loss is 1.0450665950775146\n",
      "epoch 587 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 587 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 587 after optimizer.step() : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 588 loss is 1.0450667142868042\n",
      "epoch 588 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 588 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 588 after optimizer.step() : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 589 loss is 1.045066475868225\n",
      "epoch 589 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 589 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 589 after optimizer.step() : tensor([2.9479, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 590 loss is 1.0450665950775146\n",
      "epoch 590 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 590 : params.grad right after loss.backward(): tensor([-0.0011, -0.0003])\n",
      "epoch 590 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 591 loss is 1.0450665950775146\n",
      "epoch 591 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 591 : params.grad right after loss.backward(): tensor([-0.0011, -0.0002])\n",
      "epoch 591 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 592 loss is 1.045066475868225\n",
      "epoch 592 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 592 : params.grad right after loss.backward(): tensor([-0.0011, -0.0002])\n",
      "epoch 592 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 593 loss is 1.045066475868225\n",
      "epoch 593 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 593 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 593 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 594 loss is 1.045066475868225\n",
      "epoch 594 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 594 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 594 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 595 loss is 1.045066475868225\n",
      "epoch 595 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 595 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 595 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 596 loss is 1.0450665950775146\n",
      "epoch 596 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 596 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 596 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 597 loss is 1.0450665950775146\n",
      "epoch 597 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 597 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 597 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 598 loss is 1.045066475868225\n",
      "epoch 598 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 598 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 598 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 599 loss is 1.0450665950775146\n",
      "epoch 599 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 599 : params.grad right after loss.backward(): tensor([-0.0010, -0.0002])\n",
      "epoch 599 after optimizer.step() : tensor([2.9480, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 600 loss is 1.045066475868225\n",
      "epoch 600 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 600 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 600 after optimizer.step() : tensor([2.9481, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 601 loss is 1.045066475868225\n",
      "epoch 601 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 601 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 601 after optimizer.step() : tensor([2.9481, 4.9953], requires_grad=True), required_grad : True\n",
      "epoch 602 loss is 1.0450663566589355\n",
      "epoch 602 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 602 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 602 after optimizer.step() : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 603 loss is 1.045066475868225\n",
      "epoch 603 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 603 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 603 after optimizer.step() : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 604 loss is 1.0450663566589355\n",
      "epoch 604 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 604 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 604 after optimizer.step() : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 605 loss is 1.045066475868225\n",
      "epoch 605 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 605 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 605 after optimizer.step() : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 606 loss is 1.045066475868225\n",
      "epoch 606 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 606 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 606 after optimizer.step() : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 607 loss is 1.045066475868225\n",
      "epoch 607 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 607 : params.grad right after loss.backward(): tensor([-0.0009, -0.0002])\n",
      "epoch 607 after optimizer.step() : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 608 loss is 1.045066475868225\n",
      "epoch 608 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 608 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 608 after optimizer.step() : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 609 loss is 1.0450663566589355\n",
      "epoch 609 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 609 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 609 after optimizer.step() : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 610 loss is 1.045066475868225\n",
      "epoch 610 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 610 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 610 after optimizer.step() : tensor([2.9481, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 611 loss is 1.0450663566589355\n",
      "epoch 611 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 611 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 611 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 612 loss is 1.0450663566589355\n",
      "epoch 612 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 612 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 612 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 613 loss is 1.0450663566589355\n",
      "epoch 613 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 613 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 613 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 614 loss is 1.0450663566589355\n",
      "epoch 614 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 614 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 614 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 615 loss is 1.0450663566589355\n",
      "epoch 615 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 615 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 615 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 616 loss is 1.0450663566589355\n",
      "epoch 616 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 616 : params.grad right after loss.backward(): tensor([-0.0008, -0.0002])\n",
      "epoch 616 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 617 loss is 1.0450663566589355\n",
      "epoch 617 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 617 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 617 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 618 loss is 1.045066475868225\n",
      "epoch 618 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 618 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 618 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 619 loss is 1.045066475868225\n",
      "epoch 619 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 619 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 619 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 620 loss is 1.0450663566589355\n",
      "epoch 620 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 620 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 620 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 621 loss is 1.0450663566589355\n",
      "epoch 621 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 621 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 621 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 622 loss is 1.0450663566589355\n",
      "epoch 622 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 622 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 622 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 623 loss is 1.0450663566589355\n",
      "epoch 623 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 623 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 623 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 624 loss is 1.0450663566589355\n",
      "epoch 624 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 624 : params.grad right after loss.backward(): tensor([-0.0007, -0.0002])\n",
      "epoch 624 after optimizer.step() : tensor([2.9482, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 625 loss is 1.0450663566589355\n",
      "epoch 625 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 625 : params.grad right after loss.backward(): tensor([-0.0007, -0.0001])\n",
      "epoch 625 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 626 loss is 1.0450663566589355\n",
      "epoch 626 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 626 : params.grad right after loss.backward(): tensor([-0.0007, -0.0001])\n",
      "epoch 626 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 627 loss is 1.045066475868225\n",
      "epoch 627 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 627 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 627 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 628 loss is 1.045066237449646\n",
      "epoch 628 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 628 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 628 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 629 loss is 1.0450663566589355\n",
      "epoch 629 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 629 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 629 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 630 loss is 1.0450663566589355\n",
      "epoch 630 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 630 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 630 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 631 loss is 1.0450663566589355\n",
      "epoch 631 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 631 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 631 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 632 loss is 1.0450663566589355\n",
      "epoch 632 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 632 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 632 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 633 loss is 1.0450663566589355\n",
      "epoch 633 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 633 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 633 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 634 loss is 1.0450663566589355\n",
      "epoch 634 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 634 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 634 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 635 loss is 1.045066237449646\n",
      "epoch 635 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 635 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 635 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 636 loss is 1.045066237449646\n",
      "epoch 636 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 636 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 636 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 637 loss is 1.0450663566589355\n",
      "epoch 637 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 637 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 637 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 638 loss is 1.0450663566589355\n",
      "epoch 638 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 638 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 638 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 639 loss is 1.0450663566589355\n",
      "epoch 639 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 639 : params.grad right after loss.backward(): tensor([-0.0006, -0.0001])\n",
      "epoch 639 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 640 loss is 1.0450663566589355\n",
      "epoch 640 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 640 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 640 after optimizer.step() : tensor([2.9483, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 641 loss is 1.0450661182403564\n",
      "epoch 641 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 641 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 641 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 642 loss is 1.0450663566589355\n",
      "epoch 642 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 642 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 642 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 643 loss is 1.0450663566589355\n",
      "epoch 643 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 643 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 643 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 644 loss is 1.045066237449646\n",
      "epoch 644 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 644 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 644 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 645 loss is 1.0450661182403564\n",
      "epoch 645 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 645 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 645 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 646 loss is 1.0450663566589355\n",
      "epoch 646 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 646 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 646 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 647 loss is 1.0450663566589355\n",
      "epoch 647 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 647 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 647 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 648 loss is 1.0450663566589355\n",
      "epoch 648 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 648 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 648 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 649 loss is 1.0450661182403564\n",
      "epoch 649 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 649 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 649 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 650 loss is 1.0450661182403564\n",
      "epoch 650 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 650 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 650 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 651 loss is 1.0450661182403564\n",
      "epoch 651 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 651 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 651 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 652 loss is 1.0450661182403564\n",
      "epoch 652 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 652 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 652 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 653 loss is 1.045066237449646\n",
      "epoch 653 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 653 : params.grad right after loss.backward(): tensor([-0.0005, -0.0001])\n",
      "epoch 653 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 654 loss is 1.0450661182403564\n",
      "epoch 654 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 654 : params.grad right after loss.backward(): tensor([-4.4786e-04, -9.8750e-05])\n",
      "epoch 654 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 655 loss is 1.045066237449646\n",
      "epoch 655 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 655 : params.grad right after loss.backward(): tensor([-4.4162e-04, -9.7252e-05])\n",
      "epoch 655 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 656 loss is 1.0450663566589355\n",
      "epoch 656 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 656 : params.grad right after loss.backward(): tensor([-4.3545e-04, -9.5934e-05])\n",
      "epoch 656 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 657 loss is 1.0450661182403564\n",
      "epoch 657 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 657 : params.grad right after loss.backward(): tensor([-4.2957e-04, -9.4522e-05])\n",
      "epoch 657 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 658 loss is 1.045066237449646\n",
      "epoch 658 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 658 : params.grad right after loss.backward(): tensor([-4.2372e-04, -9.3088e-05])\n",
      "epoch 658 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 659 loss is 1.0450663566589355\n",
      "epoch 659 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 659 : params.grad right after loss.backward(): tensor([-4.1781e-04, -9.1664e-05])\n",
      "epoch 659 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 660 loss is 1.0450663566589355\n",
      "epoch 660 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 660 : params.grad right after loss.backward(): tensor([-4.1197e-04, -9.0294e-05])\n",
      "epoch 660 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 661 loss is 1.045066237449646\n",
      "epoch 661 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 661 : params.grad right after loss.backward(): tensor([-4.0637e-04, -8.8792e-05])\n",
      "epoch 661 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 662 loss is 1.0450663566589355\n",
      "epoch 662 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 662 : params.grad right after loss.backward(): tensor([-4.0084e-04, -8.7366e-05])\n",
      "epoch 662 after optimizer.step() : tensor([2.9484, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 663 loss is 1.0450663566589355\n",
      "epoch 663 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 663 : params.grad right after loss.backward(): tensor([-3.9530e-04, -8.5931e-05])\n",
      "epoch 663 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 664 loss is 1.045066237449646\n",
      "epoch 664 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 664 : params.grad right after loss.backward(): tensor([-3.8984e-04, -8.4519e-05])\n",
      "epoch 664 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 665 loss is 1.045066237449646\n",
      "epoch 665 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 665 : params.grad right after loss.backward(): tensor([-3.8462e-04, -8.3040e-05])\n",
      "epoch 665 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 666 loss is 1.045066237449646\n",
      "epoch 666 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 666 : params.grad right after loss.backward(): tensor([-3.7942e-04, -8.1558e-05])\n",
      "epoch 666 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 667 loss is 1.0450661182403564\n",
      "epoch 667 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 667 : params.grad right after loss.backward(): tensor([-3.7416e-04, -8.0042e-05])\n",
      "epoch 667 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 668 loss is 1.045066237449646\n",
      "epoch 668 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 668 : params.grad right after loss.backward(): tensor([-3.6897e-04, -7.8574e-05])\n",
      "epoch 668 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 669 loss is 1.045066237449646\n",
      "epoch 669 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 669 : params.grad right after loss.backward(): tensor([-3.6409e-04, -7.7099e-05])\n",
      "epoch 669 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 670 loss is 1.0450663566589355\n",
      "epoch 670 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 670 : params.grad right after loss.backward(): tensor([-3.5921e-04, -7.5623e-05])\n",
      "epoch 670 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 671 loss is 1.045066237449646\n",
      "epoch 671 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 671 : params.grad right after loss.backward(): tensor([-3.5427e-04, -7.4059e-05])\n",
      "epoch 671 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 672 loss is 1.045066237449646\n",
      "epoch 672 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 672 : params.grad right after loss.backward(): tensor([-3.4945e-04, -7.2543e-05])\n",
      "epoch 672 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 673 loss is 1.045066237449646\n",
      "epoch 673 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 673 : params.grad right after loss.backward(): tensor([-3.4463e-04, -7.1082e-05])\n",
      "epoch 673 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 674 loss is 1.0450663566589355\n",
      "epoch 674 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 674 : params.grad right after loss.backward(): tensor([-3.4003e-04, -7.0516e-05])\n",
      "epoch 674 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 675 loss is 1.045066237449646\n",
      "epoch 675 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 675 : params.grad right after loss.backward(): tensor([-3.3545e-04, -6.9939e-05])\n",
      "epoch 675 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 676 loss is 1.045066237449646\n",
      "epoch 676 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 676 : params.grad right after loss.backward(): tensor([-3.3083e-04, -6.9387e-05])\n",
      "epoch 676 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 677 loss is 1.0450661182403564\n",
      "epoch 677 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 677 : params.grad right after loss.backward(): tensor([-3.2627e-04, -6.8773e-05])\n",
      "epoch 677 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 678 loss is 1.0450663566589355\n",
      "epoch 678 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 678 : params.grad right after loss.backward(): tensor([-3.2165e-04, -6.8203e-05])\n",
      "epoch 678 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 679 loss is 1.0450661182403564\n",
      "epoch 679 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 679 : params.grad right after loss.backward(): tensor([-3.1740e-04, -6.7640e-05])\n",
      "epoch 679 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 680 loss is 1.045066237449646\n",
      "epoch 680 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 680 : params.grad right after loss.backward(): tensor([-3.1313e-04, -6.7048e-05])\n",
      "epoch 680 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 681 loss is 1.0450661182403564\n",
      "epoch 681 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 681 : params.grad right after loss.backward(): tensor([-3.0889e-04, -6.6422e-05])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 681 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 682 loss is 1.045066237449646\n",
      "epoch 682 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 682 : params.grad right after loss.backward(): tensor([-3.0448e-04, -6.5800e-05])\n",
      "epoch 682 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 683 loss is 1.0450663566589355\n",
      "epoch 683 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 683 : params.grad right after loss.backward(): tensor([-3.0036e-04, -6.5237e-05])\n",
      "epoch 683 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 684 loss is 1.0450661182403564\n",
      "epoch 684 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 684 : params.grad right after loss.backward(): tensor([-2.9604e-04, -6.4638e-05])\n",
      "epoch 684 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 685 loss is 1.0450663566589355\n",
      "epoch 685 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 685 : params.grad right after loss.backward(): tensor([-2.9210e-04, -6.3967e-05])\n",
      "epoch 685 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 686 loss is 1.045066237449646\n",
      "epoch 686 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 686 : params.grad right after loss.backward(): tensor([-2.8820e-04, -6.3341e-05])\n",
      "epoch 686 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 687 loss is 1.045066237449646\n",
      "epoch 687 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 687 : params.grad right after loss.backward(): tensor([-2.8422e-04, -6.2745e-05])\n",
      "epoch 687 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 688 loss is 1.0450661182403564\n",
      "epoch 688 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 688 : params.grad right after loss.backward(): tensor([-2.8035e-04, -6.2101e-05])\n",
      "epoch 688 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 689 loss is 1.0450661182403564\n",
      "epoch 689 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 689 : params.grad right after loss.backward(): tensor([-2.7639e-04, -6.1456e-05])\n",
      "epoch 689 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 690 loss is 1.045066237449646\n",
      "epoch 690 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 690 : params.grad right after loss.backward(): tensor([-2.7241e-04, -6.0849e-05])\n",
      "epoch 690 after optimizer.step() : tensor([2.9485, 4.9954], requires_grad=True), required_grad : True\n",
      "epoch 691 loss is 1.045066237449646\n",
      "epoch 691 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 691 : params.grad right after loss.backward(): tensor([-2.6885e-04, -6.0167e-05])\n",
      "epoch 691 after optimizer.step() : tensor([2.9485, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 692 loss is 1.0450661182403564\n",
      "epoch 692 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 692 : params.grad right after loss.backward(): tensor([-2.6525e-04, -5.9515e-05])\n",
      "epoch 692 after optimizer.step() : tensor([2.9485, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 693 loss is 1.0450661182403564\n",
      "epoch 693 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 693 : params.grad right after loss.backward(): tensor([-2.6166e-04, -5.8811e-05])\n",
      "epoch 693 after optimizer.step() : tensor([2.9485, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 694 loss is 1.0450661182403564\n",
      "epoch 694 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 694 : params.grad right after loss.backward(): tensor([-2.5812e-04, -5.8256e-05])\n",
      "epoch 694 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 695 loss is 1.045066237449646\n",
      "epoch 695 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 695 : params.grad right after loss.backward(): tensor([-2.5443e-04, -5.7533e-05])\n",
      "epoch 695 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 696 loss is 1.0450661182403564\n",
      "epoch 696 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 696 : params.grad right after loss.backward(): tensor([-2.5089e-04, -5.6908e-05])\n",
      "epoch 696 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 697 loss is 1.045066237449646\n",
      "epoch 697 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 697 : params.grad right after loss.backward(): tensor([-2.4721e-04, -5.6230e-05])\n",
      "epoch 697 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 698 loss is 1.045066237449646\n",
      "epoch 698 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 698 : params.grad right after loss.backward(): tensor([-2.4394e-04, -5.5522e-05])\n",
      "epoch 698 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 699 loss is 1.0450661182403564\n",
      "epoch 699 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 699 : params.grad right after loss.backward(): tensor([-2.4074e-04, -5.4885e-05])\n",
      "epoch 699 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 700 loss is 1.0450661182403564\n",
      "epoch 700 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 700 : params.grad right after loss.backward(): tensor([-2.3744e-04, -5.4181e-05])\n",
      "epoch 700 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 701 loss is 1.0450661182403564\n",
      "epoch 701 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 701 : params.grad right after loss.backward(): tensor([-2.3419e-04, -5.3532e-05])\n",
      "epoch 701 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 702 loss is 1.045066237449646\n",
      "epoch 702 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 702 : params.grad right after loss.backward(): tensor([-2.3093e-04, -5.2828e-05])\n",
      "epoch 702 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 703 loss is 1.045066237449646\n",
      "epoch 703 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 703 : params.grad right after loss.backward(): tensor([-2.2765e-04, -5.2113e-05])\n",
      "epoch 703 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 704 loss is 1.0450661182403564\n",
      "epoch 704 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 704 : params.grad right after loss.backward(): tensor([-2.2434e-04, -5.1424e-05])\n",
      "epoch 704 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 705 loss is 1.045066237449646\n",
      "epoch 705 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 705 : params.grad right after loss.backward(): tensor([-2.2151e-04, -5.0776e-05])\n",
      "epoch 705 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 706 loss is 1.045066237449646\n",
      "epoch 706 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 706 : params.grad right after loss.backward(): tensor([-2.1850e-04, -5.0016e-05])\n",
      "epoch 706 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 707 loss is 1.0450661182403564\n",
      "epoch 707 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 707 : params.grad right after loss.backward(): tensor([-2.1563e-04, -4.9386e-05])\n",
      "epoch 707 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 708 loss is 1.0450661182403564\n",
      "epoch 708 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 708 : params.grad right after loss.backward(): tensor([-2.1264e-04, -4.8626e-05])\n",
      "epoch 708 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 709 loss is 1.0450661182403564\n",
      "epoch 709 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 709 : params.grad right after loss.backward(): tensor([-2.0968e-04, -4.7944e-05])\n",
      "epoch 709 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 710 loss is 1.0450661182403564\n",
      "epoch 710 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 710 : params.grad right after loss.backward(): tensor([-2.0681e-04, -4.7136e-05])\n",
      "epoch 710 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 711 loss is 1.0450663566589355\n",
      "epoch 711 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 711 : params.grad right after loss.backward(): tensor([-2.0382e-04, -4.6484e-05])\n",
      "epoch 711 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 712 loss is 1.045066237449646\n",
      "epoch 712 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 712 : params.grad right after loss.backward(): tensor([-2.0090e-04, -4.5754e-05])\n",
      "epoch 712 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 713 loss is 1.0450661182403564\n",
      "epoch 713 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 713 : params.grad right after loss.backward(): tensor([-1.9825e-04, -4.4979e-05])\n",
      "epoch 713 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 714 loss is 1.0450663566589355\n",
      "epoch 714 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 714 : params.grad right after loss.backward(): tensor([-1.9572e-04, -4.4353e-05])\n",
      "epoch 714 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 715 loss is 1.0450661182403564\n",
      "epoch 715 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 715 : params.grad right after loss.backward(): tensor([-1.9313e-04, -4.3623e-05])\n",
      "epoch 715 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 716 loss is 1.0450661182403564\n",
      "epoch 716 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 716 : params.grad right after loss.backward(): tensor([-1.9053e-04, -4.2856e-05])\n",
      "epoch 716 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 717 loss is 1.045066237449646\n",
      "epoch 717 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 717 : params.grad right after loss.backward(): tensor([-1.8790e-04, -4.2107e-05])\n",
      "epoch 717 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 718 loss is 1.0450661182403564\n",
      "epoch 718 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 718 : params.grad right after loss.backward(): tensor([-1.8536e-04, -4.1399e-05])\n",
      "epoch 718 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 719 loss is 1.0450661182403564\n",
      "epoch 719 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 719 : params.grad right after loss.backward(): tensor([-1.8272e-04, -4.0673e-05])\n",
      "epoch 719 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 720 loss is 1.0450661182403564\n",
      "epoch 720 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 720 : params.grad right after loss.backward(): tensor([-1.8013e-04, -3.9965e-05])\n",
      "epoch 720 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 721 loss is 1.0450661182403564\n",
      "epoch 721 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 721 : params.grad right after loss.backward(): tensor([-1.7749e-04, -3.9168e-05])\n",
      "epoch 721 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 722 loss is 1.0450661182403564\n",
      "epoch 722 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 722 : params.grad right after loss.backward(): tensor([-1.7518e-04, -3.8389e-05])\n",
      "epoch 722 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 723 loss is 1.045066237449646\n",
      "epoch 723 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 723 : params.grad right after loss.backward(): tensor([-1.7292e-04, -3.7581e-05])\n",
      "epoch 723 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 724 loss is 1.0450661182403564\n",
      "epoch 724 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 724 : params.grad right after loss.backward(): tensor([-1.7072e-04, -3.6996e-05])\n",
      "epoch 724 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 725 loss is 1.0450661182403564\n",
      "epoch 725 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 725 : params.grad right after loss.backward(): tensor([-1.6843e-04, -3.6068e-05])\n",
      "epoch 725 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 726 loss is 1.045066237449646\n",
      "epoch 726 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 726 : params.grad right after loss.backward(): tensor([-1.6610e-04, -3.5387e-05])\n",
      "epoch 726 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 727 loss is 1.0450661182403564\n",
      "epoch 727 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 727 : params.grad right after loss.backward(): tensor([-1.6388e-04, -3.4615e-05])\n",
      "epoch 727 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 728 loss is 1.0450661182403564\n",
      "epoch 728 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 728 : params.grad right after loss.backward(): tensor([-1.6152e-04, -3.3833e-05])\n",
      "epoch 728 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 729 loss is 1.0450661182403564\n",
      "epoch 729 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 729 : params.grad right after loss.backward(): tensor([-1.5932e-04, -3.3036e-05])\n",
      "epoch 729 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 730 loss is 1.0450663566589355\n",
      "epoch 730 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 730 : params.grad right after loss.backward(): tensor([-1.5705e-04, -3.2276e-05])\n",
      "epoch 730 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 731 loss is 1.045066237449646\n",
      "epoch 731 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 731 : params.grad right after loss.backward(): tensor([-1.5478e-04, -3.1497e-05])\n",
      "epoch 731 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 732 loss is 1.045066237449646\n",
      "epoch 732 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 732 : params.grad right after loss.backward(): tensor([-1.5280e-04, -3.0745e-05])\n",
      "epoch 732 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 733 loss is 1.0450661182403564\n",
      "epoch 733 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 733 : params.grad right after loss.backward(): tensor([-1.5088e-04, -2.9933e-05])\n",
      "epoch 733 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 734 loss is 1.045066237449646\n",
      "epoch 734 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 734 : params.grad right after loss.backward(): tensor([-1.4895e-04, -2.9095e-05])\n",
      "epoch 734 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 735 loss is 1.045066237449646\n",
      "epoch 735 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 735 : params.grad right after loss.backward(): tensor([-1.4701e-04, -2.8342e-05])\n",
      "epoch 735 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 736 loss is 1.0450661182403564\n",
      "epoch 736 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 736 : params.grad right after loss.backward(): tensor([-1.4511e-04, -2.7582e-05])\n",
      "epoch 736 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 737 loss is 1.0450661182403564\n",
      "epoch 737 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 737 : params.grad right after loss.backward(): tensor([-1.4311e-04, -2.6781e-05])\n",
      "epoch 737 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 738 loss is 1.0450661182403564\n",
      "epoch 738 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 738 : params.grad right after loss.backward(): tensor([-1.4125e-04, -2.6029e-05])\n",
      "epoch 738 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 739 loss is 1.0450661182403564\n",
      "epoch 739 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 739 : params.grad right after loss.backward(): tensor([-1.3924e-04, -2.5161e-05])\n",
      "epoch 739 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 740 loss is 1.045066237449646\n",
      "epoch 740 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 740 : params.grad right after loss.backward(): tensor([-1.3734e-04, -2.4371e-05])\n",
      "epoch 740 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 741 loss is 1.045066237449646\n",
      "epoch 741 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 741 : params.grad right after loss.backward(): tensor([-1.3535e-04, -2.3596e-05])\n",
      "epoch 741 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 742 loss is 1.045066237449646\n",
      "epoch 742 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 742 : params.grad right after loss.backward(): tensor([-1.3338e-04, -2.3756e-05])\n",
      "epoch 742 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 743 loss is 1.045066237449646\n",
      "epoch 743 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 743 : params.grad right after loss.backward(): tensor([-1.3141e-04, -2.3942e-05])\n",
      "epoch 743 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 744 loss is 1.0450661182403564\n",
      "epoch 744 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 744 : params.grad right after loss.backward(): tensor([-1.2943e-04, -2.3123e-05])\n",
      "epoch 744 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 745 loss is 1.045066237449646\n",
      "epoch 745 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 745 : params.grad right after loss.backward(): tensor([-1.2786e-04, -2.3324e-05])\n",
      "epoch 745 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 746 loss is 1.0450661182403564\n",
      "epoch 746 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 746 : params.grad right after loss.backward(): tensor([-1.2617e-04, -2.3458e-05])\n",
      "epoch 746 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 747 loss is 1.0450661182403564\n",
      "epoch 747 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 747 : params.grad right after loss.backward(): tensor([-1.2445e-04, -2.3540e-05])\n",
      "epoch 747 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 748 loss is 1.045066237449646\n",
      "epoch 748 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 748 : params.grad right after loss.backward(): tensor([-1.2278e-04, -2.3637e-05])\n",
      "epoch 748 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 749 loss is 1.0450661182403564\n",
      "epoch 749 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 749 : params.grad right after loss.backward(): tensor([-1.2112e-04, -2.3790e-05])\n",
      "epoch 749 after optimizer.step() : tensor([2.9486, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 750 loss is 1.0450661182403564\n",
      "epoch 750 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 750 : params.grad right after loss.backward(): tensor([-1.1941e-04, -2.3924e-05])\n",
      "epoch 750 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 751 loss is 1.0450661182403564\n",
      "epoch 751 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 751 : params.grad right after loss.backward(): tensor([-1.1788e-04, -2.3130e-05])\n",
      "epoch 751 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 752 loss is 1.045066237449646\n",
      "epoch 752 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 752 : params.grad right after loss.backward(): tensor([-1.1622e-04, -2.3268e-05])\n",
      "epoch 752 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 753 loss is 1.0450661182403564\n",
      "epoch 753 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 753 : params.grad right after loss.backward(): tensor([-1.1457e-04, -2.3413e-05])\n",
      "epoch 753 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 754 loss is 1.045066237449646\n",
      "epoch 754 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 754 : params.grad right after loss.backward(): tensor([-1.1293e-04, -2.3525e-05])\n",
      "epoch 754 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 755 loss is 1.0450661182403564\n",
      "epoch 755 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 755 : params.grad right after loss.backward(): tensor([-1.1123e-04, -2.3667e-05])\n",
      "epoch 755 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 756 loss is 1.0450661182403564\n",
      "epoch 756 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 756 : params.grad right after loss.backward(): tensor([-1.0961e-04, -2.3831e-05])\n",
      "epoch 756 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 757 loss is 1.0450661182403564\n",
      "epoch 757 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 757 : params.grad right after loss.backward(): tensor([-1.0789e-04, -2.3939e-05])\n",
      "epoch 757 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 758 loss is 1.045066237449646\n",
      "epoch 758 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 758 : params.grad right after loss.backward(): tensor([-1.0638e-04, -2.3197e-05])\n",
      "epoch 758 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 759 loss is 1.045066237449646\n",
      "epoch 759 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 759 : params.grad right after loss.backward(): tensor([-1.0502e-04, -2.3283e-05])\n",
      "epoch 759 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 760 loss is 1.045066237449646\n",
      "epoch 760 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 760 : params.grad right after loss.backward(): tensor([-1.0359e-04, -2.3298e-05])\n",
      "epoch 760 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 761 loss is 1.045066237449646\n",
      "epoch 761 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 761 : params.grad right after loss.backward(): tensor([-1.0229e-04, -2.3410e-05])\n",
      "epoch 761 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 762 loss is 1.045066237449646\n",
      "epoch 762 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 762 : params.grad right after loss.backward(): tensor([-1.0095e-04, -2.3540e-05])\n",
      "epoch 762 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 763 loss is 1.0450661182403564\n",
      "epoch 763 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 763 : params.grad right after loss.backward(): tensor([-9.9726e-05, -2.3689e-05])\n",
      "epoch 763 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 764 loss is 1.0450661182403564\n",
      "epoch 764 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 764 : params.grad right after loss.backward(): tensor([-9.8363e-05, -2.3834e-05])\n",
      "epoch 764 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 765 loss is 1.045066237449646\n",
      "epoch 765 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 765 : params.grad right after loss.backward(): tensor([-9.7066e-05, -2.3913e-05])\n",
      "epoch 765 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 766 loss is 1.0450661182403564\n",
      "epoch 766 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 766 : params.grad right after loss.backward(): tensor([-9.5777e-05, -2.3086e-05])\n",
      "epoch 766 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 767 loss is 1.0450661182403564\n",
      "epoch 767 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 767 : params.grad right after loss.backward(): tensor([-9.4481e-05, -2.3205e-05])\n",
      "epoch 767 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 768 loss is 1.045066237449646\n",
      "epoch 768 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 768 : params.grad right after loss.backward(): tensor([-9.3035e-05, -2.3209e-05])\n",
      "epoch 768 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 769 loss is 1.0450661182403564\n",
      "epoch 769 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 769 : params.grad right after loss.backward(): tensor([-9.1717e-05, -2.3384e-05])\n",
      "epoch 769 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 770 loss is 1.0450661182403564\n",
      "epoch 770 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 770 : params.grad right after loss.backward(): tensor([-9.0428e-05, -2.3469e-05])\n",
      "epoch 770 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 771 loss is 1.0450661182403564\n",
      "epoch 771 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 771 : params.grad right after loss.backward(): tensor([-8.9057e-05, -2.3544e-05])\n",
      "epoch 771 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 772 loss is 1.045066237449646\n",
      "epoch 772 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 772 : params.grad right after loss.backward(): tensor([-8.7760e-05, -2.3693e-05])\n",
      "epoch 772 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 773 loss is 1.0450661182403564\n",
      "epoch 773 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 773 : params.grad right after loss.backward(): tensor([-8.6427e-05, -2.3793e-05])\n",
      "epoch 773 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 774 loss is 1.045066237449646\n",
      "epoch 774 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 774 : params.grad right after loss.backward(): tensor([-8.5078e-05, -2.3909e-05])\n",
      "epoch 774 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 775 loss is 1.045066237449646\n",
      "epoch 775 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 775 : params.grad right after loss.backward(): tensor([-8.3767e-05, -2.3015e-05])\n",
      "epoch 775 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 776 loss is 1.045066237449646\n",
      "epoch 776 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 776 : params.grad right after loss.backward(): tensor([-8.2500e-05, -2.3164e-05])\n",
      "epoch 776 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 777 loss is 1.0450663566589355\n",
      "epoch 777 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 777 : params.grad right after loss.backward(): tensor([-8.1509e-05, -2.3283e-05])\n",
      "epoch 777 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 778 loss is 1.0450661182403564\n",
      "epoch 778 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 778 : params.grad right after loss.backward(): tensor([-8.0504e-05, -2.3369e-05])\n",
      "epoch 778 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 779 loss is 1.045066237449646\n",
      "epoch 779 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 779 : params.grad right after loss.backward(): tensor([-7.9483e-05, -2.3380e-05])\n",
      "epoch 779 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 780 loss is 1.0450661182403564\n",
      "epoch 780 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 780 : params.grad right after loss.backward(): tensor([-7.8529e-05, -2.3488e-05])\n",
      "epoch 780 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 781 loss is 1.045066237449646\n",
      "epoch 781 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 781 : params.grad right after loss.backward(): tensor([-7.7531e-05, -2.3596e-05])\n",
      "epoch 781 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 782 loss is 1.0450661182403564\n",
      "epoch 782 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 782 : params.grad right after loss.backward(): tensor([-7.6540e-05, -2.3670e-05])\n",
      "epoch 782 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 783 loss is 1.045065999031067\n",
      "epoch 783 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 783 : params.grad right after loss.backward(): tensor([-7.5571e-05, -2.3771e-05])\n",
      "epoch 783 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 784 loss is 1.0450661182403564\n",
      "epoch 784 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 784 : params.grad right after loss.backward(): tensor([-7.4476e-05, -2.3793e-05])\n",
      "epoch 784 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 785 loss is 1.0450661182403564\n",
      "epoch 785 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 785 : params.grad right after loss.backward(): tensor([-7.3560e-05, -2.3965e-05])\n",
      "epoch 785 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 786 loss is 1.045066237449646\n",
      "epoch 786 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 786 : params.grad right after loss.backward(): tensor([-7.2658e-05, -2.3045e-05])\n",
      "epoch 786 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 787 loss is 1.045066237449646\n",
      "epoch 787 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 787 : params.grad right after loss.backward(): tensor([-7.1563e-05, -2.3115e-05])\n",
      "epoch 787 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 788 loss is 1.0450661182403564\n",
      "epoch 788 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 788 : params.grad right after loss.backward(): tensor([-7.0646e-05, -2.3257e-05])\n",
      "epoch 788 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 789 loss is 1.0450661182403564\n",
      "epoch 789 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 789 : params.grad right after loss.backward(): tensor([-6.9641e-05, -2.3313e-05])\n",
      "epoch 789 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 790 loss is 1.045066237449646\n",
      "epoch 790 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 790 : params.grad right after loss.backward(): tensor([-6.8620e-05, -2.3365e-05])\n",
      "epoch 790 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 791 loss is 1.0450661182403564\n",
      "epoch 791 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 791 : params.grad right after loss.backward(): tensor([-6.7629e-05, -2.3421e-05])\n",
      "epoch 791 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 792 loss is 1.045066237449646\n",
      "epoch 792 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 792 : params.grad right after loss.backward(): tensor([-6.6638e-05, -2.3495e-05])\n",
      "epoch 792 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 793 loss is 1.0450661182403564\n",
      "epoch 793 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 793 : params.grad right after loss.backward(): tensor([-6.5617e-05, -2.3637e-05])\n",
      "epoch 793 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 794 loss is 1.0450661182403564\n",
      "epoch 794 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 794 : params.grad right after loss.backward(): tensor([-6.4656e-05, -2.3723e-05])\n",
      "epoch 794 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 795 loss is 1.045066237449646\n",
      "epoch 795 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 795 : params.grad right after loss.backward(): tensor([-6.3628e-05, -2.3782e-05])\n",
      "epoch 795 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 796 loss is 1.0450661182403564\n",
      "epoch 796 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 796 : params.grad right after loss.backward(): tensor([-6.2667e-05, -2.3823e-05])\n",
      "epoch 796 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 797 loss is 1.0450661182403564\n",
      "epoch 797 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 797 : params.grad right after loss.backward(): tensor([-6.1624e-05, -2.3924e-05])\n",
      "epoch 797 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 798 loss is 1.045066237449646\n",
      "epoch 798 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 798 : params.grad right after loss.backward(): tensor([-6.0655e-05, -2.3067e-05])\n",
      "epoch 798 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 799 loss is 1.0450661182403564\n",
      "epoch 799 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 799 : params.grad right after loss.backward(): tensor([-5.9694e-05, -2.3142e-05])\n",
      "epoch 799 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 800 loss is 1.0450663566589355\n",
      "epoch 800 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 800 : params.grad right after loss.backward(): tensor([-5.8651e-05, -2.3216e-05])\n",
      "epoch 800 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 801 loss is 1.045066237449646\n",
      "epoch 801 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 801 : params.grad right after loss.backward(): tensor([-5.8055e-05, -2.3305e-05])\n",
      "epoch 801 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 802 loss is 1.0450663566589355\n",
      "epoch 802 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 802 : params.grad right after loss.backward(): tensor([-5.7355e-05, -2.3317e-05])\n",
      "epoch 802 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 803 loss is 1.0450661182403564\n",
      "epoch 803 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 803 : params.grad right after loss.backward(): tensor([-5.6736e-05, -2.3402e-05])\n",
      "epoch 803 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 804 loss is 1.0450661182403564\n",
      "epoch 804 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 804 : params.grad right after loss.backward(): tensor([-5.6073e-05, -2.3406e-05])\n",
      "epoch 804 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 805 loss is 1.0450661182403564\n",
      "epoch 805 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 805 : params.grad right after loss.backward(): tensor([-5.5395e-05, -2.3492e-05])\n",
      "epoch 805 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 806 loss is 1.0450661182403564\n",
      "epoch 806 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 806 : params.grad right after loss.backward(): tensor([-5.4702e-05, -2.3540e-05])\n",
      "epoch 806 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 807 loss is 1.045065999031067\n",
      "epoch 807 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 807 : params.grad right after loss.backward(): tensor([-5.4039e-05, -2.3581e-05])\n",
      "epoch 807 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 808 loss is 1.0450661182403564\n",
      "epoch 808 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 808 : params.grad right after loss.backward(): tensor([-5.3450e-05, -2.3656e-05])\n",
      "epoch 808 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 809 loss is 1.0450661182403564\n",
      "epoch 809 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 809 : params.grad right after loss.backward(): tensor([-5.2646e-05, -2.3603e-05])\n",
      "epoch 809 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 810 loss is 1.0450661182403564\n",
      "epoch 810 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 810 : params.grad right after loss.backward(): tensor([-5.2176e-05, -2.3816e-05])\n",
      "epoch 810 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 811 loss is 1.045066237449646\n",
      "epoch 811 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 811 : params.grad right after loss.backward(): tensor([-5.1327e-05, -2.3756e-05])\n",
      "epoch 811 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 812 loss is 1.0450663566589355\n",
      "epoch 812 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 812 : params.grad right after loss.backward(): tensor([-5.0791e-05, -2.3954e-05])\n",
      "epoch 812 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 813 loss is 1.045066237449646\n",
      "epoch 813 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 813 : params.grad right after loss.backward(): tensor([-5.0008e-05, -2.2952e-05])\n",
      "epoch 813 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 814 loss is 1.045066237449646\n",
      "epoch 814 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 814 : params.grad right after loss.backward(): tensor([-4.9479e-05, -2.3082e-05])\n",
      "epoch 814 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 815 loss is 1.0450661182403564\n",
      "epoch 815 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 815 : params.grad right after loss.backward(): tensor([-4.8764e-05, -2.3093e-05])\n",
      "epoch 815 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 816 loss is 1.0450661182403564\n",
      "epoch 816 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 816 : params.grad right after loss.backward(): tensor([-4.8108e-05, -2.3138e-05])\n",
      "epoch 816 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 817 loss is 1.0450661182403564\n",
      "epoch 817 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 817 : params.grad right after loss.backward(): tensor([-4.7497e-05, -2.3261e-05])\n",
      "epoch 817 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 818 loss is 1.0450663566589355\n",
      "epoch 818 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 818 : params.grad right after loss.backward(): tensor([-4.6805e-05, -2.3272e-05])\n",
      "epoch 818 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 819 loss is 1.0450661182403564\n",
      "epoch 819 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 819 : params.grad right after loss.backward(): tensor([-4.6119e-05, -2.3369e-05])\n",
      "epoch 819 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 820 loss is 1.0450661182403564\n",
      "epoch 820 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 820 : params.grad right after loss.backward(): tensor([-4.5471e-05, -2.3354e-05])\n",
      "epoch 820 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 821 loss is 1.0450663566589355\n",
      "epoch 821 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 821 : params.grad right after loss.backward(): tensor([-4.4815e-05, -2.3440e-05])\n",
      "epoch 821 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 822 loss is 1.0450661182403564\n",
      "epoch 822 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 822 : params.grad right after loss.backward(): tensor([-4.4145e-05, -2.3458e-05])\n",
      "epoch 822 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 823 loss is 1.045066237449646\n",
      "epoch 823 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 823 : params.grad right after loss.backward(): tensor([-4.3452e-05, -2.3529e-05])\n",
      "epoch 823 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 824 loss is 1.045066237449646\n",
      "epoch 824 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 824 : params.grad right after loss.backward(): tensor([-4.2789e-05, -2.3518e-05])\n",
      "epoch 824 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 825 loss is 1.0450661182403564\n",
      "epoch 825 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 825 : params.grad right after loss.backward(): tensor([-4.2088e-05, -2.3581e-05])\n",
      "epoch 825 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 826 loss is 1.045066237449646\n",
      "epoch 826 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 826 : params.grad right after loss.backward(): tensor([-4.1507e-05, -2.3678e-05])\n",
      "epoch 826 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 827 loss is 1.0450661182403564\n",
      "epoch 827 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 827 : params.grad right after loss.backward(): tensor([-4.0837e-05, -2.3689e-05])\n",
      "epoch 827 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 828 loss is 1.0450661182403564\n",
      "epoch 828 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 828 : params.grad right after loss.backward(): tensor([-4.0129e-05, -2.3790e-05])\n",
      "epoch 828 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 829 loss is 1.0450661182403564\n",
      "epoch 829 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 829 : params.grad right after loss.backward(): tensor([-3.9540e-05, -2.3905e-05])\n",
      "epoch 829 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 830 loss is 1.045066237449646\n",
      "epoch 830 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 830 : params.grad right after loss.backward(): tensor([-3.8870e-05, -2.2952e-05])\n",
      "epoch 830 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 831 loss is 1.045066237449646\n",
      "epoch 831 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 831 : params.grad right after loss.backward(): tensor([-3.8214e-05, -2.2966e-05])\n",
      "epoch 831 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 832 loss is 1.0450661182403564\n",
      "epoch 832 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 832 : params.grad right after loss.backward(): tensor([-3.7581e-05, -2.3026e-05])\n",
      "epoch 832 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 833 loss is 1.0450661182403564\n",
      "epoch 833 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 833 : params.grad right after loss.backward(): tensor([-3.6828e-05, -2.3060e-05])\n",
      "epoch 833 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 834 loss is 1.045065999031067\n",
      "epoch 834 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 834 : params.grad right after loss.backward(): tensor([-3.6240e-05, -2.3138e-05])\n",
      "epoch 834 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 835 loss is 1.0450661182403564\n",
      "epoch 835 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 835 : params.grad right after loss.backward(): tensor([-3.5584e-05, -2.3238e-05])\n",
      "epoch 835 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 836 loss is 1.0450661182403564\n",
      "epoch 836 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 836 : params.grad right after loss.backward(): tensor([-3.5211e-05, -2.3201e-05])\n",
      "epoch 836 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 837 loss is 1.0450661182403564\n",
      "epoch 837 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 837 : params.grad right after loss.backward(): tensor([-3.4891e-05, -2.3253e-05])\n",
      "epoch 837 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 838 loss is 1.045066237449646\n",
      "epoch 838 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 838 : params.grad right after loss.backward(): tensor([-3.4548e-05, -2.3220e-05])\n",
      "epoch 838 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 839 loss is 1.045066237449646\n",
      "epoch 839 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 839 : params.grad right after loss.backward(): tensor([-3.4280e-05, -2.3406e-05])\n",
      "epoch 839 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 840 loss is 1.0450663566589355\n",
      "epoch 840 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 840 : params.grad right after loss.backward(): tensor([-3.3870e-05, -2.3395e-05])\n",
      "epoch 840 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 841 loss is 1.0450661182403564\n",
      "epoch 841 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 841 : params.grad right after loss.backward(): tensor([-3.3557e-05, -2.3369e-05])\n",
      "epoch 841 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 842 loss is 1.045066237449646\n",
      "epoch 842 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 842 : params.grad right after loss.backward(): tensor([-3.3237e-05, -2.3410e-05])\n",
      "epoch 842 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 843 loss is 1.045066237449646\n",
      "epoch 843 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 843 : params.grad right after loss.backward(): tensor([-3.2872e-05, -2.3425e-05])\n",
      "epoch 843 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 844 loss is 1.0450661182403564\n",
      "epoch 844 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 844 : params.grad right after loss.backward(): tensor([-3.2596e-05, -2.3521e-05])\n",
      "epoch 844 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 845 loss is 1.0450661182403564\n",
      "epoch 845 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 845 : params.grad right after loss.backward(): tensor([-3.2254e-05, -2.3551e-05])\n",
      "epoch 845 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 846 loss is 1.0450663566589355\n",
      "epoch 846 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 846 : params.grad right after loss.backward(): tensor([-3.1829e-05, -2.3499e-05])\n",
      "epoch 846 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 847 loss is 1.0450663566589355\n",
      "epoch 847 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 847 : params.grad right after loss.backward(): tensor([-3.1538e-05, -2.3521e-05])\n",
      "epoch 847 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 848 loss is 1.0450661182403564\n",
      "epoch 848 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 848 : params.grad right after loss.backward(): tensor([-3.1248e-05, -2.3585e-05])\n",
      "epoch 848 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 849 loss is 1.0450661182403564\n",
      "epoch 849 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 849 : params.grad right after loss.backward(): tensor([-3.0912e-05, -2.3648e-05])\n",
      "epoch 849 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 850 loss is 1.0450661182403564\n",
      "epoch 850 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 850 : params.grad right after loss.backward(): tensor([-3.0585e-05, -2.3652e-05])\n",
      "epoch 850 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 851 loss is 1.045065999031067\n",
      "epoch 851 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 851 : params.grad right after loss.backward(): tensor([-3.0234e-05, -2.3644e-05])\n",
      "epoch 851 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 852 loss is 1.0450661182403564\n",
      "epoch 852 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 852 : params.grad right after loss.backward(): tensor([-2.9825e-05, -2.3648e-05])\n",
      "epoch 852 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 853 loss is 1.0450661182403564\n",
      "epoch 853 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 853 : params.grad right after loss.backward(): tensor([-2.9460e-05, -2.3652e-05])\n",
      "epoch 853 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 854 loss is 1.0450661182403564\n",
      "epoch 854 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 854 : params.grad right after loss.backward(): tensor([-2.9214e-05, -2.3749e-05])\n",
      "epoch 854 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 855 loss is 1.0450661182403564\n",
      "epoch 855 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 855 : params.grad right after loss.backward(): tensor([-2.8923e-05, -2.3756e-05])\n",
      "epoch 855 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 856 loss is 1.045066237449646\n",
      "epoch 856 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 856 : params.grad right after loss.backward(): tensor([-2.8618e-05, -2.3846e-05])\n",
      "epoch 856 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 857 loss is 1.045066237449646\n",
      "epoch 857 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 857 : params.grad right after loss.backward(): tensor([-2.8297e-05, -2.2862e-05])\n",
      "epoch 857 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 858 loss is 1.045066237449646\n",
      "epoch 858 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 858 : params.grad right after loss.backward(): tensor([-2.7962e-05, -2.2881e-05])\n",
      "epoch 858 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 859 loss is 1.045066237449646\n",
      "epoch 859 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 859 : params.grad right after loss.backward(): tensor([-2.7701e-05, -2.2940e-05])\n",
      "epoch 859 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 860 loss is 1.045066237449646\n",
      "epoch 860 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 860 : params.grad right after loss.backward(): tensor([-2.7306e-05, -2.2981e-05])\n",
      "epoch 860 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 861 loss is 1.0450663566589355\n",
      "epoch 861 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 861 : params.grad right after loss.backward(): tensor([-2.6911e-05, -2.2978e-05])\n",
      "epoch 861 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 862 loss is 1.0450661182403564\n",
      "epoch 862 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 862 : params.grad right after loss.backward(): tensor([-2.6651e-05, -2.3026e-05])\n",
      "epoch 862 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 863 loss is 1.0450661182403564\n",
      "epoch 863 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 863 : params.grad right after loss.backward(): tensor([-2.6330e-05, -2.3004e-05])\n",
      "epoch 863 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 864 loss is 1.045066237449646\n",
      "epoch 864 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 864 : params.grad right after loss.backward(): tensor([-2.6017e-05, -2.3086e-05])\n",
      "epoch 864 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 865 loss is 1.045066237449646\n",
      "epoch 865 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 865 : params.grad right after loss.backward(): tensor([-2.5667e-05, -2.3108e-05])\n",
      "epoch 865 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 866 loss is 1.0450661182403564\n",
      "epoch 866 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 866 : params.grad right after loss.backward(): tensor([-2.5205e-05, -2.3074e-05])\n",
      "epoch 866 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 867 loss is 1.0450661182403564\n",
      "epoch 867 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 867 : params.grad right after loss.backward(): tensor([-2.4982e-05, -2.3123e-05])\n",
      "epoch 867 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 868 loss is 1.045065999031067\n",
      "epoch 868 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 868 : params.grad right after loss.backward(): tensor([-2.4654e-05, -2.3182e-05])\n",
      "epoch 868 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 869 loss is 1.0450661182403564\n",
      "epoch 869 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 869 : params.grad right after loss.backward(): tensor([-2.4334e-05, -2.3212e-05])\n",
      "epoch 869 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 870 loss is 1.0450661182403564\n",
      "epoch 870 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 870 : params.grad right after loss.backward(): tensor([-2.3931e-05, -2.3201e-05])\n",
      "epoch 870 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 871 loss is 1.0450661182403564\n",
      "epoch 871 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 871 : params.grad right after loss.backward(): tensor([-2.3603e-05, -2.3171e-05])\n",
      "epoch 871 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 872 loss is 1.0450661182403564\n",
      "epoch 872 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 872 : params.grad right after loss.backward(): tensor([-2.3291e-05, -2.3238e-05])\n",
      "epoch 872 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 873 loss is 1.0450661182403564\n",
      "epoch 873 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 873 : params.grad right after loss.backward(): tensor([-2.3030e-05, -2.3276e-05])\n",
      "epoch 873 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 874 loss is 1.0450661182403564\n",
      "epoch 874 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 874 : params.grad right after loss.backward(): tensor([-2.2694e-05, -2.3320e-05])\n",
      "epoch 874 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 875 loss is 1.045066237449646\n",
      "epoch 875 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 875 : params.grad right after loss.backward(): tensor([-2.2277e-05, -2.3358e-05])\n",
      "epoch 875 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 876 loss is 1.0450661182403564\n",
      "epoch 876 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 876 : params.grad right after loss.backward(): tensor([-2.1949e-05, -2.3395e-05])\n",
      "epoch 876 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 877 loss is 1.045066237449646\n",
      "epoch 877 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 877 : params.grad right after loss.backward(): tensor([-2.1666e-05, -2.3391e-05])\n",
      "epoch 877 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 878 loss is 1.045066237449646\n",
      "epoch 878 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 878 : params.grad right after loss.backward(): tensor([-2.1331e-05, -2.3473e-05])\n",
      "epoch 878 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 879 loss is 1.045066237449646\n",
      "epoch 879 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 879 : params.grad right after loss.backward(): tensor([-2.0966e-05, -2.3458e-05])\n",
      "epoch 879 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 880 loss is 1.045066237449646\n",
      "epoch 880 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 880 : params.grad right after loss.backward(): tensor([-2.0579e-05, -2.3492e-05])\n",
      "epoch 880 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 881 loss is 1.045066237449646\n",
      "epoch 881 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 881 : params.grad right after loss.backward(): tensor([-2.0318e-05, -2.3533e-05])\n",
      "epoch 881 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 882 loss is 1.0450661182403564\n",
      "epoch 882 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 882 : params.grad right after loss.backward(): tensor([-1.9997e-05, -2.3536e-05])\n",
      "epoch 882 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 883 loss is 1.0450661182403564\n",
      "epoch 883 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 883 : params.grad right after loss.backward(): tensor([-1.9714e-05, -2.3589e-05])\n",
      "epoch 883 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 884 loss is 1.0450661182403564\n",
      "epoch 884 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 884 : params.grad right after loss.backward(): tensor([-1.9401e-05, -2.3626e-05])\n",
      "epoch 884 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 885 loss is 1.0450661182403564\n",
      "epoch 885 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 885 : params.grad right after loss.backward(): tensor([-1.8954e-05, -2.3622e-05])\n",
      "epoch 885 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 886 loss is 1.0450661182403564\n",
      "epoch 886 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 886 : params.grad right after loss.backward(): tensor([-1.8641e-05, -2.3618e-05])\n",
      "epoch 886 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 887 loss is 1.0450661182403564\n",
      "epoch 887 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 887 : params.grad right after loss.backward(): tensor([-1.8314e-05, -2.3656e-05])\n",
      "epoch 887 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 888 loss is 1.0450661182403564\n",
      "epoch 888 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 888 : params.grad right after loss.backward(): tensor([-1.8045e-05, -2.3723e-05])\n",
      "epoch 888 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 889 loss is 1.0450661182403564\n",
      "epoch 889 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 889 : params.grad right after loss.backward(): tensor([-1.7688e-05, -2.3693e-05])\n",
      "epoch 889 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 890 loss is 1.0450663566589355\n",
      "epoch 890 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 890 : params.grad right after loss.backward(): tensor([-1.7345e-05, -2.3730e-05])\n",
      "epoch 890 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 891 loss is 1.045066237449646\n",
      "epoch 891 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 891 : params.grad right after loss.backward(): tensor([-1.7039e-05, -2.3723e-05])\n",
      "epoch 891 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 892 loss is 1.0450661182403564\n",
      "epoch 892 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 892 : params.grad right after loss.backward(): tensor([-1.6689e-05, -2.3741e-05])\n",
      "epoch 892 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 893 loss is 1.0450661182403564\n",
      "epoch 893 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 893 : params.grad right after loss.backward(): tensor([-1.6354e-05, -2.3801e-05])\n",
      "epoch 893 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 894 loss is 1.0450661182403564\n",
      "epoch 894 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 894 : params.grad right after loss.backward(): tensor([-1.6019e-05, -2.3860e-05])\n",
      "epoch 894 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 895 loss is 1.0450661182403564\n",
      "epoch 895 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 895 : params.grad right after loss.backward(): tensor([-1.5721e-05, -2.2929e-05])\n",
      "epoch 895 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 896 loss is 1.0450661182403564\n",
      "epoch 896 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 896 : params.grad right after loss.backward(): tensor([-1.5378e-05, -2.2970e-05])\n",
      "epoch 896 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 897 loss is 1.045066237449646\n",
      "epoch 897 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 897 : params.grad right after loss.backward(): tensor([-1.5110e-05, -2.3007e-05])\n",
      "epoch 897 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 898 loss is 1.0450661182403564\n",
      "epoch 898 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 898 : params.grad right after loss.backward(): tensor([-1.4745e-05, -2.2996e-05])\n",
      "epoch 898 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 899 loss is 1.045066237449646\n",
      "epoch 899 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 899 : params.grad right after loss.backward(): tensor([-1.4447e-05, -2.3063e-05])\n",
      "epoch 899 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 900 loss is 1.0450661182403564\n",
      "epoch 900 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 900 : params.grad right after loss.backward(): tensor([-1.4059e-05, -2.3056e-05])\n",
      "epoch 900 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 901 loss is 1.0450661182403564\n",
      "epoch 901 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 901 : params.grad right after loss.backward(): tensor([-1.3724e-05, -2.3048e-05])\n",
      "epoch 901 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 902 loss is 1.0450661182403564\n",
      "epoch 902 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 902 : params.grad right after loss.backward(): tensor([-1.3441e-05, -2.3171e-05])\n",
      "epoch 902 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 903 loss is 1.0450661182403564\n",
      "epoch 903 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 903 : params.grad right after loss.backward(): tensor([-1.3091e-05, -2.3182e-05])\n",
      "epoch 903 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 904 loss is 1.0450661182403564\n",
      "epoch 904 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 904 : params.grad right after loss.backward(): tensor([-1.2763e-05, -2.3223e-05])\n",
      "epoch 904 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 905 loss is 1.0450661182403564\n",
      "epoch 905 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 905 : params.grad right after loss.backward(): tensor([-1.2398e-05, -2.3216e-05])\n",
      "epoch 905 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 906 loss is 1.045065999031067\n",
      "epoch 906 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 906 : params.grad right after loss.backward(): tensor([-1.2062e-05, -2.3276e-05])\n",
      "epoch 906 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 907 loss is 1.0450661182403564\n",
      "epoch 907 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 907 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 907 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 908 loss is 1.0450661182403564\n",
      "epoch 908 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 908 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 908 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 909 loss is 1.0450661182403564\n",
      "epoch 909 params.grad right before loss.backward() : tensor([0., 0.])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 909 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 909 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 910 loss is 1.0450661182403564\n",
      "epoch 910 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 910 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 910 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 911 loss is 1.0450661182403564\n",
      "epoch 911 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 911 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 911 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 912 loss is 1.0450661182403564\n",
      "epoch 912 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 912 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 912 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 913 loss is 1.0450661182403564\n",
      "epoch 913 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 913 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 913 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 914 loss is 1.0450661182403564\n",
      "epoch 914 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 914 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 914 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 915 loss is 1.0450661182403564\n",
      "epoch 915 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 915 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 915 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 916 loss is 1.0450661182403564\n",
      "epoch 916 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 916 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 916 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 917 loss is 1.0450661182403564\n",
      "epoch 917 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 917 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 917 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 918 loss is 1.0450661182403564\n",
      "epoch 918 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 918 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 918 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 919 loss is 1.0450661182403564\n",
      "epoch 919 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 919 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 919 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 920 loss is 1.0450661182403564\n",
      "epoch 920 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 920 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 920 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 921 loss is 1.0450661182403564\n",
      "epoch 921 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 921 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 921 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 922 loss is 1.0450661182403564\n",
      "epoch 922 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 922 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 922 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 923 loss is 1.0450661182403564\n",
      "epoch 923 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 923 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 923 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 924 loss is 1.0450661182403564\n",
      "epoch 924 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 924 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 924 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 925 loss is 1.0450661182403564\n",
      "epoch 925 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 925 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 925 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 926 loss is 1.0450661182403564\n",
      "epoch 926 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 926 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 926 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 927 loss is 1.0450661182403564\n",
      "epoch 927 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 927 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 927 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 928 loss is 1.0450661182403564\n",
      "epoch 928 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 928 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 928 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 929 loss is 1.0450661182403564\n",
      "epoch 929 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 929 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 929 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 930 loss is 1.0450661182403564\n",
      "epoch 930 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 930 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 930 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 931 loss is 1.0450661182403564\n",
      "epoch 931 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 931 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 931 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 932 loss is 1.0450661182403564\n",
      "epoch 932 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 932 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 932 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 933 loss is 1.0450661182403564\n",
      "epoch 933 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 933 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 933 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 934 loss is 1.0450661182403564\n",
      "epoch 934 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 934 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 934 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 935 loss is 1.0450661182403564\n",
      "epoch 935 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 935 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 935 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 936 loss is 1.0450661182403564\n",
      "epoch 936 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 936 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 936 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 937 loss is 1.0450661182403564\n",
      "epoch 937 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 937 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 937 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 938 loss is 1.0450661182403564\n",
      "epoch 938 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 938 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 938 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 939 loss is 1.0450661182403564\n",
      "epoch 939 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 939 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 939 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 940 loss is 1.0450661182403564\n",
      "epoch 940 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 940 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 940 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 941 loss is 1.0450661182403564\n",
      "epoch 941 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 941 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 941 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 942 loss is 1.0450661182403564\n",
      "epoch 942 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 942 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 942 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 943 loss is 1.0450661182403564\n",
      "epoch 943 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 943 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 943 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 944 loss is 1.0450661182403564\n",
      "epoch 944 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 944 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 944 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 945 loss is 1.0450661182403564\n",
      "epoch 945 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 945 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 945 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 946 loss is 1.0450661182403564\n",
      "epoch 946 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 946 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 946 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 947 loss is 1.0450661182403564\n",
      "epoch 947 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 947 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 947 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 948 loss is 1.0450661182403564\n",
      "epoch 948 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 948 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 948 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 949 loss is 1.0450661182403564\n",
      "epoch 949 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 949 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 949 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 950 loss is 1.0450661182403564\n",
      "epoch 950 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 950 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 950 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 951 loss is 1.0450661182403564\n",
      "epoch 951 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 951 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 951 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 952 loss is 1.0450661182403564\n",
      "epoch 952 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 952 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 952 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 953 loss is 1.0450661182403564\n",
      "epoch 953 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 953 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 953 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 954 loss is 1.0450661182403564\n",
      "epoch 954 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 954 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 954 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 955 loss is 1.0450661182403564\n",
      "epoch 955 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 955 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 955 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 956 loss is 1.0450661182403564\n",
      "epoch 956 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 956 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 956 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 957 loss is 1.0450661182403564\n",
      "epoch 957 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 957 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 957 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 958 loss is 1.0450661182403564\n",
      "epoch 958 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 958 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 958 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 959 loss is 1.0450661182403564\n",
      "epoch 959 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 959 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 959 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 960 loss is 1.0450661182403564\n",
      "epoch 960 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 960 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 960 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 961 loss is 1.0450661182403564\n",
      "epoch 961 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 961 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 961 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 962 loss is 1.0450661182403564\n",
      "epoch 962 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 962 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 962 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 963 loss is 1.0450661182403564\n",
      "epoch 963 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 963 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 963 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 964 loss is 1.0450661182403564\n",
      "epoch 964 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 964 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 964 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 965 loss is 1.0450661182403564\n",
      "epoch 965 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 965 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 965 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 966 loss is 1.0450661182403564\n",
      "epoch 966 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 966 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 966 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 967 loss is 1.0450661182403564\n",
      "epoch 967 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 967 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 967 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 968 loss is 1.0450661182403564\n",
      "epoch 968 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 968 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 968 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 969 loss is 1.0450661182403564\n",
      "epoch 969 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 969 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 969 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 970 loss is 1.0450661182403564\n",
      "epoch 970 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 970 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 970 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 971 loss is 1.0450661182403564\n",
      "epoch 971 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 971 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 971 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 972 loss is 1.0450661182403564\n",
      "epoch 972 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 972 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 972 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 973 loss is 1.0450661182403564\n",
      "epoch 973 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 973 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 973 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 974 loss is 1.0450661182403564\n",
      "epoch 974 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 974 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 974 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 975 loss is 1.0450661182403564\n",
      "epoch 975 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 975 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 975 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 976 loss is 1.0450661182403564\n",
      "epoch 976 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 976 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 976 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 977 loss is 1.0450661182403564\n",
      "epoch 977 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 977 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 977 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 978 loss is 1.0450661182403564\n",
      "epoch 978 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 978 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 978 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 979 loss is 1.0450661182403564\n",
      "epoch 979 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 979 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 979 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 980 loss is 1.0450661182403564\n",
      "epoch 980 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 980 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 980 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 981 loss is 1.0450661182403564\n",
      "epoch 981 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 981 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 981 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 982 loss is 1.0450661182403564\n",
      "epoch 982 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 982 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 982 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 983 loss is 1.0450661182403564\n",
      "epoch 983 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 983 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 983 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 984 loss is 1.0450661182403564\n",
      "epoch 984 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 984 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 984 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 985 loss is 1.0450661182403564\n",
      "epoch 985 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 985 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 985 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 986 loss is 1.0450661182403564\n",
      "epoch 986 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 986 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 986 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 987 loss is 1.0450661182403564\n",
      "epoch 987 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 987 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 987 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 988 loss is 1.0450661182403564\n",
      "epoch 988 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 988 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 988 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 989 loss is 1.0450661182403564\n",
      "epoch 989 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 989 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 989 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 990 loss is 1.0450661182403564\n",
      "epoch 990 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 990 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 990 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 991 loss is 1.0450661182403564\n",
      "epoch 991 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 991 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 991 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 992 loss is 1.0450661182403564\n",
      "epoch 992 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 992 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 992 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 993 loss is 1.0450661182403564\n",
      "epoch 993 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 993 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 993 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 994 loss is 1.0450661182403564\n",
      "epoch 994 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 994 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 994 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 995 loss is 1.0450661182403564\n",
      "epoch 995 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 995 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 995 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 996 loss is 1.0450661182403564\n",
      "epoch 996 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 996 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 996 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 997 loss is 1.0450661182403564\n",
      "epoch 997 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 997 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 997 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 998 loss is 1.0450661182403564\n",
      "epoch 998 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 998 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 998 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n",
      "epoch 999 loss is 1.0450661182403564\n",
      "epoch 999 params.grad right before loss.backward() : tensor([0., 0.])\n",
      "epoch 999 : params.grad right after loss.backward(): tensor([-1.1750e-05, -2.3328e-05])\n",
      "epoch 999 after optimizer.step() : tensor([2.9487, 4.9955], requires_grad=True), required_grad : True\n"
     ]
    }
   ],
   "source": [
    "train_loop(model,loss_fn,params,sgd,x,y,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfb467f",
   "metadata": {},
   "source": [
    "# Let's use torch.nn to build simple linear regression with nn.Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4034f639",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4c92c9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Linear(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "23a82ec5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nn.Linear model parameters : [Parameter containing:\n",
      "tensor([[-0.7463]], requires_grad=True), Parameter containing:\n",
      "tensor([0.2764], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "print(f\"nn.Linear model parameters : {[param for param in model.parameters()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "9b32e243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "now x has shape : torch.Size([100])\n"
     ]
    }
   ],
   "source": [
    "x_new = x.unsqueeze(1)\n",
    "y_true = y.unsqueeze(1)\n",
    "print(f\"now x has shape : {x.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "fee79bf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred.shape : torch.Size([100, 1])\n",
      "y.shape : torch.Size([100])\n",
      "y_true.shape : torch.Size([100, 1])\n"
     ]
    }
   ],
   "source": [
    "y_pred = model(x_new)\n",
    "print(f\"y_pred.shape : {y_pred.shape}\")\n",
    "print(f\"y.shape : {y.shape}\")\n",
    "print(f\"y_true.shape : {y_true.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c66a4d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd = optim.SGD(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "540789a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "792387a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(model, loss_fn,optimizer, x, y_true, epochs):\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()        \n",
    "        y_pred = model(x)\n",
    "        loss = loss_fn(y_pred, y_true)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"epoch {epoch} : {loss}, parameters {[param for param in model.parameters()]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ca3ee28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 : 30.84231948852539, parameters [Parameter containing:\n",
      "tensor([[-0.7002]], requires_grad=True), Parameter containing:\n",
      "tensor([0.3666], requires_grad=True)]\n",
      "epoch 100 : 2.18280291557312, parameters [Parameter containing:\n",
      "tensor([[1.9482]], requires_grad=True), Parameter containing:\n",
      "tensor([4.2989], requires_grad=True)]\n",
      "epoch 200 : 1.1042948961257935, parameters [Parameter containing:\n",
      "tensor([[2.6866]], requires_grad=True), Parameter containing:\n",
      "tensor([4.8811], requires_grad=True)]\n",
      "epoch 300 : 1.0485889911651611, parameters [Parameter containing:\n",
      "tensor([[2.8815]], requires_grad=True), Parameter containing:\n",
      "tensor([4.9746], requires_grad=True)]\n",
      "epoch 400 : 1.0452847480773926, parameters [Parameter containing:\n",
      "tensor([[2.9317]], requires_grad=True), Parameter containing:\n",
      "tensor([4.9913], requires_grad=True)]\n",
      "epoch 500 : 1.0450799465179443, parameters [Parameter containing:\n",
      "tensor([[2.9444]], requires_grad=True), Parameter containing:\n",
      "tensor([4.9946], requires_grad=True)]\n",
      "epoch 600 : 1.0450669527053833, parameters [Parameter containing:\n",
      "tensor([[2.9477]], requires_grad=True), Parameter containing:\n",
      "tensor([4.9953], requires_grad=True)]\n",
      "epoch 700 : 1.0450663566589355, parameters [Parameter containing:\n",
      "tensor([[2.9485]], requires_grad=True), Parameter containing:\n",
      "tensor([4.9954], requires_grad=True)]\n",
      "epoch 800 : 1.0450661182403564, parameters [Parameter containing:\n",
      "tensor([[2.9487]], requires_grad=True), Parameter containing:\n",
      "tensor([4.9955], requires_grad=True)]\n",
      "epoch 900 : 1.0450661182403564, parameters [Parameter containing:\n",
      "tensor([[2.9487]], requires_grad=True), Parameter containing:\n",
      "tensor([4.9955], requires_grad=True)]\n"
     ]
    }
   ],
   "source": [
    "train_loop(model,loss_fn,sgd,x_new,y_true,epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33aa7c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
